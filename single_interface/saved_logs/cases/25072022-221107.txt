Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.28
Average Loss: 0.09623
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.08
Average Loss: 0.09575
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.47
Average Loss: 0.0914
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.68
Average Loss: 0.08641
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.58
Average Loss: 0.06878
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.72
Average Loss: 0.00654
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.38
Average Loss: -0.01512
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.98
Average Loss: -0.02826
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.97
Average Loss: -0.03168
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.08
Average Loss: -0.02898
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.5
Average Loss: -0.03614
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.83
Average Loss: -0.03526
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.67
Average Loss: -0.03099
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.9
Average Loss: -0.02454
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.65
Average Loss: -0.02988
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.53
Average Loss: -0.02423
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.22
Average Loss: -0.02688
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.2
Average Loss: -0.0204
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.13
Average Loss: -0.02068
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.95
Average Loss: -0.01875
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.98
Average Loss: -0.01699
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.93
Average Loss: -0.02411
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.65
Average Loss: -0.02364
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.9
Average Loss: -0.01589
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.23
Average Loss: -0.01668
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.9
Average Loss: -0.01485
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.58
Average Loss: -0.01338
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.82
Average Loss: -0.00836
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.35
Average Loss: -0.00985
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.65
Average Loss: -0.00719
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.22
Average Loss: -0.00727
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.95
Average Loss: -0.00778
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.08
Average Loss: -0.00704
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.3
Average Loss: -0.00768
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.0
Average Loss: -0.00828
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.98
Average Loss: -0.00689
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.3
Average Loss: -0.01085
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.8
Average Loss: -0.00785
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.6
Average Loss: -0.0104
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.28
Average Loss: -0.00528
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.73
Average Loss: -0.00422
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.83
Average Loss: -0.00235
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.68
Average Loss: -0.00407
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.72
Average Loss: -0.00457
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.45
Average Loss: -0.00691
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.67
Average Loss: -0.00412
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.78
Average Loss: -0.00499
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.5
Average Loss: -0.00714
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.9
Average Loss: -0.00378
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.83
Average Loss: -0.0065
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.82
Average Loss: -0.00464
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.85
Average Loss: -0.00482
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.], grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 196
Failure Rate: 1.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 196
Failure Rate: 1.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 198
Failure Rate: 0.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 198
Failure Rate: 0.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 198
Failure Rate: 0.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 196
Failure Rate: 1.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 198
Failure Rate: 0.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 198
Failure Rate: 0.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 196
Failure Rate: 1.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 198
Failure Rate: 0.5%
------------------------------------------------------

