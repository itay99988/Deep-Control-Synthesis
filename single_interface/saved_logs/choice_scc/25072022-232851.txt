Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2234, 0.2937, 0.2337, 0.2492], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.0
Average Loss: 0.20084
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2144, 0.3073, 0.2272, 0.2511], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.2
Average Loss: 0.14277
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2014, 0.3285, 0.2175, 0.2526], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.7
Average Loss: 0.03993
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1836, 0.3589, 0.2037, 0.2538], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.1
Average Loss: 0.01568
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1739, 0.3653, 0.1987, 0.2621], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.8
Average Loss: 0.01996
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1701, 0.3565, 0.1989, 0.2745], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.6
Average Loss: 0.03076
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1667, 0.3425, 0.1986, 0.2922], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.5
Average Loss: 0.00175
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1678, 0.3175, 0.1994, 0.3153], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.4
Average Loss: -0.02595
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1635, 0.2957, 0.1930, 0.3477], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.3
Average Loss: -0.04213
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1620, 0.2683, 0.1893, 0.3805], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.3
Average Loss: -0.0473
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1524, 0.2272, 0.1822, 0.4382], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.8
Average Loss: -0.06207
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1132, 0.1468, 0.1513, 0.5887], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.9
Average Loss: -0.0854
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0533, 0.0611, 0.0853, 0.8002], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.9
Average Loss: -0.0871
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0183, 0.0212, 0.0329, 0.9277], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.0
Average Loss: -0.07634
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0068, 0.0078, 0.0129, 0.9725], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.7
Average Loss: -0.03472
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0049, 0.0062, 0.0089, 0.9800], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.5
Average Loss: -0.01785
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0035, 0.0041, 0.0065, 0.9859], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.0
Average Loss: -0.00631
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0026, 0.0030, 0.0049, 0.9895], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.0
Average Loss: -0.00148
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0021, 0.0023, 0.0038, 0.9918], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.0
Average Loss: -0.00115
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0016, 0.0018, 0.0030, 0.9935], grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------

