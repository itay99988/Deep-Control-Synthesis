Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2503, 0.3032, 0.2119, 0.2346], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.4
Average Loss: 0.15134
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2126, 0.3735, 0.1909, 0.2231], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.3
Average Loss: 0.01663
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1594, 0.4778, 0.1605, 0.2023], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.3
Average Loss: 0.00803
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1483, 0.4806, 0.1556, 0.2156], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.5
Average Loss: 0.00759
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1550, 0.4443, 0.1632, 0.2375], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.0
Average Loss: 0.00413
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1662, 0.4016, 0.1741, 0.2581], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.7
Average Loss: -0.01052
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1705, 0.3630, 0.1777, 0.2888], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.8
Average Loss: -0.02278
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1608, 0.3336, 0.1707, 0.3349], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.4
Average Loss: -0.01913
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1474, 0.3053, 0.1611, 0.3862], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.8
Average Loss: -0.02875
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1334, 0.2699, 0.1473, 0.4493], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.2
Average Loss: -0.03458
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1180, 0.2377, 0.1310, 0.5132], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.1
Average Loss: -0.03485
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1072, 0.2137, 0.1190, 0.5600], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.0
Average Loss: -0.04696
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0959, 0.1782, 0.1023, 0.6237], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.8
Average Loss: -0.05251
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0673, 0.1286, 0.0701, 0.7340], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.4
Average Loss: -0.05508
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0308, 0.0659, 0.0319, 0.8714], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.3
Average Loss: -0.03204
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0073, 0.0199, 0.0077, 0.9650], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.9
Average Loss: -0.00173
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0071, 0.0196, 0.0075, 0.9659], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.0
Average Loss: -0.00909
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0073, 0.0198, 0.0075, 0.9654], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.4
Average Loss: 0.0123
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0058, 0.0163, 0.0060, 0.9720], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.5
Average Loss: -0.01223
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0043, 0.0126, 0.0044, 0.9788], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.8
Average Loss: -0.00198
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0030, 0.0095, 0.0032, 0.9844], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.7
Average Loss: -0.0062
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0021, 0.0070, 0.0022, 0.9886], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.7
Average Loss: 0.00092
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0016, 0.0055, 0.0017, 0.9913], grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------

