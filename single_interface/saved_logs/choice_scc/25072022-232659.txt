Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2883, 0.1994, 0.2311, 0.2811], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.3
Average Loss: 0.21908
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2781, 0.1873, 0.2379, 0.2967], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.4
Average Loss: 0.09405
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2831, 0.1675, 0.2302, 0.3191], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.8
Average Loss: 0.0069
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2767, 0.1501, 0.2222, 0.3510], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.7
Average Loss: 0.0039
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2596, 0.1437, 0.2223, 0.3743], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.9
Average Loss: 0.02904
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2420, 0.1352, 0.2195, 0.4033], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.6
Average Loss: 0.02641
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2214, 0.1206, 0.2082, 0.4499], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.8
Average Loss: 0.03355
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1902, 0.1027, 0.1880, 0.5190], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.1
Average Loss: 0.02087
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1642, 0.0876, 0.1675, 0.5807], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.8
Average Loss: 0.00964
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1452, 0.0768, 0.1531, 0.6249], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.0
Average Loss: 0.01043
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1242, 0.0663, 0.1327, 0.6769], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.5
Average Loss: -0.00322
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0924, 0.0494, 0.0905, 0.7677], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.6
Average Loss: -0.0313
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0419, 0.0213, 0.0369, 0.8999], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.2
Average Loss: -0.03595
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0152, 0.0072, 0.0123, 0.9653], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.9
Average Loss: -0.0366
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0073, 0.0033, 0.0056, 0.9838], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.9
Average Loss: -0.03173
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0048, 0.0021, 0.0037, 0.9894], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.7
Average Loss: -0.03512
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0038, 0.0016, 0.0028, 0.9918], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.8
Average Loss: -0.03445
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0030, 0.0012, 0.0023, 0.9935], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.0
Average Loss: -0.03585
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0026, 0.0010, 0.0019, 0.9944], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.0
Average Loss: -0.03585
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.2008e-03, 8.6728e-04, 1.6238e-03, 9.9531e-01],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------

