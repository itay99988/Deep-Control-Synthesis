Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2322, 0.2380, 0.2760, 0.2538], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.1
Average Loss: 0.11862
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2285, 0.2340, 0.2963, 0.2412], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.22
Average Loss: 0.03383
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2240, 0.2223, 0.3274, 0.2263], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.35
Average Loss: -0.00579
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2209, 0.2115, 0.3515, 0.2161], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.23
Average Loss: -0.01555
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2235, 0.2150, 0.3421, 0.2194], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.27
Average Loss: -0.03972
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2263, 0.2254, 0.3221, 0.2262], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.33
Average Loss: -0.06796
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2308, 0.2328, 0.3039, 0.2325], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.1
Average Loss: -0.06999
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2341, 0.2354, 0.2952, 0.2353], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.85
Average Loss: -0.07533
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2381, 0.2381, 0.2918, 0.2320], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.33
Average Loss: -0.07505
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2401, 0.2383, 0.2918, 0.2299], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.5
Average Loss: -0.07939
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2387, 0.2400, 0.2875, 0.2337], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.75
Average Loss: -0.08061
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2398, 0.2406, 0.2853, 0.2343], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.33
Average Loss: -0.07568
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2438, 0.2398, 0.2854, 0.2309], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.12
Average Loss: -0.08018
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2442, 0.2412, 0.2826, 0.2320], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.43
Average Loss: -0.06963
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2493, 0.2412, 0.2823, 0.2272], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.52
Average Loss: -0.07288
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2568, 0.2413, 0.2823, 0.2195], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.43
Average Loss: -0.07685
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2669, 0.2427, 0.2791, 0.2113], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.88
Average Loss: -0.07129
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2733, 0.2435, 0.2771, 0.2061], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.78
Average Loss: -0.07115
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2751, 0.2444, 0.2753, 0.2051], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.95
Average Loss: -0.07298
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2775, 0.2454, 0.2725, 0.2045], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.82
Average Loss: -0.07216
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2814, 0.2470, 0.2695, 0.2021], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.87
Average Loss: -0.06574
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2889, 0.2486, 0.2634, 0.1991], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.17
Average Loss: -0.07302
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2948, 0.2493, 0.2595, 0.1965], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.3
Average Loss: -0.07563
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2995, 0.2496, 0.2560, 0.1949], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.72
Average Loss: -0.0726
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3079, 0.2501, 0.2503, 0.1916], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.7
Average Loss: -0.06939
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3217, 0.2502, 0.2435, 0.1846], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.1
Average Loss: -0.07487
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3265, 0.2500, 0.2378, 0.1858], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.28
Average Loss: -0.06974
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3382, 0.2486, 0.2313, 0.1819], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.2
Average Loss: -0.07666
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3569, 0.2455, 0.2226, 0.1751], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.45
Average Loss: -0.07711
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3764, 0.2413, 0.2138, 0.1685], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.12
Average Loss: -0.07937
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3852, 0.2382, 0.2091, 0.1676], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.65
Average Loss: -0.07425
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4113, 0.2308, 0.2006, 0.1573], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.92
Average Loss: -0.07183
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4320, 0.2237, 0.1927, 0.1516], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.18
Average Loss: -0.07857
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4697, 0.2124, 0.1781, 0.1398], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.97
Average Loss: -0.07423
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5154, 0.1978, 0.1624, 0.1244], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.07
Average Loss: -0.07923
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5802, 0.1773, 0.1402, 0.1024], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.97
Average Loss: -0.07498
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6612, 0.1484, 0.1125, 0.0779], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.62
Average Loss: -0.06756
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7417, 0.1158, 0.0859, 0.0566], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.22
Average Loss: -0.07083
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7915, 0.0939, 0.0697, 0.0449], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.13
Average Loss: -0.06859
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8582, 0.0648, 0.0476, 0.0294], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.55
Average Loss: -0.04362
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8909, 0.0499, 0.0368, 0.0224], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.47
Average Loss: -0.05013
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9391, 0.0285, 0.0206, 0.0118], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.68
Average Loss: -0.05039
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9598, 0.0190, 0.0136, 0.0076], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.15
Average Loss: -0.0489
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9627, 0.0178, 0.0126, 0.0070], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.03
Average Loss: -0.05025
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9656, 0.0165, 0.0116, 0.0063], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.23
Average Loss: -0.04061
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9666, 0.0160, 0.0113, 0.0061], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.68
Average Loss: -0.04501
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9694, 0.0147, 0.0103, 0.0056], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.1
Average Loss: -0.04136
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9720, 0.0135, 0.0095, 0.0050], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.43
Average Loss: -0.04325
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9716, 0.0137, 0.0096, 0.0051], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.17
Average Loss: -0.03729
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9746, 0.0123, 0.0086, 0.0045], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.13
Average Loss: -0.0388
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9786, 0.0105, 0.0072, 0.0037], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.02
Average Loss: -0.03358
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9827, 0.0085, 0.0059, 0.0029], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.97
Average Loss: -0.03341
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9868, 0.0066, 0.0045, 0.0021], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.02
Average Loss: -0.03505
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9886, 0.0057, 0.0038, 0.0018], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.32
Average Loss: -0.03913
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9909, 0.0047, 0.0031, 0.0014], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.22
Average Loss: -0.03307
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9408e-01, 3.0857e-03, 1.9800e-03, 8.5744e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.15
Average Loss: -0.02741
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9678e-01, 1.7114e-03, 1.0658e-03, 4.3964e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.77
Average Loss: -0.02935
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9833e-01, 9.1090e-04, 5.5045e-04, 2.1303e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.35
Average Loss: -0.02963
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9877e-01, 6.7400e-04, 4.0199e-04, 1.5139e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.37
Average Loss: -0.0298
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9906e-01, 5.2103e-04, 3.0705e-04, 1.1287e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.37
Average Loss: -0.02864
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9931e-01, 3.8841e-04, 2.2577e-04, 8.0695e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.38
Average Loss: -0.03016
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9943e-01, 3.1896e-04, 1.8399e-04, 6.4700e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.78
Average Loss: -0.03015
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9948e-01, 2.9254e-04, 1.6842e-04, 5.8982e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.07
Average Loss: -0.02326
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9939e-01, 3.4014e-04, 1.9918e-04, 7.0394e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.18
Average Loss: -0.02272
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9956e-01, 2.4812e-04, 1.4138e-04, 4.9044e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.85
Average Loss: -0.02553
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9971e-01, 1.6385e-04, 9.1252e-05, 3.0483e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.72
Average Loss: -0.02233
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9984e-01, 9.3254e-05, 5.0410e-05, 1.5851e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.32
Average Loss: -0.02668
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9993e-01, 3.9724e-05, 2.0513e-05, 5.8240e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.07
Average Loss: -0.0171
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9995e-01, 2.8005e-05, 1.4044e-05, 3.7956e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.97
Average Loss: -0.01378
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9996e-01, 2.2056e-05, 1.1036e-05, 2.8305e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.25
Average Loss: -0.01768
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9997e-01, 1.7025e-05, 8.4013e-06, 2.1143e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.58
Average Loss: -0.02234
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 9.3129e-06, 4.3803e-06, 1.0465e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.23
Average Loss: -0.01287
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 6.0503e-06, 2.8322e-06, 6.6105e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.33
Average Loss: -0.01647
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 4.5557e-06, 2.1051e-06, 4.7823e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.52
Average Loss: -0.01481
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 2.8491e-06, 1.2846e-06, 2.7729e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.0
Average Loss: -0.02104
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 9.5672e-07, 4.0810e-07, 7.8358e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.13
Average Loss: -0.01031
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.0657e-06, 4.5566e-07, 8.7605e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.88
Average Loss: -0.01
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.5693e-06, 6.8086e-07, 1.3469e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.07
Average Loss: -0.0138
Timesteps So Far: 234000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.8541e-06, 8.4609e-07, 1.6453e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.78
Average Loss: -0.0171
Timesteps So Far: 237000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 2.2493e-06, 1.0653e-06, 2.0715e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.98
Average Loss: -0.02282
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.4405e-06, 7.2050e-07, 1.2491e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.92
Average Loss: -0.02483
Timesteps So Far: 243000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 6.1063e-07, 3.2415e-07, 4.8260e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.68
Average Loss: -0.02686
Timesteps So Far: 246000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 2.6296e-07, 1.5375e-07, 1.9398e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.5
Average Loss: -0.01325
Timesteps So Far: 249000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 3.0806e-07, 2.0622e-07, 2.3924e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.62
Average Loss: -0.02028
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 4.2332e-07, 3.4192e-07, 3.6187e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.8
Average Loss: -0.00841
Timesteps So Far: 255000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 3.7009e-07, 2.8638e-07, 2.9413e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.9
Average Loss: -0.01782
Timesteps So Far: 258000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 3.1287e-07, 2.5820e-07, 2.4326e-08],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------

