Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2649, 0.2458, 0.2505, 0.2388], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.75
Average Loss: 0.10257
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2678, 0.2356, 0.2602, 0.2364], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.63
Average Loss: 0.02348
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2729, 0.2282, 0.2641, 0.2348], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.23
Average Loss: -0.01137
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2763, 0.2263, 0.2622, 0.2353], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.35
Average Loss: -0.03554
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2773, 0.2321, 0.2557, 0.2349], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.47
Average Loss: -0.05458
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2773, 0.2383, 0.2499, 0.2345], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.85
Average Loss: -0.06583
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2766, 0.2404, 0.2480, 0.2350], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.48
Average Loss: -0.06798
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2773, 0.2427, 0.2458, 0.2342], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.57
Average Loss: -0.07116
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2782, 0.2441, 0.2438, 0.2339], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.62
Average Loss: -0.07383
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2788, 0.2456, 0.2421, 0.2334], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.5
Average Loss: -0.07438
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2801, 0.2471, 0.2408, 0.2320], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.95
Average Loss: -0.07625
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2803, 0.2474, 0.2401, 0.2322], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.87
Average Loss: -0.07276
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2808, 0.2480, 0.2395, 0.2317], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.9
Average Loss: -0.07664
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2812, 0.2483, 0.2390, 0.2315], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.23
Average Loss: -0.07034
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2828, 0.2486, 0.2377, 0.2309], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.03
Average Loss: -0.05153
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2840, 0.2481, 0.2371, 0.2307], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.37
Average Loss: -0.02162
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2857, 0.2479, 0.2358, 0.2306], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.1
Average Loss: -0.03258
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2908, 0.2478, 0.2334, 0.2280], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.77
Average Loss: -0.02957
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2958, 0.2468, 0.2311, 0.2263], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.97
Average Loss: -0.01791
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2988, 0.2445, 0.2305, 0.2262], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.65
Average Loss: -0.01699
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3053, 0.2429, 0.2279, 0.2239], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.37
Average Loss: -0.02769
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3155, 0.2411, 0.2234, 0.2201], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.98
Average Loss: -0.01949
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3245, 0.2370, 0.2215, 0.2171], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.93
Average Loss: -0.02859
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3339, 0.2327, 0.2193, 0.2141], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.53
Average Loss: -0.01638
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3463, 0.2302, 0.2160, 0.2075], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.97
Average Loss: -0.01701
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3578, 0.2273, 0.2127, 0.2022], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.47
Average Loss: -0.01478
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3735, 0.2244, 0.2084, 0.1937], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.17
Average Loss: -0.01129
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3746, 0.2250, 0.2069, 0.1935], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.87
Average Loss: -0.01535
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3709, 0.2267, 0.2083, 0.1941], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.52
Average Loss: -0.015
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3760, 0.2268, 0.2053, 0.1919], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.75
Average Loss: -0.00951
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3884, 0.2250, 0.1990, 0.1876], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.83
Average Loss: -0.01551
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3954, 0.2224, 0.1954, 0.1868], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.53
Average Loss: -0.01152
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4069, 0.2192, 0.1926, 0.1813], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.53
Average Loss: -0.01441
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4142, 0.2166, 0.1888, 0.1803], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.78
Average Loss: -0.01385
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4174, 0.2142, 0.1856, 0.1829], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.78
Average Loss: -0.01761
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4307, 0.2096, 0.1801, 0.1797], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.65
Average Loss: -0.011
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4451, 0.2041, 0.1759, 0.1749], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.87
Average Loss: -0.00819
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4739, 0.1940, 0.1658, 0.1663], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.32
Average Loss: -0.00942
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5095, 0.1823, 0.1533, 0.1549], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.47
Average Loss: -0.00937
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5403, 0.1707, 0.1434, 0.1456], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.25
Average Loss: -0.0081
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5795, 0.1580, 0.1305, 0.1320], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.93
Average Loss: -0.00483
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6036, 0.1514, 0.1218, 0.1232], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.15
Average Loss: -0.00567
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6570, 0.1353, 0.1031, 0.1046], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.02
Average Loss: -0.00781
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6945, 0.1233, 0.0899, 0.0922], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.63
Average Loss: -0.00625
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7613, 0.1009, 0.0675, 0.0703], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.52
Average Loss: -0.00802
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8565, 0.0637, 0.0388, 0.0410], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.1
Average Loss: -0.01548
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9513, 0.0234, 0.0121, 0.0132], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.37
Average Loss: -0.02844
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9824, 0.0090, 0.0040, 0.0045], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.27
Average Loss: -0.03416
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9921, 0.0043, 0.0017, 0.0019], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.17
Average Loss: -0.03253
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9544e-01, 2.5480e-03, 9.4531e-04, 1.0633e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.73
Average Loss: -0.0288
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9948, 0.0028, 0.0011, 0.0013], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.98
Average Loss: -0.03415
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9655e-01, 1.9104e-03, 7.2603e-04, 8.1218e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.03
Average Loss: -0.02849
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9769e-01, 1.3090e-03, 4.7057e-04, 5.3060e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.17
Average Loss: -0.03226
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9819e-01, 1.0414e-03, 3.6036e-04, 4.0757e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.92
Average Loss: -0.03144
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9827e-01, 9.9338e-04, 3.4400e-04, 3.8999e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.28
Average Loss: -0.02823
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9844e-01, 9.1101e-04, 3.0535e-04, 3.4546e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.72
Average Loss: -0.02446
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9890e-01, 6.5730e-04, 2.0649e-04, 2.3580e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.42
Average Loss: -0.03078
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9904e-01, 5.7444e-04, 1.7948e-04, 2.0758e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.88
Average Loss: -0.03157
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9829e-01, 9.9977e-04, 3.3281e-04, 3.7567e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.8
Average Loss: -0.03335
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9862e-01, 8.2116e-04, 2.6123e-04, 2.9631e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.78
Average Loss: -0.02539
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9906e-01, 5.6682e-04, 1.7295e-04, 1.9935e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.73
Average Loss: -0.02688
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9919e-01, 4.9951e-04, 1.4549e-04, 1.6680e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.52
Average Loss: -0.02163
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9936e-01, 4.0351e-04, 1.1164e-04, 1.2809e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.77
Average Loss: -0.02661
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9958e-01, 2.7301e-04, 7.0297e-05, 8.1353e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.72
Average Loss: -0.0219
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9947e-01, 3.3522e-04, 9.0657e-05, 1.0432e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.52
Average Loss: -0.02016
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9959e-01, 2.6647e-04, 6.8808e-05, 7.9234e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.12
Average Loss: -0.01861
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9971e-01, 1.9065e-04, 4.5745e-05, 5.2737e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.92
Average Loss: -0.01583
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9975e-01, 1.6519e-04, 3.9613e-05, 4.5790e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.05
Average Loss: -0.01609
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9981e-01, 1.2686e-04, 2.9557e-05, 3.4180e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.72
Average Loss: -0.0149
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9986e-01, 9.5352e-05, 2.1455e-05, 2.4924e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.17
Average Loss: -0.01486
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9986e-01, 9.5752e-05, 2.1959e-05, 2.5483e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.52
Average Loss: -0.01191
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9985e-01, 1.0136e-04, 2.3200e-05, 2.6517e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.67
Average Loss: -0.01405
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9989e-01, 7.5486e-05, 1.6893e-05, 1.9402e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.05
Average Loss: -0.01038
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9988e-01, 7.7134e-05, 1.7657e-05, 2.0209e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.32
Average Loss: -0.00841
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9995e-01, 3.5020e-05, 7.3228e-06, 8.6056e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.48
Average Loss: -0.00939
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9997e-01, 2.0471e-05, 4.0060e-06, 4.7801e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.42
Average Loss: -0.00897
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9998e-01, 1.7333e-05, 3.3116e-06, 3.9518e-06],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 114
Failure Rate: 21.5%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 114
Failure Rate: 21.5%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 114
Failure Rate: 21.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 114
Failure Rate: 21.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 114
Failure Rate: 21.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 114
Failure Rate: 21.5%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 114
Failure Rate: 21.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 114
Failure Rate: 21.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 114
Failure Rate: 21.5%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 114
Failure Rate: 21.5%
------------------------------------------------------

