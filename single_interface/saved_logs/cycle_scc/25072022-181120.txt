Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2133, 0.3054, 0.2516, 0.2297], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.73
Average Loss: 0.13449
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2112, 0.2966, 0.2454, 0.2468], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.07
Average Loss: 0.03819
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2087, 0.3116, 0.2377, 0.2420], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.9
Average Loss: -0.0183
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2058, 0.3156, 0.2369, 0.2417], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.68
Average Loss: -0.02812
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2085, 0.3060, 0.2415, 0.2441], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.32
Average Loss: -0.04322
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2165, 0.2951, 0.2433, 0.2452], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.23
Average Loss: -0.05851
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2224, 0.2875, 0.2439, 0.2462], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.02
Average Loss: -0.06116
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2235, 0.2874, 0.2431, 0.2461], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.72
Average Loss: -0.07228
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2226, 0.2873, 0.2440, 0.2460], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.43
Average Loss: -0.07182
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2246, 0.2867, 0.2432, 0.2455], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.93
Average Loss: -0.07669
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2260, 0.2899, 0.2389, 0.2452], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.63
Average Loss: -0.07474
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2271, 0.2897, 0.2386, 0.2446], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.88
Average Loss: -0.07162
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2313, 0.2890, 0.2368, 0.2429], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.33
Average Loss: -0.07003
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2343, 0.2898, 0.2330, 0.2428], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.62
Average Loss: -0.06761
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2363, 0.2933, 0.2291, 0.2413], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.07
Average Loss: -0.04824
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2408, 0.2913, 0.2288, 0.2391], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.52
Average Loss: -0.02692
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2491, 0.2904, 0.2244, 0.2362], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.5
Average Loss: -0.00262
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2592, 0.2892, 0.2210, 0.2306], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.87
Average Loss: -0.01464
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2727, 0.2907, 0.2146, 0.2220], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.13
Average Loss: -0.00287
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2865, 0.2912, 0.2073, 0.2150], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.83
Average Loss: 0.00388
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3036, 0.2935, 0.1979, 0.2051], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.63
Average Loss: -0.00046
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3259, 0.2958, 0.1857, 0.1926], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.7
Average Loss: 0.00406
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3447, 0.2920, 0.1800, 0.1833], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.43
Average Loss: -0.01085
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3580, 0.2827, 0.1813, 0.1780], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.67
Average Loss: -0.00388
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3831, 0.2807, 0.1691, 0.1671], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.17
Average Loss: 0.00674
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4229, 0.2710, 0.1528, 0.1533], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.97
Average Loss: 0.00319
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4604, 0.2574, 0.1406, 0.1415], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.2
Average Loss: -0.00587
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4969, 0.2414, 0.1311, 0.1306], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.78
Average Loss: -0.00227
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4948, 0.2479, 0.1284, 0.1288], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.13
Average Loss: -0.00467
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5091, 0.2452, 0.1229, 0.1228], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.98
Average Loss: -0.00262
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5762, 0.2159, 0.1044, 0.1035], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.4
Average Loss: 0.00949
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5488, 0.2317, 0.1096, 0.1099], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.22
Average Loss: -0.00822
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5767, 0.2184, 0.1031, 0.1017], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.17
Average Loss: -0.00485
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6085, 0.2048, 0.0943, 0.0924], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.42
Average Loss: -0.00907
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6018, 0.2098, 0.0948, 0.0935], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.88
Average Loss: -0.00624
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6266, 0.1990, 0.0875, 0.0870], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.37
Average Loss: -0.00384
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6891, 0.1688, 0.0710, 0.0712], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.3
Average Loss: 0.00525
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6984, 0.1645, 0.0683, 0.0689], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.33
Average Loss: -0.01181
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7367, 0.1444, 0.0590, 0.0598], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.57
Average Loss: -0.00634
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7786, 0.1227, 0.0486, 0.0501], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.9
Average Loss: -0.00615
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8106, 0.1053, 0.0411, 0.0430], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.27
Average Loss: -0.00655
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8467, 0.0838, 0.0337, 0.0358], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.82
Average Loss: -0.02517
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9367, 0.0367, 0.0127, 0.0139], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.0
Average Loss: -0.02401
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9852, 0.0094, 0.0025, 0.0029], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.12
Average Loss: -0.03927
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9524e-01, 3.1752e-03, 7.3357e-04, 8.5480e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.6
Average Loss: -0.03999
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9750e-01, 1.7086e-03, 3.6467e-04, 4.2470e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.75
Average Loss: -0.03707
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9855e-01, 1.0228e-03, 1.9695e-04, 2.3209e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.28
Average Loss: -0.03826
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9866e-01, 9.6991e-04, 1.7041e-04, 2.0370e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.83
Average Loss: -0.03961
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9877e-01, 9.1123e-04, 1.4479e-04, 1.7619e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.72
Average Loss: -0.04015
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9874e-01, 9.4886e-04, 1.3907e-04, 1.7127e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.63
Average Loss: -0.03855
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9889e-01, 8.4836e-04, 1.1634e-04, 1.4527e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.43
Average Loss: -0.02774
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9895e-01, 8.0504e-04, 1.0897e-04, 1.3643e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.85
Average Loss: -0.03258
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9908e-01, 7.0782e-04, 9.3292e-05, 1.1717e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.38
Average Loss: -0.03464
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9926e-01, 5.7856e-04, 7.2612e-05, 9.1192e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.38
Average Loss: -0.03246
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9931e-01, 5.3993e-04, 6.6583e-05, 8.3338e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.03
Average Loss: -0.03951
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9937e-01, 4.9471e-04, 5.9735e-05, 7.4716e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.12
Average Loss: -0.03492
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9934e-01, 5.1896e-04, 6.2167e-05, 7.8608e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.25
Average Loss: -0.03385
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9953e-01, 3.7147e-04, 4.0936e-05, 5.2617e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.02
Average Loss: -0.0282
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9953e-01, 3.8386e-04, 3.9409e-05, 5.1019e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.08
Average Loss: -0.03253
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9975e-01, 2.0628e-04, 1.9957e-05, 2.6178e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.15
Average Loss: -0.02041
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9924e-01, 6.2850e-04, 5.6145e-05, 7.5504e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.43
Average Loss: -0.02528
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9958e-01, 3.5286e-04, 2.7667e-05, 3.7412e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.27
Average Loss: -0.02384
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9980e-01, 1.6675e-04, 1.2975e-05, 1.7553e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.9
Average Loss: -0.02634
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9992e-01, 6.8939e-05, 5.3267e-06, 7.3413e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.82
Average Loss: -0.01739
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9985e-01, 1.2532e-04, 8.6365e-06, 1.2040e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.37
Average Loss: -0.02027
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9987e-01, 1.1402e-04, 7.2003e-06, 1.0230e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.02
Average Loss: -0.018
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9993e-01, 6.5429e-05, 3.8617e-06, 5.5394e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.2
Average Loss: -0.01379
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9995e-01, 4.0959e-05, 2.2934e-06, 3.3234e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.13
Average Loss: -0.01309
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9997e-01, 2.7459e-05, 1.3969e-06, 2.0232e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.02
Average Loss: -0.01459
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9998e-01, 1.6677e-05, 7.9434e-07, 1.1593e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.42
Average Loss: -0.01122
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9998e-01, 1.4250e-05, 6.1167e-07, 9.0629e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.87
Average Loss: -0.00927
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9998e-01, 1.3896e-05, 5.5959e-07, 8.4095e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.98
Average Loss: -0.00881
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 1.2313e-05, 4.9964e-07, 7.5979e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.15
Average Loss: -0.00967
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 6.8504e-06, 2.5517e-07, 3.8780e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.18
Average Loss: -0.01065
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 4.9811e-06, 1.7545e-07, 2.6742e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.62
Average Loss: -0.00439
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 8.9301e-06, 3.0475e-07, 4.7037e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.48
Average Loss: -0.00626
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 6.1331e-06, 2.0482e-07, 3.2021e-07],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------

