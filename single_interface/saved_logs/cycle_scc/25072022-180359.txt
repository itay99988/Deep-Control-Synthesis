Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2316, 0.2476, 0.2520, 0.2688], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.25
Average Loss: 0.12332
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2268, 0.2581, 0.2541, 0.2610], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.12
Average Loss: 0.05708
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2219, 0.2741, 0.2569, 0.2470], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.92
Average Loss: -0.00694
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2181, 0.2868, 0.2587, 0.2364], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.6
Average Loss: -0.02811
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2208, 0.2784, 0.2572, 0.2437], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.82
Average Loss: -0.04255
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2261, 0.2621, 0.2549, 0.2568], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.92
Average Loss: -0.06151
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2303, 0.2525, 0.2548, 0.2624], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.9
Average Loss: -0.07081
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2324, 0.2491, 0.2552, 0.2634], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.43
Average Loss: -0.07616
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2341, 0.2449, 0.2545, 0.2665], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.8
Average Loss: -0.07047
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2344, 0.2447, 0.2543, 0.2666], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.43
Average Loss: -0.0663
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2347, 0.2450, 0.2540, 0.2663], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.93
Average Loss: -0.04944
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2355, 0.2480, 0.2535, 0.2630], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.57
Average Loss: -0.00533
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2381, 0.2509, 0.2519, 0.2590], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.72
Average Loss: -0.00071
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2433, 0.2534, 0.2506, 0.2527], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.68
Average Loss: -0.01389
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2479, 0.2527, 0.2495, 0.2498], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.7
Average Loss: -0.0113
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2533, 0.2518, 0.2484, 0.2465], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.97
Average Loss: -0.01605
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2596, 0.2452, 0.2485, 0.2467], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.82
Average Loss: -0.01669
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2653, 0.2438, 0.2471, 0.2437], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.35
Average Loss: -0.01661
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2684, 0.2389, 0.2497, 0.2430], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.72
Average Loss: -0.00079
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2739, 0.2324, 0.2533, 0.2404], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.55
Average Loss: -0.01087
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2820, 0.2315, 0.2494, 0.2371], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.67
Average Loss: -0.00669
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2871, 0.2311, 0.2454, 0.2363], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.23
Average Loss: -0.01221
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2877, 0.2309, 0.2400, 0.2414], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.47
Average Loss: -0.00656
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3061, 0.2288, 0.2334, 0.2317], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.38
Average Loss: -0.01317
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3178, 0.2249, 0.2266, 0.2307], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.45
Average Loss: -0.01001
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3097, 0.2235, 0.2231, 0.2437], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.13
Average Loss: -0.01568
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3191, 0.2215, 0.2179, 0.2414], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.85
Average Loss: -0.01318
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3523, 0.2184, 0.2081, 0.2213], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.97
Average Loss: -0.01661
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3909, 0.2141, 0.1954, 0.1995], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.37
Average Loss: -0.01054
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4638, 0.2017, 0.1721, 0.1624], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.9
Average Loss: -0.01819
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5452, 0.1821, 0.1445, 0.1282], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.32
Average Loss: -0.01798
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6752, 0.1432, 0.1011, 0.0805], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.1
Average Loss: -0.01982
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8243, 0.0865, 0.0526, 0.0366], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.2
Average Loss: -0.02756
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9261, 0.0400, 0.0212, 0.0127], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.78
Average Loss: -0.02703
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9674, 0.0188, 0.0090, 0.0048], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.98
Average Loss: -0.02901
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9822, 0.0106, 0.0048, 0.0023], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.68
Average Loss: -0.03064
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9831, 0.0102, 0.0045, 0.0022], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.0
Average Loss: -0.03408
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9856, 0.0088, 0.0038, 0.0018], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.53
Average Loss: -0.03706
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9904, 0.0060, 0.0025, 0.0011], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.62
Average Loss: -0.03287
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9893, 0.0067, 0.0028, 0.0012], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.03
Average Loss: -0.03854
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9894, 0.0066, 0.0028, 0.0012], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.0
Average Loss: -0.03883
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9255e-01, 4.7157e-03, 1.9369e-03, 7.9585e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.97
Average Loss: -0.03634
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9452e-01, 3.5273e-03, 1.4140e-03, 5.4149e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.83
Average Loss: -0.03533
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9407e-01, 3.7648e-03, 1.5562e-03, 6.0584e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.93
Average Loss: -0.03415
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9362e-01, 4.0244e-03, 1.6846e-03, 6.7419e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.62
Average Loss: -0.03409
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9502e-01, 3.1883e-03, 1.3044e-03, 4.9180e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.53
Average Loss: -0.03493
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9580e-01, 2.7102e-03, 1.0901e-03, 3.9810e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.95
Average Loss: -0.03814
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9591e-01, 2.6139e-03, 1.0765e-03, 3.9622e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.57
Average Loss: -0.03087
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9645e-01, 2.2656e-03, 9.4048e-04, 3.4079e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.6
Average Loss: -0.02872
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9586e-01, 2.6078e-03, 1.1140e-03, 4.2102e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.42
Average Loss: -0.03187
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9661e-01, 2.1593e-03, 9.0495e-04, 3.2914e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.15
Average Loss: -0.03166
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9768e-01, 1.5060e-03, 6.0717e-04, 2.0674e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.42
Average Loss: -0.03027
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9848e-01, 9.9961e-04, 3.8967e-04, 1.3184e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.85
Average Loss: -0.03136
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9926e-01, 5.0035e-04, 1.8058e-04, 5.8399e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.35
Average Loss: -0.03152
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9950e-01, 3.4325e-04, 1.1776e-04, 3.7197e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.85
Average Loss: -0.02863
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9945e-01, 3.7833e-04, 1.3092e-04, 4.1520e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.68
Average Loss: -0.03012
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9944e-01, 3.8405e-04, 1.3321e-04, 4.0850e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.72
Average Loss: -0.02983
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9930e-01, 4.7663e-04, 1.7024e-04, 5.2137e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.17
Average Loss: -0.03051
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9927e-01, 4.9519e-04, 1.7854e-04, 5.3130e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.65
Average Loss: -0.02705
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9924e-01, 5.1604e-04, 1.8614e-04, 5.6525e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.03
Average Loss: -0.0259
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9941e-01, 4.0579e-04, 1.4118e-04, 4.3122e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.48
Average Loss: -0.02505
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9955e-01, 3.1234e-04, 1.0473e-04, 3.1505e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.33
Average Loss: -0.02488
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9967e-01, 2.3471e-04, 7.5660e-05, 2.1613e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.28
Average Loss: -0.02402
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9977e-01, 1.6406e-04, 5.0331e-05, 1.3760e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.33
Average Loss: -0.02344
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9975e-01, 1.8076e-04, 5.5759e-05, 1.5458e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.37
Average Loss: -0.0227
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9971e-01, 2.0721e-04, 6.4822e-05, 1.8289e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.4
Average Loss: -0.01968
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9965e-01, 2.5163e-04, 7.8048e-05, 2.2725e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.23
Average Loss: -0.01774
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9889e-01, 7.6783e-04, 2.5475e-04, 8.6286e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.12
Average Loss: -0.01869
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9903e-01, 6.8324e-04, 2.1532e-04, 7.1273e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.37
Average Loss: -0.01684
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9960e-01, 2.8950e-04, 8.4467e-05, 2.4774e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.05
Average Loss: -0.01706
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9952e-01, 3.4524e-04, 1.0334e-04, 3.0962e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.97
Average Loss: -0.02107
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9951e-01, 3.5495e-04, 1.0209e-04, 3.1020e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.25
Average Loss: -0.02119
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9940e-01, 4.2916e-04, 1.2647e-04, 3.9549e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.28
Average Loss: -0.01896
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9960e-01, 2.8170e-04, 8.9783e-05, 2.5861e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.18
Average Loss: -0.01896
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9949e-01, 3.5243e-04, 1.2114e-04, 3.3562e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.78
Average Loss: -0.01661
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9968e-01, 2.2388e-04, 7.3082e-05, 1.9149e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.37
Average Loss: -0.01555
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9980e-01, 1.4717e-04, 4.5156e-05, 1.1470e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.6
Average Loss: -0.0152
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9979e-01, 1.5225e-04, 4.8182e-05, 1.1960e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.52
Average Loss: -0.01227
Timesteps So Far: 234000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9987e-01, 9.7569e-05, 2.9745e-05, 6.4767e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.95
Average Loss: -0.01176
Timesteps So Far: 237000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9991e-01, 6.5571e-05, 1.9034e-05, 4.0717e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.45
Average Loss: -0.00945
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9994e-01, 4.5656e-05, 1.2671e-05, 2.6716e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.92
Average Loss: -0.00846
Timesteps So Far: 243000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9998e-01, 1.7482e-05, 4.3159e-06, 8.4198e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.92
Average Loss: -0.00842
Timesteps So Far: 246000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9998e-01, 1.8483e-05, 4.6656e-06, 8.6364e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.2
Average Loss: -0.00701
Timesteps So Far: 249000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 1.0144e-05, 2.3822e-06, 4.3895e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.57
Average Loss: -0.00525
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 8.0905e-06, 1.8637e-06, 3.2546e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.68
Average Loss: -0.00426
Timesteps So Far: 255000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 6.5579e-06, 1.4730e-06, 2.4477e-07],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------

