Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2592, 0.2746, 0.2401, 0.2261], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.67
Average Loss: 0.10379
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2581, 0.2828, 0.2370, 0.2221], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.82
Average Loss: 0.01642
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2568, 0.2940, 0.2322, 0.2171], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.28
Average Loss: -0.01018
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2572, 0.2945, 0.2319, 0.2165], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.17
Average Loss: -0.02414
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2596, 0.2873, 0.2338, 0.2192], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.57
Average Loss: -0.04621
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2615, 0.2784, 0.2374, 0.2228], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.7
Average Loss: -0.06058
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2625, 0.2727, 0.2398, 0.2251], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.62
Average Loss: -0.06864
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2629, 0.2695, 0.2415, 0.2262], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.48
Average Loss: -0.07378
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2635, 0.2688, 0.2412, 0.2265], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.88
Average Loss: -0.07374
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2641, 0.2675, 0.2414, 0.2269], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.52
Average Loss: -0.07063
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2648, 0.2677, 0.2409, 0.2266], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.98
Average Loss: -0.07605
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2659, 0.2667, 0.2410, 0.2265], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.72
Average Loss: -0.0757
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2673, 0.2661, 0.2404, 0.2262], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.47
Average Loss: -0.06751
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2683, 0.2670, 0.2393, 0.2255], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.97
Average Loss: -0.07399
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2691, 0.2685, 0.2379, 0.2246], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.07
Average Loss: -0.07535
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2704, 0.2694, 0.2364, 0.2238], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.33
Average Loss: -0.06866
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2715, 0.2693, 0.2359, 0.2233], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.35
Average Loss: -0.07231
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2738, 0.2692, 0.2348, 0.2222], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.02
Average Loss: -0.06588
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2761, 0.2696, 0.2334, 0.2210], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.85
Average Loss: -0.04278
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2798, 0.2689, 0.2318, 0.2195], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.53
Average Loss: -0.01308
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2836, 0.2723, 0.2279, 0.2163], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.02
Average Loss: -0.01018
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2885, 0.2746, 0.2243, 0.2126], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.8
Average Loss: -0.00584
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2945, 0.2753, 0.2212, 0.2090], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.4
Average Loss: -0.0076
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3020, 0.2765, 0.2168, 0.2047], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.85
Average Loss: -0.00912
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3142, 0.2741, 0.2120, 0.1997], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.72
Average Loss: -0.00024
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3277, 0.2739, 0.2051, 0.1933], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.68
Average Loss: -0.0081
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3427, 0.2721, 0.1983, 0.1870], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.17
Average Loss: -0.00128
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3568, 0.2688, 0.1932, 0.1812], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.68
Average Loss: -0.00518
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3691, 0.2669, 0.1885, 0.1754], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.98
Average Loss: 0.00257
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3857, 0.2646, 0.1815, 0.1682], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.05
Average Loss: 0.0056
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4063, 0.2619, 0.1722, 0.1595], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.0
Average Loss: 0.00362
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4330, 0.2551, 0.1620, 0.1499], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.55
Average Loss: 0.00305
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4636, 0.2452, 0.1512, 0.1400], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.35
Average Loss: -0.00248
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4921, 0.2351, 0.1415, 0.1313], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.23
Average Loss: 0.00725
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5339, 0.2213, 0.1281, 0.1167], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.23
Average Loss: 0.0017
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5584, 0.2103, 0.1200, 0.1113], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.42
Average Loss: 0.01069
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5943, 0.1970, 0.1085, 0.1002], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.58
Average Loss: -0.00308
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6122, 0.1896, 0.1028, 0.0954], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.05
Average Loss: 0.00575
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6357, 0.1800, 0.0957, 0.0886], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.53
Average Loss: 0.00176
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6623, 0.1681, 0.0881, 0.0815], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.85
Average Loss: 0.00314
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6848, 0.1581, 0.0817, 0.0755], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.73
Average Loss: -0.00101
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7155, 0.1435, 0.0733, 0.0677], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.77
Average Loss: 0.00511
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7413, 0.1311, 0.0663, 0.0613], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.93
Average Loss: 0.00376
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7556, 0.1244, 0.0624, 0.0577], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.1
Average Loss: 0.00073
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7690, 0.1182, 0.0586, 0.0542], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.7
Average Loss: 0.00643
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7799, 0.1129, 0.0557, 0.0516], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.27
Average Loss: 0.00337
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8012, 0.1022, 0.0501, 0.0464], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.98
Average Loss: 0.00237
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8077, 0.0987, 0.0486, 0.0450], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.48
Average Loss: 0.00797
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7977, 0.1035, 0.0514, 0.0475], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.35
Average Loss: 0.00513
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7989, 0.1026, 0.0512, 0.0473], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.03
Average Loss: 0.0027
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8083, 0.0974, 0.0489, 0.0453], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.4
Average Loss: -4e-05
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8229, 0.0901, 0.0451, 0.0419], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.88
Average Loss: 0.00812
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8399, 0.0816, 0.0407, 0.0378], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.05
Average Loss: 0.00573
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8482, 0.0776, 0.0385, 0.0357], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.58
Average Loss: 0.00861
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8622, 0.0702, 0.0351, 0.0325], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.65
Average Loss: 0.00982
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8652, 0.0684, 0.0345, 0.0318], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.45
Average Loss: 0.00898
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8763, 0.0626, 0.0318, 0.0293], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.97
Average Loss: 0.01669
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8843, 0.0583, 0.0299, 0.0274], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.52
Average Loss: 0.01792
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8942, 0.0531, 0.0276, 0.0252], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.75
Average Loss: 0.0065
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9011, 0.0497, 0.0259, 0.0233], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.65
Average Loss: 0.0081
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8938, 0.0539, 0.0278, 0.0245], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.38
Average Loss: -0.00784
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8867, 0.0585, 0.0295, 0.0253], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.33
Average Loss: 0.00361
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8806, 0.0624, 0.0308, 0.0262], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.3
Average Loss: 0.01308
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8828, 0.0613, 0.0302, 0.0257], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.03
Average Loss: 0.00894
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8859, 0.0597, 0.0293, 0.0251], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.62
Average Loss: 0.0127
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8826, 0.0616, 0.0299, 0.0260], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.4
Average Loss: 0.00995
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8825, 0.0618, 0.0296, 0.0261], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.43
Average Loss: 0.00824
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8897, 0.0583, 0.0276, 0.0244], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.82
Average Loss: 0.00806
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8969, 0.0547, 0.0257, 0.0228], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.92
Average Loss: -0.00216
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9008, 0.0530, 0.0244, 0.0219], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.78
Average Loss: -0.00014
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9004, 0.0537, 0.0240, 0.0219], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.4
Average Loss: -0.00168
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9068, 0.0509, 0.0219, 0.0204], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.83
Average Loss: 0.00468
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9039, 0.0528, 0.0221, 0.0211], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.28
Average Loss: 0.01689
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9213, 0.0430, 0.0182, 0.0175], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.0
Average Loss: 0.02648
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9439, 0.0303, 0.0130, 0.0128], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.85
Average Loss: -0.00507
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9646, 0.0190, 0.0081, 0.0083], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.58
Average Loss: 0.00405
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9813, 0.0101, 0.0042, 0.0044], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.77
Average Loss: 0.00819
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9942, 0.0032, 0.0013, 0.0014], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.88
Average Loss: -0.00993
Timesteps So Far: 234000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9931e-01, 3.9211e-04, 1.4307e-04, 1.5492e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.65
Average Loss: -0.01888
Timesteps So Far: 237000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9986e-01, 8.3754e-05, 2.8673e-05, 3.1312e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.72
Average Loss: -0.0278
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9995e-01, 2.7735e-05, 8.9712e-06, 9.9712e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.88
Average Loss: -0.03249
Timesteps So Far: 243000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9998e-01, 1.5037e-05, 4.6855e-06, 5.2723e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.77
Average Loss: -0.02994
Timesteps So Far: 246000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9997e-01, 2.0027e-05, 6.4485e-06, 7.0480e-06],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------

