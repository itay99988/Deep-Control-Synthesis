Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2495, 0.2258, 0.2654, 0.2593], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.38
Average Loss: 0.1417
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2505, 0.2332, 0.2617, 0.2546], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.12
Average Loss: 0.08631
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2502, 0.2280, 0.2644, 0.2574], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.78
Average Loss: 0.00534
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2490, 0.2152, 0.2708, 0.2651], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.27
Average Loss: -0.01541
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2502, 0.2122, 0.2719, 0.2656], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.38
Average Loss: -0.02301
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2540, 0.2124, 0.2705, 0.2631], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.8
Average Loss: -0.03447
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2583, 0.2115, 0.2706, 0.2596], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.93
Average Loss: -0.05924
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2589, 0.2150, 0.2708, 0.2553], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.33
Average Loss: -0.07372
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2598, 0.2145, 0.2718, 0.2539], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.3
Average Loss: -0.07813
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2600, 0.2152, 0.2717, 0.2531], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.07
Average Loss: -0.07218
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2604, 0.2159, 0.2721, 0.2516], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.03
Average Loss: -0.07208
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2614, 0.2149, 0.2732, 0.2504], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.83
Average Loss: -0.07446
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2626, 0.2142, 0.2725, 0.2508], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.28
Average Loss: -0.07619
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2636, 0.2139, 0.2711, 0.2514], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.95
Average Loss: -0.07518
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2647, 0.2137, 0.2710, 0.2505], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.13
Average Loss: -0.07427
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2665, 0.2118, 0.2729, 0.2488], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.78
Average Loss: -0.07827
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2681, 0.2107, 0.2725, 0.2488], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.78
Average Loss: -0.07093
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2690, 0.2105, 0.2739, 0.2466], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.48
Average Loss: -0.07163
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2703, 0.2111, 0.2724, 0.2462], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.87
Average Loss: -0.07514
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2732, 0.2091, 0.2725, 0.2452], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.43
Average Loss: -0.07478
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2897, 0.1986, 0.2743, 0.2374], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.8
Average Loss: -0.06926
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2963, 0.2007, 0.2699, 0.2331], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.38
Average Loss: -0.07478
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3082, 0.1994, 0.2626, 0.2298], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.77
Average Loss: -0.07096
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3119, 0.2018, 0.2585, 0.2279], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.0
Average Loss: -0.0687
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3139, 0.2035, 0.2599, 0.2227], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.68
Average Loss: -0.0743
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3110, 0.2043, 0.2593, 0.2254], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.18
Average Loss: -0.0711
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3185, 0.2042, 0.2554, 0.2220], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.23
Average Loss: -0.07392
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3229, 0.2021, 0.2548, 0.2202], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.23
Average Loss: -0.07583
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3317, 0.1999, 0.2523, 0.2161], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.3
Average Loss: -0.06559
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3335, 0.2014, 0.2512, 0.2139], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.08
Average Loss: -0.07176
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3447, 0.2009, 0.2459, 0.2085], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.55
Average Loss: -0.06841
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3651, 0.1967, 0.2404, 0.1977], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.57
Average Loss: -0.06451
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3790, 0.1930, 0.2369, 0.1911], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.35
Average Loss: -0.07041
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3807, 0.1924, 0.2359, 0.1910], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.03
Average Loss: -0.06385
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3929, 0.1912, 0.2286, 0.1874], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.38
Average Loss: -0.06476
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4122, 0.1857, 0.2228, 0.1794], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.45
Average Loss: -0.04494
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4170, 0.1806, 0.2259, 0.1764], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.0
Average Loss: -0.04557
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4468, 0.1706, 0.2186, 0.1640], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.6
Average Loss: -0.04089
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4749, 0.1629, 0.2076, 0.1547], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.9
Average Loss: -0.03345
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4979, 0.1547, 0.1994, 0.1479], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.32
Average Loss: -0.04024
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5451, 0.1415, 0.1791, 0.1344], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.4
Average Loss: -0.04309
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5925, 0.1268, 0.1602, 0.1205], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.9
Average Loss: -0.04337
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6752, 0.1010, 0.1283, 0.0954], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.58
Average Loss: -0.04559
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7979, 0.0634, 0.0805, 0.0583], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.23
Average Loss: -0.02995
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8338, 0.0512, 0.0660, 0.0490], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.83
Average Loss: -0.02777
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9255, 0.0230, 0.0300, 0.0215], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.6
Average Loss: -0.0373
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9793, 0.0066, 0.0085, 0.0056], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.05
Average Loss: -0.03198
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9906, 0.0030, 0.0039, 0.0025], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.85
Average Loss: -0.03215
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9952, 0.0015, 0.0020, 0.0013], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.35
Average Loss: -0.03419
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9744e-01, 8.1447e-04, 1.0815e-03, 6.6532e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.6
Average Loss: -0.02161
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9813e-01, 6.0524e-04, 7.8849e-04, 4.7977e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.32
Average Loss: -0.03128
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9882e-01, 3.8264e-04, 5.0333e-04, 2.9863e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.4
Average Loss: -0.02846
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9921e-01, 2.5615e-04, 3.3638e-04, 1.9456e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.2
Average Loss: -0.02559
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9931e-01, 2.2107e-04, 2.9518e-04, 1.7314e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.9
Average Loss: -0.02253
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9928e-01, 2.3271e-04, 3.0337e-04, 1.8017e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.87
Average Loss: -0.02505
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9937e-01, 2.0671e-04, 2.6484e-04, 1.5643e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.37
Average Loss: -0.02285
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9933e-01, 2.2956e-04, 2.7566e-04, 1.6691e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.8
Average Loss: -0.02675
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9940e-01, 2.0629e-04, 2.4562e-04, 1.4788e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.18
Average Loss: -0.02985
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9933e-01, 2.3676e-04, 2.6712e-04, 1.6140e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.87
Average Loss: -0.02263
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9953e-01, 1.6652e-04, 1.9254e-04, 1.1178e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.52
Average Loss: -0.01995
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9959e-01, 1.4517e-04, 1.7084e-04, 9.7239e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.52
Average Loss: -0.03021
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9954e-01, 1.6902e-04, 1.8676e-04, 1.0916e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.82
Average Loss: -0.03029
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9943e-01, 2.1574e-04, 2.2431e-04, 1.3456e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.13
Average Loss: -0.02754
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9973e-01, 1.0088e-04, 1.1220e-04, 6.1691e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.92
Average Loss: -0.02408
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9986e-01, 4.8846e-05, 5.7323e-05, 2.9264e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.57
Average Loss: -0.01931
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9982e-01, 6.7820e-05, 7.5350e-05, 4.0102e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.2
Average Loss: -0.02093
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9984e-01, 6.1210e-05, 6.7426e-05, 3.5581e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.05
Average Loss: -0.01588
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9992e-01, 2.9211e-05, 3.3743e-05, 1.6411e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.98
Average Loss: -0.01689
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9996e-01, 1.4085e-05, 1.8045e-05, 8.0758e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.62
Average Loss: -0.01512
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9998e-01, 6.2746e-06, 8.0921e-06, 3.3170e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.17
Average Loss: -0.01423
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9998e-01, 5.5454e-06, 7.3377e-06, 3.0084e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.68
Average Loss: -0.01472
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 3.6397e-06, 4.9504e-06, 1.9695e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.25
Average Loss: -0.01136
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 2.6258e-06, 3.5762e-06, 1.3802e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.25
Average Loss: -0.01753
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 1.9401e-06, 2.6528e-06, 1.0028e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.72
Average Loss: -0.0135
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9998e-01, 5.6339e-06, 7.1054e-06, 3.0164e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.4
Average Loss: -0.01664
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 2.4473e-06, 3.3256e-06, 1.2898e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.37
Average Loss: -0.01197
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.3414e-06, 1.9061e-06, 7.1455e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.72
Average Loss: -0.01202
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 6.5174e-07, 9.3008e-07, 3.3391e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.35
Average Loss: -0.00914
Timesteps So Far: 234000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 2.9232e-07, 4.2975e-07, 1.4975e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.95
Average Loss: -0.01095
Timesteps So Far: 237000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.1137e-07, 1.6492e-07, 5.4490e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.48
Average Loss: -0.00617
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 4.2251e-08, 6.2597e-08, 1.9612e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.37
Average Loss: -0.00796
Timesteps So Far: 243000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.8210e-08, 2.7083e-08, 8.1146e-09],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.07
Average Loss: -0.00526
Timesteps So Far: 246000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.3636e-08, 2.0216e-08, 5.9339e-09],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.07
Average Loss: -0.0056
Timesteps So Far: 249000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 2.3453e-08, 3.4988e-08, 1.0597e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.3
Average Loss: -0.00723
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.2321e-08, 1.8449e-08, 5.3118e-09],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.42
Average Loss: -0.00733
Timesteps So Far: 255000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 6.0206e-09, 9.0757e-09, 2.4501e-09],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.78
Average Loss: -0.00575
Timesteps So Far: 258000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 3.7957e-09, 5.6419e-09, 1.4694e-09],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------

