Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2174, 0.2603, 0.2340, 0.2882], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.27
Average Loss: 0.14438
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2214, 0.2463, 0.2367, 0.2955], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.65
Average Loss: 0.07012
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2330, 0.2315, 0.2232, 0.3123], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.32
Average Loss: -0.01362
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2284, 0.2303, 0.2300, 0.3114], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.23
Average Loss: -0.04864
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2184, 0.2413, 0.2392, 0.3012], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.55
Average Loss: -0.06006
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2114, 0.2487, 0.2443, 0.2955], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.68
Average Loss: -0.07256
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2109, 0.2497, 0.2448, 0.2946], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.7
Average Loss: -0.0723
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2090, 0.2511, 0.2453, 0.2946], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.2
Average Loss: -0.07586
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2079, 0.2524, 0.2456, 0.2941], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.77
Average Loss: -0.07641
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2069, 0.2541, 0.2461, 0.2930], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.33
Average Loss: -0.07786
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2069, 0.2557, 0.2463, 0.2912], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.0
Average Loss: -0.07224
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2090, 0.2548, 0.2454, 0.2908], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.22
Average Loss: -0.05199
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2144, 0.2510, 0.2426, 0.2920], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.33
Average Loss: -0.00023
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2280, 0.2403, 0.2339, 0.2978], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.05
Average Loss: -0.00849
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2406, 0.2339, 0.2254, 0.3002], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.3
Average Loss: -0.02374
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2426, 0.2415, 0.2275, 0.2885], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.3
Average Loss: 0.00021
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2486, 0.2465, 0.2257, 0.2792], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.33
Average Loss: -0.02617
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2343, 0.2518, 0.2281, 0.2858], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.75
Average Loss: -0.00093
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2381, 0.2540, 0.2263, 0.2817], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.77
Average Loss: -0.00644
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2454, 0.2547, 0.2232, 0.2767], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.9
Average Loss: -0.01446
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2563, 0.2534, 0.2183, 0.2720], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.03
Average Loss: -0.00725
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2615, 0.2554, 0.2158, 0.2673], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.83
Average Loss: -0.00509
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2682, 0.2568, 0.2123, 0.2627], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.55
Average Loss: -0.01416
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2713, 0.2606, 0.2096, 0.2585], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.63
Average Loss: -0.01135
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2742, 0.2647, 0.2071, 0.2540], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.8
Average Loss: -0.00329
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2746, 0.2685, 0.2064, 0.2504], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.98
Average Loss: -0.00819
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2732, 0.2726, 0.2065, 0.2477], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.93
Average Loss: -0.00752
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2751, 0.2749, 0.2053, 0.2446], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.58
Average Loss: -0.01058
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2754, 0.2744, 0.2064, 0.2437], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.5
Average Loss: -0.01508
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2819, 0.2726, 0.2050, 0.2406], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.98
Average Loss: -0.01201
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2862, 0.2754, 0.2018, 0.2366], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.15
Average Loss: -0.01677
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2939, 0.2814, 0.1955, 0.2291], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.25
Average Loss: -0.01738
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2989, 0.2849, 0.1920, 0.2242], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.77
Average Loss: -0.02537
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3052, 0.2875, 0.1881, 0.2192], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.43
Average Loss: -0.01394
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3179, 0.2885, 0.1820, 0.2116], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.67
Average Loss: -0.01635
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3394, 0.2873, 0.1727, 0.2006], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.77
Average Loss: -0.02464
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3776, 0.2829, 0.1570, 0.1825], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.22
Average Loss: -0.02701
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4566, 0.2673, 0.1277, 0.1484], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.33
Average Loss: -0.02816
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6097, 0.2190, 0.0792, 0.0921], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.62
Average Loss: -0.03421
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7520, 0.1580, 0.0414, 0.0486], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.65
Average Loss: -0.02905
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7949, 0.1445, 0.0277, 0.0329], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.38
Average Loss: -0.03219
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8590, 0.1069, 0.0155, 0.0186], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.28
Average Loss: -0.03442
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9087, 0.0708, 0.0093, 0.0112], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.4
Average Loss: -0.03071
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9441, 0.0428, 0.0059, 0.0072], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.88
Average Loss: -0.03244
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9637, 0.0274, 0.0040, 0.0049], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.6
Average Loss: -0.03273
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9658, 0.0251, 0.0041, 0.0050], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.9
Average Loss: -0.03154
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9633, 0.0264, 0.0046, 0.0057], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.07
Average Loss: -0.0314
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9660, 0.0242, 0.0044, 0.0054], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.17
Average Loss: -0.03155
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9724, 0.0196, 0.0036, 0.0045], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.63
Average Loss: -0.02999
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9771, 0.0161, 0.0030, 0.0037], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.28
Average Loss: -0.03328
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9812, 0.0132, 0.0025, 0.0031], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.97
Average Loss: -0.02967
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9833, 0.0117, 0.0022, 0.0028], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.62
Average Loss: -0.03395
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9863, 0.0095, 0.0018, 0.0023], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.55
Average Loss: -0.03024
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9887, 0.0079, 0.0015, 0.0019], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.73
Average Loss: -0.03195
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9909, 0.0064, 0.0012, 0.0015], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.87
Average Loss: -0.03371
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9218e-01, 5.5456e-03, 9.8289e-04, 1.2914e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.9
Average Loss: -0.03324
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9260e-01, 5.2415e-03, 9.2627e-04, 1.2302e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.08
Average Loss: -0.03061
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9236e-01, 5.3815e-03, 9.6849e-04, 1.2881e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.25
Average Loss: -0.02855
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9265e-01, 5.1677e-03, 9.3422e-04, 1.2465e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.37
Average Loss: -0.0302
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9922, 0.0055, 0.0010, 0.0013], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.53
Average Loss: -0.02972
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9922, 0.0054, 0.0010, 0.0013], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.45
Average Loss: -0.02235
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9273e-01, 5.0714e-03, 9.3601e-04, 1.2643e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.5
Average Loss: -0.03389
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9311e-01, 4.7952e-03, 8.9377e-04, 1.2007e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.58
Average Loss: -0.02424
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9401e-01, 4.1741e-03, 7.7273e-04, 1.0412e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.9
Average Loss: -0.02004
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9359e-01, 4.4189e-03, 8.4565e-04, 1.1406e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.43
Average Loss: -0.02653
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9281e-01, 4.8941e-03, 9.7285e-04, 1.3198e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.48
Average Loss: -0.01799
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9924, 0.0051, 0.0010, 0.0014], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.33
Average Loss: -0.01632
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9291e-01, 4.7365e-03, 9.8841e-04, 1.3672e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.75
Average Loss: -0.01732
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9444e-01, 3.7180e-03, 7.6815e-04, 1.0698e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.7
Average Loss: -0.01461
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9520e-01, 3.1974e-03, 6.6672e-04, 9.3707e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.65
Average Loss: -0.01605
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9641e-01, 2.3961e-03, 4.9663e-04, 7.0228e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.28
Average Loss: -0.01092
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9746e-01, 1.6965e-03, 3.4708e-04, 4.9395e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.45
Average Loss: -0.00967
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9808e-01, 1.2890e-03, 2.6384e-04, 3.7192e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.07
Average Loss: -0.00694
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9825e-01, 1.1640e-03, 2.4190e-04, 3.4323e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.25
Average Loss: -0.00791
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9839e-01, 1.0628e-03, 2.2438e-04, 3.1862e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.38
Average Loss: -0.00876
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9881e-01, 7.8867e-04, 1.6368e-04, 2.3445e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.28
Average Loss: -0.00726
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9910e-01, 6.0134e-04, 1.2198e-04, 1.7618e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.57
Average Loss: -0.00789
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9920e-01, 5.3454e-04, 1.0768e-04, 1.5551e-04],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------

