Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2619, 0.2327, 0.2581, 0.2473], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.62
Average Loss: 0.10563
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2601, 0.2359, 0.2517, 0.2523], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.45
Average Loss: 0.03899
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2605, 0.2384, 0.2405, 0.2607], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.1
Average Loss: -0.01016
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2597, 0.2444, 0.2354, 0.2605], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.15
Average Loss: -0.03099
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2615, 0.2401, 0.2437, 0.2547], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.57
Average Loss: -0.05258
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2630, 0.2313, 0.2576, 0.2481], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.87
Average Loss: -0.06013
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2638, 0.2290, 0.2603, 0.2468], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.77
Average Loss: -0.06257
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2651, 0.2247, 0.2640, 0.2462], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.53
Average Loss: -0.06889
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2661, 0.2230, 0.2633, 0.2476], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.17
Average Loss: -0.07365
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2677, 0.2208, 0.2641, 0.2474], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.78
Average Loss: -0.07658
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2687, 0.2188, 0.2646, 0.2479], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.28
Average Loss: -0.0788
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2696, 0.2172, 0.2658, 0.2474], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.38
Average Loss: -0.07182
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2738, 0.2132, 0.2649, 0.2481], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.6
Average Loss: -0.07628
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2790, 0.2112, 0.2636, 0.2462], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.77
Average Loss: -0.07467
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2868, 0.2081, 0.2603, 0.2449], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.75
Average Loss: -0.0715
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2975, 0.2061, 0.2532, 0.2432], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.25
Average Loss: -0.07884
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3186, 0.2000, 0.2413, 0.2401], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.1
Average Loss: -0.07455
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3549, 0.1901, 0.2227, 0.2323], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.13
Average Loss: -0.07118
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4016, 0.1782, 0.2021, 0.2181], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.82
Average Loss: -0.07137
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4331, 0.1734, 0.1893, 0.2042], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.58
Average Loss: -0.06954
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4962, 0.1621, 0.1621, 0.1795], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.43
Average Loss: -0.06874
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5549, 0.1486, 0.1396, 0.1569], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.12
Average Loss: -0.06248
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6555, 0.1193, 0.1032, 0.1221], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.48
Average Loss: -0.06239
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7554, 0.0874, 0.0701, 0.0871], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.53
Average Loss: -0.06571
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8654, 0.0523, 0.0356, 0.0467], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.95
Average Loss: -0.04537
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9186, 0.0329, 0.0205, 0.0279], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.42
Average Loss: -0.04544
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9349, 0.0267, 0.0161, 0.0223], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.22
Average Loss: -0.04574
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9286, 0.0291, 0.0177, 0.0246], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.83
Average Loss: -0.05983
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9393, 0.0251, 0.0148, 0.0208], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.87
Average Loss: -0.04511
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9528, 0.0198, 0.0113, 0.0161], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.62
Average Loss: -0.04372
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9585, 0.0176, 0.0098, 0.0141], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.98
Average Loss: -0.04612
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9578, 0.0178, 0.0099, 0.0145], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.18
Average Loss: -0.045
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9634, 0.0155, 0.0086, 0.0126], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.48
Average Loss: -0.05059
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9689, 0.0132, 0.0073, 0.0107], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.23
Average Loss: -0.04899
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9767, 0.0100, 0.0054, 0.0079], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.45
Average Loss: -0.05577
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9805, 0.0085, 0.0045, 0.0065], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.3
Average Loss: -0.04868
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9824, 0.0077, 0.0040, 0.0059], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.68
Average Loss: -0.0501
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9813, 0.0082, 0.0043, 0.0062], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.2
Average Loss: -0.05456
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9857, 0.0064, 0.0032, 0.0047], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.47
Average Loss: -0.05192
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9860, 0.0062, 0.0031, 0.0046], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.63
Average Loss: -0.05075
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9855, 0.0064, 0.0033, 0.0048], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.32
Average Loss: -0.04757
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9907, 0.0042, 0.0020, 0.0030], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.25
Average Loss: -0.05432
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9897, 0.0046, 0.0023, 0.0034], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.27
Average Loss: -0.05061
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9909, 0.0041, 0.0020, 0.0030], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.35
Average Loss: -0.04353
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9929, 0.0032, 0.0015, 0.0023], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.93
Average Loss: -0.0433
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9928, 0.0033, 0.0016, 0.0024], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.18
Average Loss: -0.04107
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9949, 0.0024, 0.0011, 0.0017], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.58
Average Loss: -0.03988
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9556e-01, 2.0670e-03, 9.3706e-04, 1.4372e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.98
Average Loss: -0.0345
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9720e-01, 1.3621e-03, 5.5785e-04, 8.7885e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.6
Average Loss: -0.03391
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9831e-01, 8.4139e-04, 3.2207e-04, 5.2316e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.73
Average Loss: -0.03365
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9917e-01, 4.2567e-04, 1.4916e-04, 2.5332e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.8
Average Loss: -0.02947
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9954e-01, 2.4514e-04, 7.9579e-05, 1.4030e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.87
Average Loss: -0.03272
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9964e-01, 1.9497e-04, 6.0971e-05, 1.0780e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.33
Average Loss: -0.031
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9973e-01, 1.4699e-04, 4.3967e-05, 7.7152e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.6
Average Loss: -0.03542
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9978e-01, 1.2159e-04, 3.6438e-05, 6.4295e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.75
Average Loss: -0.03454
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9980e-01, 1.0889e-04, 3.2420e-05, 5.6834e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.97
Average Loss: -0.03408
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9984e-01, 8.7660e-05, 2.4762e-05, 4.3673e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.18
Average Loss: -0.03325
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9990e-01, 5.8331e-05, 1.5341e-05, 2.7915e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.0
Average Loss: -0.03
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9990e-01, 5.8050e-05, 1.5189e-05, 2.7295e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.58
Average Loss: -0.02974
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9994e-01, 3.3127e-05, 7.9134e-06, 1.4807e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.07
Average Loss: -0.02937
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9996e-01, 2.5969e-05, 6.0518e-06, 1.1563e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.92
Average Loss: -0.02965
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9997e-01, 2.0037e-05, 4.4973e-06, 8.8552e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.88
Average Loss: -0.02281
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9997e-01, 2.0299e-05, 4.3855e-06, 8.3565e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.35
Average Loss: -0.03013
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9997e-01, 1.5915e-05, 3.2969e-06, 6.3336e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.32
Average Loss: -0.02407
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 9.3398e-06, 1.7849e-06, 3.6438e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.97
Average Loss: -0.02119
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 5.2539e-06, 9.1875e-07, 1.9534e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.48
Average Loss: -0.02511
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 2.7579e-06, 4.4226e-07, 1.0004e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.47
Average Loss: -0.02187
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 2.1318e-06, 3.1729e-07, 7.5948e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.45
Average Loss: -0.01764
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.9880e-06, 2.9974e-07, 7.0872e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.47
Average Loss: -0.01728
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.1698e-06, 1.7272e-07, 3.9715e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.93
Average Loss: -0.01687
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 7.7016e-07, 1.0693e-07, 2.5330e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.03
Average Loss: -0.02263
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 5.8156e-07, 7.6171e-08, 1.9347e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.6
Average Loss: -0.01919
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 6.1343e-07, 8.5898e-08, 2.1547e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.45
Average Loss: -0.01804
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 4.1219e-07, 5.5250e-08, 1.4071e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.65
Average Loss: -0.01237
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 3.4623e-07, 4.5615e-08, 1.2199e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.08
Average Loss: -0.0141
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.6565e-07, 1.9415e-08, 5.4651e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.27
Average Loss: -0.01605
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 8.6406e-08, 9.4526e-09, 2.8343e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.83
Average Loss: -0.00688
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 6.4569e-08, 6.3845e-09, 2.0562e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.9
Average Loss: -0.00815
Timesteps So Far: 234000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 4.5607e-08, 4.3808e-09, 1.4482e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.45
Average Loss: -0.00747
Timesteps So Far: 237000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 2.5784e-08, 2.3640e-09, 8.1293e-09],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.85
Average Loss: -0.00525
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.3529e-08, 1.1066e-09, 3.9757e-09],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.72
Average Loss: -0.0059
Timesteps So Far: 243000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 6.7362e-09, 5.0996e-10, 1.9533e-09],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.05
Average Loss: -0.00545
Timesteps So Far: 246000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 2.6224e-09, 1.8952e-10, 7.5731e-10],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.4
Average Loss: -0.00377
Timesteps So Far: 249000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 3.2714e-09, 2.0496e-10, 9.0669e-10],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.32
Average Loss: -0.00593
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.7540e-09, 1.1890e-10, 5.0892e-10],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.73
Average Loss: -0.00322
Timesteps So Far: 255000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.1254e-09, 7.3543e-11, 3.3261e-10],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------

