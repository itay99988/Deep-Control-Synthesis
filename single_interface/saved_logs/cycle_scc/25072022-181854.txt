Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2425, 0.2757, 0.2355, 0.2463], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.03
Average Loss: 0.09892
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2445, 0.2776, 0.2257, 0.2522], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.23
Average Loss: 0.01441
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2448, 0.2792, 0.2199, 0.2562], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.67
Average Loss: -0.02232
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2411, 0.2801, 0.2204, 0.2583], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.93
Average Loss: -0.03933
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2388, 0.2809, 0.2231, 0.2573], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.78
Average Loss: -0.05503
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2374, 0.2813, 0.2256, 0.2556], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.87
Average Loss: -0.06567
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2366, 0.2815, 0.2269, 0.2549], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.4
Average Loss: -0.07792
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2364, 0.2817, 0.2275, 0.2545], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.57
Average Loss: -0.07302
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2360, 0.2820, 0.2278, 0.2543], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.15
Average Loss: -0.06961
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2358, 0.2825, 0.2275, 0.2542], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.08
Average Loss: -0.07555
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2360, 0.2828, 0.2275, 0.2538], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.05
Average Loss: -0.07325
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2363, 0.2831, 0.2272, 0.2535], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.85
Average Loss: -0.07508
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2372, 0.2833, 0.2263, 0.2533], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.33
Average Loss: -0.077
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2385, 0.2831, 0.2258, 0.2526], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.85
Average Loss: -0.07503
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2401, 0.2831, 0.2249, 0.2520], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.07
Average Loss: -0.07316
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2417, 0.2830, 0.2244, 0.2510], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.67
Average Loss: -0.07276
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2433, 0.2836, 0.2228, 0.2503], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.2
Average Loss: -0.07012
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2455, 0.2839, 0.2213, 0.2493], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.23
Average Loss: -0.07237
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2472, 0.2841, 0.2204, 0.2483], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.43
Average Loss: -0.07186
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2493, 0.2843, 0.2192, 0.2471], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.73
Average Loss: -0.07105
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2513, 0.2850, 0.2180, 0.2457], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.48
Average Loss: -0.0741
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2533, 0.2857, 0.2169, 0.2441], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.97
Average Loss: -0.06715
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2559, 0.2863, 0.2150, 0.2427], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.22
Average Loss: -0.06753
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2575, 0.2885, 0.2127, 0.2412], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.38
Average Loss: -0.06231
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2595, 0.2900, 0.2108, 0.2397], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.62
Average Loss: -0.03496
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2633, 0.2903, 0.2088, 0.2376], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.6
Average Loss: -0.00584
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2739, 0.2892, 0.2032, 0.2337], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.87
Average Loss: -0.01509
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2940, 0.2868, 0.1924, 0.2268], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.87
Average Loss: -0.03108
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3079, 0.2840, 0.1855, 0.2225], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.32
Average Loss: -0.01517
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3126, 0.2833, 0.1841, 0.2201], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.0
Average Loss: -0.02206
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3085, 0.2852, 0.1864, 0.2199], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.32
Average Loss: -0.03134
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3049, 0.2851, 0.1897, 0.2203], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.27
Average Loss: -0.02252
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3120, 0.2821, 0.1888, 0.2170], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.62
Average Loss: -0.01385
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3172, 0.2786, 0.1902, 0.2140], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.03
Average Loss: -0.02749
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3202, 0.2777, 0.1911, 0.2110], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.48
Average Loss: -0.02259
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3194, 0.2788, 0.1927, 0.2091], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.47
Average Loss: -0.01262
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3246, 0.2775, 0.1929, 0.2050], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.87
Average Loss: -0.02896
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3225, 0.2769, 0.1977, 0.2028], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.68
Average Loss: -0.0222
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3301, 0.2759, 0.1960, 0.1980], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.0
Average Loss: -0.01277
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3463, 0.2755, 0.1883, 0.1899], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.17
Average Loss: -0.01996
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3665, 0.2730, 0.1785, 0.1820], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.43
Average Loss: -0.02259
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3915, 0.2677, 0.1670, 0.1737], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.4
Average Loss: -0.02899
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4195, 0.2592, 0.1556, 0.1657], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.73
Average Loss: -0.02417
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4617, 0.2448, 0.1420, 0.1515], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.4
Average Loss: -0.03005
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5051, 0.2293, 0.1283, 0.1372], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.33
Average Loss: -0.03432
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5497, 0.2119, 0.1151, 0.1234], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.07
Average Loss: -0.03072
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5972, 0.1916, 0.1018, 0.1094], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.78
Average Loss: -0.03472
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6449, 0.1701, 0.0890, 0.0959], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.13
Average Loss: -0.02469
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6891, 0.1494, 0.0776, 0.0838], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.18
Average Loss: -0.03075
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7297, 0.1300, 0.0674, 0.0730], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.57
Average Loss: -0.03008
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7631, 0.1138, 0.0591, 0.0641], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.97
Average Loss: -0.02948
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7901, 0.1006, 0.0524, 0.0569], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.45
Average Loss: -0.03454
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8132, 0.0893, 0.0467, 0.0508], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.03
Average Loss: -0.03528
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8322, 0.0800, 0.0420, 0.0458], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.93
Average Loss: -0.03033
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8485, 0.0721, 0.0379, 0.0415], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.35
Average Loss: -0.0274
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8630, 0.0651, 0.0343, 0.0376], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.38
Average Loss: -0.03406
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8750, 0.0594, 0.0313, 0.0343], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.18
Average Loss: -0.03405
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8846, 0.0548, 0.0289, 0.0317], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.15
Average Loss: -0.03147
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8928, 0.0509, 0.0268, 0.0295], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.53
Average Loss: -0.02591
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9003, 0.0474, 0.0249, 0.0274], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.0
Average Loss: -0.03017
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9065, 0.0445, 0.0233, 0.0257], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.7
Average Loss: -0.03018
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9119, 0.0419, 0.0220, 0.0242], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.93
Average Loss: -0.02752
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9167, 0.0397, 0.0207, 0.0229], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.42
Average Loss: -0.02594
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9211, 0.0376, 0.0196, 0.0217], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.83
Average Loss: -0.02782
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9254, 0.0357, 0.0184, 0.0205], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.75
Average Loss: -0.02066
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9349, 0.0311, 0.0158, 0.0182], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.95
Average Loss: -0.02151
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9687, 0.0149, 0.0070, 0.0094], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.1
Average Loss: -0.02307
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9920, 0.0038, 0.0016, 0.0026], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.82
Average Loss: -0.02193
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9789e-01, 9.9381e-04, 4.1425e-04, 7.0167e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.32
Average Loss: -0.01831
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9908e-01, 4.3520e-04, 1.7907e-04, 3.0896e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.9
Average Loss: -0.0204
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9949e-01, 2.4259e-04, 9.8798e-05, 1.7242e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.02
Average Loss: -0.01479
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9967e-01, 1.5629e-04, 6.3032e-05, 1.1107e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.37
Average Loss: -0.0146
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9980e-01, 9.6296e-05, 3.8249e-05, 6.8792e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.08
Average Loss: -0.01561
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9988e-01, 5.5075e-05, 2.1439e-05, 3.9765e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.93
Average Loss: -0.0097
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9991e-01, 4.2871e-05, 1.6621e-05, 3.1110e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.83
Average Loss: -0.01124
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9983e-01, 8.1369e-05, 3.2626e-05, 5.7479e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.3
Average Loss: -0.01116
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9983e-01, 8.3179e-05, 3.3479e-05, 5.8258e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.45
Average Loss: -0.01298
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9977e-01, 1.0900e-04, 4.3550e-05, 7.2782e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.45
Average Loss: -0.0101
Timesteps So Far: 234000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9985e-01, 7.0577e-05, 2.8294e-05, 4.7251e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.05
Average Loss: -0.00969
Timesteps So Far: 237000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9993e-01, 3.2228e-05, 1.2619e-05, 2.2085e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.67
Average Loss: -0.0073
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9996e-01, 1.9789e-05, 7.6101e-06, 1.3728e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.43
Average Loss: -0.00977
Timesteps So Far: 243000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9998e-01, 1.0935e-05, 4.0992e-06, 7.9441e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.37
Average Loss: -0.00819
Timesteps So Far: 246000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9997e-01, 1.4880e-05, 5.2885e-06, 1.0310e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.4
Average Loss: -0.00804
Timesteps So Far: 249000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9997e-01, 1.2346e-05, 4.2130e-06, 8.4156e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.68
Average Loss: -0.00488
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9999e-01, 4.4402e-06, 1.5249e-06, 3.1503e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.22
Average Loss: -0.00508
Timesteps So Far: 255000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 5.9501e-07, 2.0248e-07, 4.5489e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.68
Average Loss: -0.00752
Timesteps So Far: 258000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.7866e-07, 5.8492e-08, 1.4086e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.75
Average Loss: -0.00638
Timesteps So Far: 261000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 8.7362e-08, 2.8042e-08, 7.0087e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #88 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.9
Average Loss: -0.0037
Timesteps So Far: 264000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.3547e-07, 4.4281e-08, 1.0679e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #89 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.92
Average Loss: -0.00298
Timesteps So Far: 267000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0000e+00, 1.8564e-07, 6.1671e-08, 1.4478e-07],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 194
Failure Rate: 1.5%
------------------------------------------------------

