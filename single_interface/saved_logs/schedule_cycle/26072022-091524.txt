Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 4000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 4000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2402, 0.2581, 0.2317, 0.2700], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.9
Average Loss: 0.22977
Timesteps So Far: 4000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2414, 0.2501, 0.2460, 0.2624], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.82
Average Loss: 0.10667
Timesteps So Far: 8000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2350, 0.2434, 0.2537, 0.2679], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.16
Average Loss: -0.01524
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2326, 0.2401, 0.2565, 0.2708], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.2
Average Loss: -0.03013
Timesteps So Far: 16000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2348, 0.2427, 0.2536, 0.2689], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.59
Average Loss: -0.04176
Timesteps So Far: 20000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2416, 0.2469, 0.2452, 0.2663], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.35
Average Loss: -0.03893
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2427, 0.2497, 0.2393, 0.2682], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.88
Average Loss: -0.04328
Timesteps So Far: 28000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2476, 0.2585, 0.2328, 0.2611], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.02
Average Loss: -0.04681
Timesteps So Far: 32000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2487, 0.2583, 0.2339, 0.2591], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.92
Average Loss: -0.04773
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2447, 0.2560, 0.2375, 0.2617], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.15
Average Loss: -0.05788
Timesteps So Far: 40000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2392, 0.2598, 0.2419, 0.2591], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.86
Average Loss: -0.04829
Timesteps So Far: 44000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2383, 0.2579, 0.2427, 0.2611], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.96
Average Loss: -0.04471
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2409, 0.2564, 0.2413, 0.2614], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.55
Average Loss: -0.04663
Timesteps So Far: 52000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2422, 0.2574, 0.2436, 0.2569], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.9
Average Loss: -0.03968
Timesteps So Far: 56000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2458, 0.2540, 0.2471, 0.2531], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.44
Average Loss: -0.05278
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2454, 0.2540, 0.2502, 0.2504], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.99
Average Loss: -0.03868
Timesteps So Far: 64000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2452, 0.2574, 0.2483, 0.2492], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.62
Average Loss: -0.05628
Timesteps So Far: 68000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2445, 0.2637, 0.2457, 0.2461], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.85
Average Loss: -0.05529
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2439, 0.2649, 0.2454, 0.2458], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.91
Average Loss: -0.05121
Timesteps So Far: 76000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2426, 0.2723, 0.2417, 0.2433], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.39
Average Loss: -0.05506
Timesteps So Far: 80000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2419, 0.2750, 0.2410, 0.2420], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.66
Average Loss: -0.04114
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2400, 0.2817, 0.2388, 0.2395], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.21
Average Loss: -0.05352
Timesteps So Far: 88000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2383, 0.2812, 0.2424, 0.2382], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.18
Average Loss: -0.05215
Timesteps So Far: 92000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2371, 0.2818, 0.2419, 0.2392], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.85
Average Loss: -0.05212
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2361, 0.2853, 0.2385, 0.2401], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.46
Average Loss: -0.0565
Timesteps So Far: 100000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2358, 0.2905, 0.2363, 0.2374], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.24
Average Loss: -0.05175
Timesteps So Far: 104000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2355, 0.2914, 0.2363, 0.2368], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.66
Average Loss: -0.04337
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2358, 0.2917, 0.2365, 0.2360], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.18
Average Loss: -0.02946
Timesteps So Far: 112000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2331, 0.2971, 0.2348, 0.2350], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.44
Average Loss: -0.04234
Timesteps So Far: 116000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2307, 0.3040, 0.2325, 0.2328], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.74
Average Loss: -0.02586
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2240, 0.3141, 0.2288, 0.2332], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.81
Average Loss: -0.04719
Timesteps So Far: 124000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2225, 0.3258, 0.2239, 0.2278], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.51
Average Loss: -0.04077
Timesteps So Far: 128000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2193, 0.3370, 0.2217, 0.2220], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.59
Average Loss: -0.04619
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2172, 0.3474, 0.2170, 0.2184], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.86
Average Loss: -0.04163
Timesteps So Far: 136000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2101, 0.3585, 0.2154, 0.2161], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.02
Average Loss: -0.04473
Timesteps So Far: 140000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2087, 0.3657, 0.2132, 0.2123], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.51
Average Loss: -0.04723
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2081, 0.3709, 0.2107, 0.2103], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.19
Average Loss: -0.03743
Timesteps So Far: 148000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2065, 0.3776, 0.2093, 0.2067], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.0
Average Loss: -0.04806
Timesteps So Far: 152000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2031, 0.3857, 0.2063, 0.2049], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.84
Average Loss: -0.03919
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2015, 0.3902, 0.2045, 0.2038], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.92
Average Loss: -0.04423
Timesteps So Far: 160000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1999, 0.3966, 0.2011, 0.2024], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.81
Average Loss: -0.03544
Timesteps So Far: 164000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1956, 0.4052, 0.1986, 0.2006], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.12
Average Loss: -0.03184
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1917, 0.4171, 0.1953, 0.1959], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.69
Average Loss: -0.01413
Timesteps So Far: 172000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1788, 0.4270, 0.1993, 0.1948], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.59
Average Loss: -0.01032
Timesteps So Far: 176000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1815, 0.4303, 0.1983, 0.1899], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.4
Average Loss: -0.02079
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1788, 0.4436, 0.1904, 0.1872], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.25
Average Loss: -0.0228
Timesteps So Far: 184000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1713, 0.4545, 0.1893, 0.1849], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.45
Average Loss: -0.02532
Timesteps So Far: 188000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1643, 0.4676, 0.1876, 0.1805], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.21
Average Loss: -0.0237
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1538, 0.4866, 0.1866, 0.1731], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.25
Average Loss: -0.02563
Timesteps So Far: 196000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1432, 0.5111, 0.1800, 0.1656], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.65
Average Loss: -0.01943
Timesteps So Far: 200000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1323, 0.5342, 0.1745, 0.1590], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.27
Average Loss: -0.02456
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1160, 0.5726, 0.1678, 0.1437], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.49
Average Loss: -0.02751
Timesteps So Far: 208000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0955, 0.6246, 0.1534, 0.1266], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.12
Average Loss: -0.0248
Timesteps So Far: 212000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0724, 0.6903, 0.1300, 0.1073], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.91
Average Loss: -0.02706
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0456, 0.7694, 0.1044, 0.0807], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.86
Average Loss: -0.02982
Timesteps So Far: 220000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0257, 0.8495, 0.0736, 0.0512], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.91
Average Loss: -0.03121
Timesteps So Far: 224000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0104, 0.9292, 0.0367, 0.0237], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.64
Average Loss: -0.0264
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0027, 0.9768, 0.0130, 0.0076], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.26
Average Loss: -0.01764
Timesteps So Far: 232000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.6760e-04, 9.9057e-01, 5.5146e-03, 3.0502e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.24
Average Loss: -0.0157
Timesteps So Far: 236000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.6216e-04, 9.9449e-01, 3.1991e-03, 1.8452e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.2
Average Loss: -0.01947
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.4356e-04, 9.9451e-01, 3.1339e-03, 1.9174e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.36
Average Loss: -0.02048
Timesteps So Far: 244000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.4630e-04, 9.9421e-01, 2.9835e-03, 2.3606e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.24
Average Loss: -0.02695
Timesteps So Far: 248000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.6157e-04, 9.9235e-01, 3.4247e-03, 3.6667e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.55
Average Loss: -0.02755
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.2315e-04, 9.9088e-01, 3.4128e-03, 5.0796e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.68
Average Loss: -0.0298
Timesteps So Far: 256000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.1522e-04, 9.8724e-01, 3.9751e-03, 7.9730e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.57
Average Loss: -0.02912
Timesteps So Far: 260000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.9756e-04, 9.8992e-01, 2.7136e-03, 6.7677e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.75
Average Loss: -0.02783
Timesteps So Far: 264000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.1186e-04, 9.9238e-01, 1.7725e-03, 5.4349e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.86
Average Loss: -0.02761
Timesteps So Far: 268000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.7154e-04, 9.8703e-01, 2.5121e-03, 9.7822e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.74
Average Loss: -0.03215
Timesteps So Far: 272000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.0145e-04, 9.8610e-01, 2.3835e-03, 1.0817e-02],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.66
Average Loss: -0.03629
Timesteps So Far: 276000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.5650e-04, 9.9044e-01, 1.4592e-03, 7.6484e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.22
Average Loss: -0.04034
Timesteps So Far: 280000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.3339e-04, 9.9307e-01, 1.0975e-03, 5.5004e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.12
Average Loss: -0.03971
Timesteps So Far: 284000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.3624e-04, 9.9557e-01, 9.2995e-04, 3.2624e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.82
Average Loss: -0.04376
Timesteps So Far: 288000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.5420e-04, 9.9726e-01, 9.3981e-04, 1.6453e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.09
Average Loss: -0.06441
Timesteps So Far: 292000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0726e-04, 9.9784e-01, 7.3440e-04, 1.3216e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.73
Average Loss: -0.06176
Timesteps So Far: 296000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.5884e-05, 9.9937e-01, 2.7261e-04, 3.3135e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.56
Average Loss: -0.07787
Timesteps So Far: 300000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.7123e-05, 9.9952e-01, 2.5955e-04, 2.0742e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.9
Average Loss: -0.07794
Timesteps So Far: 304000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.4989e-06, 9.9974e-01, 1.4296e-04, 1.1129e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.31
Average Loss: -0.08186
Timesteps So Far: 308000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.0547e-06, 9.9976e-01, 1.3566e-04, 9.3458e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.52
Average Loss: -0.08272
Timesteps So Far: 312000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.6439e-06, 9.9979e-01, 1.2355e-04, 8.0166e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.42
Average Loss: -0.08243
Timesteps So Far: 316000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.5298e-06, 9.9982e-01, 1.0825e-04, 7.1426e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.99
Average Loss: -0.08258
Timesteps So Far: 320000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.8138e-06, 9.9983e-01, 1.0367e-04, 6.5107e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.26
Average Loss: -0.08301
Timesteps So Far: 324000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.1765e-06, 9.9984e-01, 9.4189e-05, 5.9269e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.35
Average Loss: -0.08017
Timesteps So Far: 328000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.4487e-06, 9.9987e-01, 8.0760e-05, 4.8400e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.94
Average Loss: -0.08371
Timesteps So Far: 332000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.8558e-06, 9.9989e-01, 6.8632e-05, 3.9451e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.1
Average Loss: -0.08346
Timesteps So Far: 336000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.3890e-06, 9.9991e-01, 5.7860e-05, 3.2316e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.18
Average Loss: -0.08339
Timesteps So Far: 340000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0939e-06, 9.9992e-01, 5.4466e-05, 2.6650e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.16
Average Loss: -0.08345
Timesteps So Far: 344000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.2250e-07, 9.9993e-01, 4.1441e-05, 2.2776e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.35
Average Loss: -0.08309
Timesteps So Far: 348000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.2266e-07, 9.9994e-01, 3.9272e-05, 2.1146e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #88 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.26
Average Loss: -0.08355
Timesteps So Far: 352000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.5425e-07, 9.9994e-01, 3.9665e-05, 1.9351e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #89 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.79
Average Loss: -0.0844
Timesteps So Far: 356000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.6316e-07, 9.9995e-01, 3.6654e-05, 1.6925e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #90 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.56
Average Loss: -0.08386
Timesteps So Far: 360000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.2335e-07, 9.9994e-01, 3.9461e-05, 1.5444e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #91 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.69
Average Loss: -0.08273
Timesteps So Far: 364000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.0553e-07, 9.9994e-01, 4.0230e-05, 1.5329e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #92 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.66
Average Loss: -0.08429
Timesteps So Far: 368000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.7902e-07, 9.9995e-01, 3.8232e-05, 1.5286e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #93 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.69
Average Loss: -0.08469
Timesteps So Far: 372000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.4054e-07, 9.9995e-01, 3.6529e-05, 1.4440e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #94 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.84
Average Loss: -0.0848
Timesteps So Far: 376000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.2474e-07, 9.9995e-01, 3.6197e-05, 1.4467e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #95 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.52
Average Loss: -0.08377
Timesteps So Far: 380000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.2808e-07, 9.9995e-01, 3.8379e-05, 1.5066e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #96 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.22
Average Loss: -0.08141
Timesteps So Far: 384000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.1097e-07, 9.9995e-01, 3.9363e-05, 1.4892e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #97 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.71
Average Loss: -0.08378
Timesteps So Far: 388000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.6569e-07, 9.9995e-01, 3.5637e-05, 1.3841e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #98 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.65
Average Loss: -0.08403
Timesteps So Far: 392000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.1565e-07, 9.9995e-01, 3.3328e-05, 1.1699e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #99 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.15
Average Loss: -0.08521
Timesteps So Far: 396000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.8979e-07, 9.9996e-01, 3.2732e-05, 1.0411e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #100 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.9
Average Loss: -0.08325
Timesteps So Far: 400000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.8248e-07, 9.9996e-01, 3.3184e-05, 9.9183e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #101 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.89
Average Loss: -0.08325
Timesteps So Far: 404000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.6734e-07, 9.9996e-01, 3.3301e-05, 9.1681e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #102 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.82
Average Loss: -0.08285
Timesteps So Far: 408000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.4831e-07, 9.9996e-01, 3.2938e-05, 8.1428e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #103 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.71
Average Loss: -0.08238
Timesteps So Far: 412000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.3869e-07, 9.9996e-01, 3.4283e-05, 8.8996e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #104 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.65
Average Loss: -0.08206
Timesteps So Far: 416000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.1383e-07, 9.9996e-01, 3.4737e-05, 8.3962e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #105 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.99
Average Loss: -0.08371
Timesteps So Far: 420000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.8438e-07, 9.9996e-01, 3.0508e-05, 7.7800e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #106 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.64
Average Loss: -0.08184
Timesteps So Far: 424000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.6706e-07, 9.9996e-01, 3.1081e-05, 7.3725e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #107 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.91
Average Loss: -0.08436
Timesteps So Far: 428000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.4915e-07, 9.9996e-01, 3.0045e-05, 7.4186e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #108 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.89
Average Loss: -0.08381
Timesteps So Far: 432000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.3860e-07, 9.9996e-01, 2.8371e-05, 7.8708e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #109 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.21
Average Loss: -0.08048
Timesteps So Far: 436000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.2247e-07, 9.9997e-01, 2.6491e-05, 6.7830e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #110 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.42
Average Loss: -0.08546
Timesteps So Far: 440000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0680e-07, 9.9997e-01, 2.3352e-05, 5.3524e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #111 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.48
Average Loss: -0.0848
Timesteps So Far: 444000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.3601e-08, 9.9998e-01, 2.0076e-05, 4.8152e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #112 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.38
Average Loss: -0.08484
Timesteps So Far: 448000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.1573e-07, 9.9997e-01, 2.6486e-05, 6.2398e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #113 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.92
Average Loss: -0.08287
Timesteps So Far: 452000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.1338e-07, 9.9997e-01, 2.5998e-05, 6.9234e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #114 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.98
Average Loss: -0.07962
Timesteps So Far: 456000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0866e-07, 9.9996e-01, 3.0743e-05, 5.9759e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #115 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.55
Average Loss: -0.08504
Timesteps So Far: 460000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.3822e-08, 9.9997e-01, 2.2003e-05, 5.1897e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #116 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.59
Average Loss: -0.08489
Timesteps So Far: 464000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.6116e-08, 9.9998e-01, 1.5609e-05, 4.8040e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #117 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.52
Average Loss: -0.08192
Timesteps So Far: 468000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.5682e-08, 9.9998e-01, 1.4773e-05, 3.8947e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #118 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.55
Average Loss: -0.0854
Timesteps So Far: 472000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.5308e-08, 9.9998e-01, 1.2910e-05, 2.6770e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #119 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.69
Average Loss: -0.08602
Timesteps So Far: 476000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.0866e-08, 9.9999e-01, 1.0655e-05, 2.5551e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #120 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.32
Average Loss: -0.08568
Timesteps So Far: 480000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.3688e-08, 9.9998e-01, 1.4316e-05, 3.4666e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #121 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.52
Average Loss: -0.08198
Timesteps So Far: 484000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.5339e-08, 9.9998e-01, 1.4994e-05, 2.3680e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #122 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.75
Average Loss: -0.08563
Timesteps So Far: 488000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.6205e-08, 9.9999e-01, 1.1540e-05, 1.9243e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #123 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.84
Average Loss: -0.08616
Timesteps So Far: 492000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.8487e-08, 9.9999e-01, 8.2159e-06, 1.7224e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #124 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.54
Average Loss: -0.08598
Timesteps So Far: 496000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.5637e-08, 9.9999e-01, 7.3895e-06, 1.6342e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #125 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.24
Average Loss: -0.08507
Timesteps So Far: 500000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.1168e-08, 9.9999e-01, 5.5619e-06, 1.6055e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #126 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.58
Average Loss: -0.08578
Timesteps So Far: 504000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.7306e-08, 9.9999e-01, 7.5121e-06, 2.1678e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #127 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.61
Average Loss: -0.08566
Timesteps So Far: 508000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.2884e-08, 9.9999e-01, 6.8670e-06, 1.6933e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #128 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.81
Average Loss: -0.08623
Timesteps So Far: 512000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.7092e-08, 9.9999e-01, 4.8801e-06, 1.3263e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #129 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.58
Average Loss: -0.08534
Timesteps So Far: 516000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.7621e-08, 9.9999e-01, 5.1718e-06, 1.3811e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #130 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.36
Average Loss: -0.08585
Timesteps So Far: 520000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.3130e-08, 9.9999e-01, 7.3673e-06, 1.7805e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #131 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.51
Average Loss: -0.08577
Timesteps So Far: 524000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.3640e-08, 9.9999e-01, 7.7795e-06, 1.8196e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #132 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.86
Average Loss: -0.08202
Timesteps So Far: 528000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.1576e-08, 9.9999e-01, 8.1029e-06, 1.4610e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #133 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.71
Average Loss: -0.08592
Timesteps So Far: 532000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.8152e-08, 9.9999e-01, 6.8061e-06, 1.2326e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #134 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.75
Average Loss: -0.08602
Timesteps So Far: 536000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.3570e-08, 9.9999e-01, 4.9812e-06, 9.5789e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #135 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.68
Average Loss: -0.08614
Timesteps So Far: 540000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.2922e-08, 9.9999e-01, 4.5259e-06, 9.7337e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #136 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.02
Average Loss: -0.08481
Timesteps So Far: 544000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.6228e-08, 9.9999e-01, 6.5735e-06, 1.1038e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #137 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.55
Average Loss: -0.0854
Timesteps So Far: 548000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.4221e-08, 9.9999e-01, 6.4618e-06, 8.6349e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #138 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.81
Average Loss: -0.08608
Timesteps So Far: 552000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.8172e-09, 1.0000e+00, 4.0986e-06, 6.4787e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #139 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.55
Average Loss: -0.08595
Timesteps So Far: 556000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.4956e-09, 1.0000e+00, 3.4145e-06, 5.8326e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #140 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.4
Average Loss: -0.08588
Timesteps So Far: 560000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.1794e-08, 9.9999e-01, 5.0323e-06, 8.0407e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #141 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.49
Average Loss: -0.08594
Timesteps So Far: 564000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.2231e-08, 9.9999e-01, 5.5057e-06, 8.2191e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #142 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.91
Average Loss: -0.08281
Timesteps So Far: 568000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.2764e-08, 9.9999e-01, 5.7101e-06, 8.8403e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #143 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.14
Average Loss: -0.08551
Timesteps So Far: 572000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.1001e-08, 9.9999e-01, 5.0414e-06, 7.4964e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #144 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.94
Average Loss: -0.08385
Timesteps So Far: 576000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.7775e-09, 9.9999e-01, 5.3146e-06, 5.5688e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #145 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.78
Average Loss: -0.08614
Timesteps So Far: 580000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.6547e-09, 9.9999e-01, 4.6833e-06, 4.9126e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #146 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.82
Average Loss: -0.08629
Timesteps So Far: 584000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.7398e-09, 1.0000e+00, 3.8867e-06, 4.7314e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #147 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.8
Average Loss: -0.08633
Timesteps So Far: 588000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.1663e-09, 1.0000e+00, 3.5018e-06, 4.5680e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #148 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.79
Average Loss: -0.08626
Timesteps So Far: 592000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.3901e-09, 1.0000e+00, 3.6101e-06, 4.6849e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #149 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.69
Average Loss: -0.08589
Timesteps So Far: 596000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.4217e-09, 1.0000e+00, 3.3569e-06, 3.8004e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #150 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.79
Average Loss: -0.08572
Timesteps So Far: 600000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.7512e-09, 9.9999e-01, 4.7314e-06, 5.3464e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #151 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.85
Average Loss: -0.08593
Timesteps So Far: 604000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.2260e-09, 1.0000e+00, 4.4552e-06, 5.0177e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #152 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.61
Average Loss: -0.08528
Timesteps So Far: 608000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.2993e-09, 1.0000e+00, 3.6376e-06, 3.4743e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #153 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.74
Average Loss: -0.08537
Timesteps So Far: 612000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.4299e-09, 1.0000e+00, 2.5935e-06, 2.3982e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #154 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.9
Average Loss: -0.08635
Timesteps So Far: 616000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.9657e-09, 1.0000e+00, 2.2146e-06, 2.2579e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #155 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.74
Average Loss: -0.08622
Timesteps So Far: 620000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.9557e-09, 1.0000e+00, 3.4813e-06, 3.4135e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #156 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.5
Average Loss: -0.08598
Timesteps So Far: 624000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.4121e-09, 1.0000e+00, 3.8624e-06, 3.6771e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #157 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.56
Average Loss: -0.08537
Timesteps So Far: 628000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.5175e-09, 1.0000e+00, 3.7964e-06, 3.9090e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #158 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.25
Average Loss: -0.0859
Timesteps So Far: 632000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.5774e-09, 1.0000e+00, 3.2962e-06, 3.3300e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #159 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.25
Average Loss: -0.08389
Timesteps So Far: 636000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.0705e-09, 1.0000e+00, 2.7034e-06, 2.0525e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #160 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.86
Average Loss: -0.08631
Timesteps So Far: 640000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.5513e-09, 1.0000e+00, 2.1951e-06, 1.8752e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #161 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.76
Average Loss: -0.0862
Timesteps So Far: 644000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.6748e-09, 1.0000e+00, 2.3018e-06, 1.9627e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #162 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.65
Average Loss: -0.08609
Timesteps So Far: 648000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.0151e-09, 1.0000e+00, 3.3180e-06, 2.6984e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #163 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.61
Average Loss: -0.08601
Timesteps So Far: 652000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.3219e-09, 1.0000e+00, 3.4078e-06, 3.0211e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #164 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.49
Average Loss: -0.08566
Timesteps So Far: 656000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.7888e-09, 1.0000e+00, 3.0216e-06, 2.7868e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #165 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.42
Average Loss: -0.0859
Timesteps So Far: 660000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.8592e-09, 1.0000e+00, 2.9753e-06, 2.9437e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #166 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.15
Average Loss: -0.08573
Timesteps So Far: 664000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.5652e-09, 1.0000e+00, 2.7973e-06, 2.7818e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #167 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.81
Average Loss: -0.08493
Timesteps So Far: 668000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.6135e-09, 1.0000e+00, 3.1416e-06, 2.5086e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #168 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.45
Average Loss: -0.08563
Timesteps So Far: 672000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.2451e-09, 1.0000e+00, 2.3579e-06, 1.6316e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #169 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.72
Average Loss: -0.0861
Timesteps So Far: 676000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.9863e-09, 1.0000e+00, 2.0740e-06, 1.5651e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #170 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.54
Average Loss: -0.0854
Timesteps So Far: 680000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.0262e-09, 1.0000e+00, 2.1446e-06, 1.5973e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #171 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.58
Average Loss: -0.08547
Timesteps So Far: 684000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.9823e-09, 1.0000e+00, 2.8992e-06, 2.1548e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #172 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.31
Average Loss: -0.08502
Timesteps So Far: 688000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.9568e-09, 1.0000e+00, 2.6291e-06, 2.3454e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #173 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.7
Average Loss: -0.07631
Timesteps So Far: 692000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.3366e-09, 1.0000e+00, 1.4577e-06, 1.4747e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #174 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.35
Average Loss: -0.06873
Timesteps So Far: 696000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.7498e-09, 1.0000e+00, 2.6259e-06, 2.2305e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #175 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.94
Average Loss: -0.06789
Timesteps So Far: 700000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.2736e-09, 1.0000e+00, 1.9729e-06, 8.2945e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #176 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.89
Average Loss: -0.07958
Timesteps So Far: 704000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.6519e-09, 9.9999e-01, 6.6263e-06, 2.1395e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #177 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.71
Average Loss: -0.07943
Timesteps So Far: 708000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.1437e-09, 1.0000e+00, 2.8355e-06, 9.4204e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #178 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -0.08735
Timesteps So Far: 712000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.7583e-09, 1.0000e+00, 1.1510e-06, 6.3931e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #179 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.81
Average Loss: -0.08669
Timesteps So Far: 716000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.5110e-09, 1.0000e+00, 1.4681e-06, 1.0899e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #180 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.84
Average Loss: -0.06915
Timesteps So Far: 720000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.1600e-09, 1.0000e+00, 1.3523e-06, 9.1748e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #181 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.32
Average Loss: -0.07963
Timesteps So Far: 724000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.7004e-09, 1.0000e+00, 1.8043e-06, 1.0572e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #182 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.75
Average Loss: -0.0838
Timesteps So Far: 728000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.9459e-09, 1.0000e+00, 1.4487e-06, 7.2979e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #183 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.7
Average Loss: -0.08202
Timesteps So Far: 732000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.7231e-09, 1.0000e+00, 2.4696e-06, 8.4951e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #184 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.79
Average Loss: -0.0838
Timesteps So Far: 736000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.7205e-09, 1.0000e+00, 1.4223e-06, 5.6555e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #185 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.88
Average Loss: -0.0865
Timesteps So Far: 740000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.4713e-09, 1.0000e+00, 1.0397e-06, 5.5589e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #186 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.94
Average Loss: -0.08699
Timesteps So Far: 744000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.2522e-09, 1.0000e+00, 8.2406e-07, 5.1271e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #187 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.72
Average Loss: -0.08244
Timesteps So Far: 748000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.8888e-09, 1.0000e+00, 1.2554e-06, 8.4477e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #188 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.38
Average Loss: -0.07855
Timesteps So Far: 752000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.5091e-09, 1.0000e+00, 2.1557e-06, 8.8082e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #189 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.86
Average Loss: -0.08175
Timesteps So Far: 756000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.8796e-09, 1.0000e+00, 1.8793e-06, 5.4840e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #190 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.96
Average Loss: -0.08658
Timesteps So Far: 760000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.5135e-09, 1.0000e+00, 1.9026e-06, 7.5940e-08],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

