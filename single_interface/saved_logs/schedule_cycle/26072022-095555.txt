Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 4000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 4000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2503, 0.2974, 0.2033, 0.2490], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.65
Average Loss: 0.22154
Timesteps So Far: 4000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2565, 0.2743, 0.2116, 0.2576], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.44
Average Loss: 0.07692
Timesteps So Far: 8000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2928, 0.2698, 0.1937, 0.2438], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.08
Average Loss: -0.02257
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3200, 0.2689, 0.1808, 0.2303], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.64
Average Loss: -0.03251
Timesteps So Far: 16000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3283, 0.2690, 0.1768, 0.2259], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.45
Average Loss: -0.02874
Timesteps So Far: 20000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3257, 0.2698, 0.1777, 0.2268], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.85
Average Loss: -0.02791
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3021, 0.2733, 0.1898, 0.2349], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.44
Average Loss: -0.03136
Timesteps So Far: 28000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2615, 0.2747, 0.2146, 0.2492], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.55
Average Loss: -0.05097
Timesteps So Far: 32000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2504, 0.2646, 0.2311, 0.2539], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.76
Average Loss: -0.05017
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2479, 0.2548, 0.2444, 0.2529], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.6
Average Loss: -0.0561
Timesteps So Far: 40000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2491, 0.2485, 0.2512, 0.2512], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.88
Average Loss: -0.0508
Timesteps So Far: 44000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2498, 0.2507, 0.2498, 0.2497], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.92
Average Loss: -0.04857
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2431, 0.2584, 0.2487, 0.2497], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.84
Average Loss: -0.04773
Timesteps So Far: 52000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2389, 0.2587, 0.2515, 0.2509], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.66
Average Loss: -0.04736
Timesteps So Far: 56000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2425, 0.2569, 0.2498, 0.2507], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.39
Average Loss: -0.06138
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2475, 0.2547, 0.2490, 0.2488], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.68
Average Loss: -0.06313
Timesteps So Far: 64000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2528, 0.2511, 0.2487, 0.2475], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.84
Average Loss: -0.06055
Timesteps So Far: 68000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2584, 0.2492, 0.2456, 0.2468], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.66
Average Loss: -0.05835
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2596, 0.2514, 0.2449, 0.2441], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.51
Average Loss: -0.05972
Timesteps So Far: 76000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2526, 0.2551, 0.2460, 0.2462], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.41
Average Loss: -0.06217
Timesteps So Far: 80000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2506, 0.2547, 0.2478, 0.2469], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.59
Average Loss: -0.06754
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2536, 0.2508, 0.2519, 0.2437], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.08
Average Loss: -0.07141
Timesteps So Far: 88000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2557, 0.2523, 0.2515, 0.2406], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.15
Average Loss: -0.07259
Timesteps So Far: 92000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2529, 0.2556, 0.2511, 0.2405], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.54
Average Loss: -0.06146
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2476, 0.2568, 0.2514, 0.2443], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.89
Average Loss: -0.06911
Timesteps So Far: 100000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2484, 0.2539, 0.2529, 0.2449], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.5
Average Loss: -0.06659
Timesteps So Far: 104000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2473, 0.2555, 0.2544, 0.2427], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.06
Average Loss: -0.06674
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2496, 0.2569, 0.2502, 0.2433], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.12
Average Loss: -0.06364
Timesteps So Far: 112000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2493, 0.2580, 0.2436, 0.2491], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.91
Average Loss: -0.07003
Timesteps So Far: 116000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2502, 0.2611, 0.2379, 0.2509], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.42
Average Loss: -0.06565
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2470, 0.2659, 0.2355, 0.2516], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.92
Average Loss: -0.06667
Timesteps So Far: 124000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2454, 0.2605, 0.2431, 0.2510], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.21
Average Loss: -0.06904
Timesteps So Far: 128000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2462, 0.2563, 0.2470, 0.2505], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.84
Average Loss: -0.06421
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2418, 0.2583, 0.2500, 0.2499], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.89
Average Loss: -0.06708
Timesteps So Far: 136000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2472, 0.2537, 0.2514, 0.2477], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.18
Average Loss: -0.07185
Timesteps So Far: 140000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2465, 0.2568, 0.2557, 0.2410], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.49
Average Loss: -0.06446
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2485, 0.2595, 0.2579, 0.2341], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.46
Average Loss: -0.06573
Timesteps So Far: 148000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2489, 0.2634, 0.2574, 0.2302], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.68
Average Loss: -0.06564
Timesteps So Far: 152000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2477, 0.2637, 0.2550, 0.2336], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.28
Average Loss: -0.06849
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2471, 0.2644, 0.2544, 0.2341], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.65
Average Loss: -0.06467
Timesteps So Far: 160000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2441, 0.2662, 0.2560, 0.2337], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.49
Average Loss: -0.06331
Timesteps So Far: 164000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2441, 0.2655, 0.2490, 0.2415], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.94
Average Loss: -0.06436
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2416, 0.2623, 0.2518, 0.2443], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.75
Average Loss: -0.06601
Timesteps So Far: 172000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2400, 0.2641, 0.2528, 0.2431], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.78
Average Loss: -0.06716
Timesteps So Far: 176000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2404, 0.2674, 0.2515, 0.2407], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.59
Average Loss: -0.06562
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2408, 0.2692, 0.2490, 0.2410], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.94
Average Loss: -0.06798
Timesteps So Far: 184000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2341, 0.2804, 0.2474, 0.2381], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.02
Average Loss: -0.06342
Timesteps So Far: 188000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2315, 0.2958, 0.2349, 0.2378], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.76
Average Loss: -0.06614
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2319, 0.3005, 0.2357, 0.2319], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.51
Average Loss: -0.06387
Timesteps So Far: 196000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2284, 0.3148, 0.2302, 0.2267], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.99
Average Loss: -0.06312
Timesteps So Far: 200000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2210, 0.3384, 0.2270, 0.2136], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.59
Average Loss: -0.06692
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2187, 0.3513, 0.2182, 0.2118], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.48
Average Loss: -0.06508
Timesteps So Far: 208000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2139, 0.3571, 0.2177, 0.2112], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.88
Average Loss: -0.0619
Timesteps So Far: 212000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2081, 0.3804, 0.2078, 0.2037], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.02
Average Loss: -0.06211
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2049, 0.4029, 0.1918, 0.2004], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.11
Average Loss: -0.06344
Timesteps So Far: 220000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1975, 0.4191, 0.1863, 0.1971], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.58
Average Loss: -0.06191
Timesteps So Far: 224000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1853, 0.4447, 0.1819, 0.1882], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.88
Average Loss: -0.05692
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1791, 0.4635, 0.1751, 0.1823], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.18
Average Loss: -0.05962
Timesteps So Far: 232000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1771, 0.4738, 0.1695, 0.1796], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.52
Average Loss: -0.05321
Timesteps So Far: 236000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1784, 0.4698, 0.1699, 0.1819], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.01
Average Loss: -0.049
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1780, 0.4637, 0.1743, 0.1840], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.2
Average Loss: -0.05436
Timesteps So Far: 244000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1778, 0.4685, 0.1686, 0.1852], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.02
Average Loss: -0.0275
Timesteps So Far: 248000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1951, 0.4264, 0.1582, 0.2203], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.29
Average Loss: -0.04022
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1849, 0.4425, 0.1530, 0.2195], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.31
Average Loss: -0.03091
Timesteps So Far: 256000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1866, 0.4177, 0.1701, 0.2256], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.39
Average Loss: -0.03372
Timesteps So Far: 260000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1941, 0.3897, 0.1942, 0.2221], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.26
Average Loss: -0.02671
Timesteps So Far: 264000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1868, 0.3932, 0.1817, 0.2382], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.84
Average Loss: -0.0291
Timesteps So Far: 268000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1880, 0.3772, 0.1966, 0.2382], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.81
Average Loss: -0.02917
Timesteps So Far: 272000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1577, 0.4509, 0.1787, 0.2127], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.6
Average Loss: -0.02581
Timesteps So Far: 276000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1367, 0.5021, 0.1674, 0.1938], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.31
Average Loss: -0.01992
Timesteps So Far: 280000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1156, 0.5582, 0.1541, 0.1721], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.95
Average Loss: -0.02111
Timesteps So Far: 284000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0971, 0.6310, 0.1306, 0.1413], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.45
Average Loss: -0.02166
Timesteps So Far: 288000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0853, 0.6629, 0.1175, 0.1343], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.96
Average Loss: -0.02774
Timesteps So Far: 292000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0747, 0.7151, 0.0997, 0.1105], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.3
Average Loss: -0.02592
Timesteps So Far: 296000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0549, 0.8091, 0.0677, 0.0683], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.9
Average Loss: -0.03467
Timesteps So Far: 300000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0478, 0.8336, 0.0589, 0.0597], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.22
Average Loss: -0.03315
Timesteps So Far: 304000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0409, 0.8562, 0.0524, 0.0505], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.26
Average Loss: -0.04365
Timesteps So Far: 308000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0342, 0.8784, 0.0462, 0.0412], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.14
Average Loss: -0.03885
Timesteps So Far: 312000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0289, 0.8970, 0.0403, 0.0338], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.35
Average Loss: -0.04678
Timesteps So Far: 316000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0239, 0.9140, 0.0346, 0.0275], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.78
Average Loss: -0.03375
Timesteps So Far: 320000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0199, 0.9273, 0.0296, 0.0233], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.3
Average Loss: -0.0298
Timesteps So Far: 324000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0166, 0.9391, 0.0248, 0.0195], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.69
Average Loss: -0.01636
Timesteps So Far: 328000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0136, 0.9497, 0.0205, 0.0162], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.59
Average Loss: -0.01492
Timesteps So Far: 332000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0109, 0.9587, 0.0169, 0.0135], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.55
Average Loss: -0.02253
Timesteps So Far: 336000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0085, 0.9672, 0.0134, 0.0108], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.99
Average Loss: -0.02478
Timesteps So Far: 340000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0067, 0.9740, 0.0106, 0.0086], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.1
Average Loss: -0.03716
Timesteps So Far: 344000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0052, 0.9796, 0.0084, 0.0068], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.86
Average Loss: -0.03031
Timesteps So Far: 348000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0041, 0.9840, 0.0064, 0.0055], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #88 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.6
Average Loss: -0.02534
Timesteps So Far: 352000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0033, 0.9869, 0.0051, 0.0046], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #89 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.28
Average Loss: -0.0144
Timesteps So Far: 356000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0025, 0.9897, 0.0039, 0.0039], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #90 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.15
Average Loss: -0.00342
Timesteps So Far: 360000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0021, 0.9914, 0.0032, 0.0033], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #91 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.84
Average Loss: -0.02423
Timesteps So Far: 364000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0016, 0.9931, 0.0026, 0.0027], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #92 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.95
Average Loss: -0.01225
Timesteps So Far: 368000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0013, 0.9941, 0.0022, 0.0024], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #93 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.9
Average Loss: -0.01026
Timesteps So Far: 372000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0011, 0.9949, 0.0019, 0.0020], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #94 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.62
Average Loss: -0.0136
Timesteps So Far: 376000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.8802e-04, 9.9553e-01, 1.6582e-03, 1.8191e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #95 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.95
Average Loss: -0.01668
Timesteps So Far: 380000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.5858e-04, 9.9561e-01, 1.6493e-03, 1.7801e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #96 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.31
Average Loss: -0.00633
Timesteps So Far: 384000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.5012e-04, 9.9620e-01, 1.4231e-03, 1.5261e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #97 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.31
Average Loss: -0.0047
Timesteps So Far: 388000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.5806e-04, 9.9665e-01, 1.2550e-03, 1.3395e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #98 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.68
Average Loss: -0.00711
Timesteps So Far: 392000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.7865e-04, 9.9699e-01, 1.1339e-03, 1.1950e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #99 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.76
Average Loss: -0.00581
Timesteps So Far: 396000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.2686e-04, 9.9725e-01, 1.0571e-03, 1.0679e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #100 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.4
Average Loss: -0.01472
Timesteps So Far: 400000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.1377e-04, 9.9758e-01, 9.6046e-04, 9.4242e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #101 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.98
Average Loss: -0.01274
Timesteps So Far: 404000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.3947e-04, 9.9779e-01, 9.0183e-04, 8.6809e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #102 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.75
Average Loss: -0.0056
Timesteps So Far: 408000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.9416e-04, 9.9791e-01, 8.6718e-04, 8.2505e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #103 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.72
Average Loss: -0.00997
Timesteps So Far: 412000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.6143e-04, 9.9805e-01, 8.0751e-04, 7.8230e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #104 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.78
Average Loss: -0.00106
Timesteps So Far: 416000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.4079e-04, 9.9819e-01, 7.3144e-04, 7.4195e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #105 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.76
Average Loss: -0.00217
Timesteps So Far: 420000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.2425e-04, 9.9832e-01, 6.4889e-04, 7.0904e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #106 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.78
Average Loss: 0.0008
Timesteps So Far: 424000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.0278e-04, 9.9844e-01, 5.8681e-04, 6.7327e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #107 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.99
Average Loss: -0.00996
Timesteps So Far: 428000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.9073e-04, 9.9849e-01, 5.6878e-04, 6.4625e-04],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

