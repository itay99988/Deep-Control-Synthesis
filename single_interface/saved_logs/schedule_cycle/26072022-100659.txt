Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 4000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 4000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2705, 0.2460, 0.2768, 0.2067], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.39
Average Loss: 0.25378
Timesteps So Far: 4000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2708, 0.2392, 0.2677, 0.2223], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.04
Average Loss: 0.09906
Timesteps So Far: 8000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2841, 0.2308, 0.2561, 0.2290], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.38
Average Loss: -0.02934
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2879, 0.2283, 0.2481, 0.2356], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.52
Average Loss: -0.04679
Timesteps So Far: 16000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2835, 0.2363, 0.2471, 0.2331], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.0
Average Loss: -0.04924
Timesteps So Far: 20000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2691, 0.2479, 0.2467, 0.2363], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.42
Average Loss: -0.05897
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2632, 0.2527, 0.2490, 0.2350], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.02
Average Loss: -0.06602
Timesteps So Far: 28000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2614, 0.2520, 0.2511, 0.2355], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.15
Average Loss: -0.05954
Timesteps So Far: 32000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2628, 0.2511, 0.2489, 0.2373], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.92
Average Loss: -0.0524
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2597, 0.2534, 0.2461, 0.2408], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.89
Average Loss: -0.05839
Timesteps So Far: 40000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2555, 0.2558, 0.2426, 0.2461], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.95
Average Loss: -0.05863
Timesteps So Far: 44000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2571, 0.2543, 0.2419, 0.2467], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.76
Average Loss: -0.06273
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2586, 0.2530, 0.2423, 0.2461], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.29
Average Loss: -0.07249
Timesteps So Far: 52000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2594, 0.2533, 0.2453, 0.2420], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.84
Average Loss: -0.06502
Timesteps So Far: 56000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2595, 0.2540, 0.2489, 0.2376], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.12
Average Loss: -0.07492
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2563, 0.2581, 0.2446, 0.2409], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.94
Average Loss: -0.06588
Timesteps So Far: 64000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2517, 0.2630, 0.2496, 0.2357], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.01
Average Loss: -0.07357
Timesteps So Far: 68000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2538, 0.2629, 0.2487, 0.2345], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.25
Average Loss: -0.07409
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2514, 0.2674, 0.2453, 0.2359], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.75
Average Loss: -0.07251
Timesteps So Far: 76000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2455, 0.2808, 0.2421, 0.2316], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.72
Average Loss: -0.07147
Timesteps So Far: 80000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2326, 0.2963, 0.2439, 0.2273], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.01
Average Loss: -0.07593
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2377, 0.2921, 0.2263, 0.2439], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.56
Average Loss: -0.07803
Timesteps So Far: 88000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2222, 0.2858, 0.2433, 0.2487], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.62
Average Loss: -0.07674
Timesteps So Far: 92000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2236, 0.2797, 0.2407, 0.2560], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.8
Average Loss: -0.07677
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2308, 0.2733, 0.2341, 0.2617], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.64
Average Loss: -0.07769
Timesteps So Far: 100000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2387, 0.2684, 0.2404, 0.2525], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.8
Average Loss: -0.07697
Timesteps So Far: 104000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2379, 0.2717, 0.2427, 0.2477], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.44
Average Loss: -0.07628
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2443, 0.2633, 0.2428, 0.2497], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.49
Average Loss: -0.07946
Timesteps So Far: 112000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2495, 0.2603, 0.2335, 0.2567], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.75
Average Loss: -0.07454
Timesteps So Far: 116000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2460, 0.2653, 0.2353, 0.2534], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.08
Average Loss: -0.07795
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2470, 0.2689, 0.2379, 0.2463], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.81
Average Loss: -0.07628
Timesteps So Far: 124000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2412, 0.2710, 0.2394, 0.2484], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.8
Average Loss: -0.07585
Timesteps So Far: 128000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2391, 0.2671, 0.2455, 0.2482], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.71
Average Loss: -0.07457
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2385, 0.2709, 0.2488, 0.2418], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.92
Average Loss: -0.07627
Timesteps So Far: 136000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2298, 0.2758, 0.2511, 0.2434], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.8
Average Loss: -0.07532
Timesteps So Far: 140000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2320, 0.2833, 0.2504, 0.2342], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.76
Average Loss: -0.07483
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2258, 0.2851, 0.2548, 0.2342], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.61
Average Loss: -0.07515
Timesteps So Far: 148000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2274, 0.2858, 0.2463, 0.2405], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.68
Average Loss: -0.07676
Timesteps So Far: 152000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2267, 0.2887, 0.2460, 0.2386], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.11
Average Loss: -0.06916
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2315, 0.2933, 0.2421, 0.2330], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.39
Average Loss: -0.07177
Timesteps So Far: 160000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2289, 0.3002, 0.2419, 0.2289], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.78
Average Loss: -0.07292
Timesteps So Far: 164000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2237, 0.3114, 0.2325, 0.2325], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.84
Average Loss: -0.06996
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2201, 0.3241, 0.2262, 0.2295], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.92
Average Loss: -0.07061
Timesteps So Far: 172000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2052, 0.3296, 0.2390, 0.2262], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.82
Average Loss: -0.07201
Timesteps So Far: 176000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2097, 0.3460, 0.2255, 0.2188], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.02
Average Loss: -0.0696
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2065, 0.3513, 0.2290, 0.2132], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.85
Average Loss: -0.06752
Timesteps So Far: 184000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2026, 0.3414, 0.2343, 0.2217], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.01
Average Loss: -0.05707
Timesteps So Far: 188000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2210, 0.3146, 0.2354, 0.2290], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.1
Average Loss: -0.03137
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2210, 0.2965, 0.2358, 0.2467], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.62
Average Loss: -0.02497
Timesteps So Far: 196000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2201, 0.2926, 0.2389, 0.2484], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.32
Average Loss: -0.03447
Timesteps So Far: 200000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2254, 0.2832, 0.2448, 0.2466], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.34
Average Loss: -0.03679
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2317, 0.2755, 0.2516, 0.2412], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.95
Average Loss: -0.03398
Timesteps So Far: 208000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2268, 0.2777, 0.2566, 0.2390], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.84
Average Loss: -0.04122
Timesteps So Far: 212000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2240, 0.2865, 0.2540, 0.2356], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.77
Average Loss: -0.03643
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2212, 0.2988, 0.2573, 0.2227], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.08
Average Loss: -0.04647
Timesteps So Far: 220000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2125, 0.3134, 0.2492, 0.2249], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.88
Average Loss: -0.0319
Timesteps So Far: 224000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1980, 0.3328, 0.2510, 0.2181], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.66
Average Loss: -0.03966
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1869, 0.3709, 0.2499, 0.1923], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.42
Average Loss: -0.03767
Timesteps So Far: 232000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1749, 0.4091, 0.2465, 0.1695], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.68
Average Loss: -0.05227
Timesteps So Far: 236000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1439, 0.4601, 0.2521, 0.1438], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.99
Average Loss: -0.04765
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1215, 0.5143, 0.2494, 0.1148], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.32
Average Loss: -0.05578
Timesteps So Far: 244000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0986, 0.5893, 0.2180, 0.0940], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.16
Average Loss: -0.05885
Timesteps So Far: 248000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0763, 0.6506, 0.1912, 0.0819], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.81
Average Loss: -0.0613
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0552, 0.7084, 0.1688, 0.0676], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.54
Average Loss: -0.05992
Timesteps So Far: 256000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0252, 0.8361, 0.0964, 0.0423], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.96
Average Loss: -0.04462
Timesteps So Far: 260000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0140, 0.9003, 0.0568, 0.0289], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.21
Average Loss: -0.02849
Timesteps So Far: 264000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0050, 0.9627, 0.0189, 0.0135], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.22
Average Loss: -0.0192
Timesteps So Far: 268000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0033, 0.9742, 0.0131, 0.0094], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.38
Average Loss: -0.01093
Timesteps So Far: 272000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0028, 0.9772, 0.0121, 0.0079], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.79
Average Loss: -0.01088
Timesteps So Far: 276000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0026, 0.9787, 0.0116, 0.0072], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.95
Average Loss: -0.01385
Timesteps So Far: 280000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0025, 0.9793, 0.0118, 0.0064], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.58
Average Loss: -0.01718
Timesteps So Far: 284000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0024, 0.9779, 0.0133, 0.0064], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.59
Average Loss: -0.00847
Timesteps So Far: 288000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0024, 0.9760, 0.0151, 0.0065], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.58
Average Loss: -0.01611
Timesteps So Far: 292000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0025, 0.9744, 0.0163, 0.0068], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.94
Average Loss: -0.02255
Timesteps So Far: 296000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0027, 0.9698, 0.0200, 0.0074], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.96
Average Loss: -0.02245
Timesteps So Far: 300000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0029, 0.9680, 0.0215, 0.0076], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.34
Average Loss: -0.02084
Timesteps So Far: 304000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0026, 0.9689, 0.0218, 0.0067], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.25
Average Loss: -0.02488
Timesteps So Far: 308000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0018, 0.9743, 0.0192, 0.0047], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.62
Average Loss: -0.02063
Timesteps So Far: 312000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0018, 0.9758, 0.0177, 0.0048], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.58
Average Loss: -0.01605
Timesteps So Far: 316000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0014, 0.9820, 0.0132, 0.0034], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.59
Average Loss: -0.01643
Timesteps So Far: 320000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0012, 0.9854, 0.0104, 0.0030], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.64
Average Loss: -0.01757
Timesteps So Far: 324000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.4497e-04, 9.8921e-01, 7.5826e-03, 2.3669e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.09
Average Loss: -0.01818
Timesteps So Far: 328000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.6010e-04, 9.9177e-01, 5.7614e-03, 1.8075e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.91
Average Loss: -0.0142
Timesteps So Far: 332000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.9069e-04, 9.9396e-01, 4.2748e-03, 1.2781e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.0
Average Loss: -0.01625
Timesteps So Far: 336000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.6553e-04, 9.9608e-01, 2.9455e-03, 7.1390e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.29
Average Loss: -0.01602
Timesteps So Far: 340000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.5847e-05, 9.9838e-01, 1.2065e-03, 3.2594e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.89
Average Loss: -0.0108
Timesteps So Far: 344000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.6783e-05, 9.9846e-01, 1.3198e-03, 1.6942e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.41
Average Loss: 0.00297
Timesteps So Far: 348000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.8547e-05, 9.9549e-01, 4.3345e-03, 1.3012e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #88 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.35
Average Loss: 0.01553
Timesteps So Far: 352000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.0847e-05, 9.9910e-01, 8.2458e-04, 5.9070e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #89 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.98
Average Loss: 0.00011
Timesteps So Far: 356000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.7780e-05, 9.9869e-01, 1.2129e-03, 7.3161e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #90 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.98
Average Loss: -0.00075
Timesteps So Far: 360000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.2902e-05, 9.9879e-01, 1.0883e-03, 8.8454e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #91 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.82
Average Loss: -0.00018
Timesteps So Far: 364000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.9489e-05, 9.9860e-01, 1.2989e-03, 7.3349e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #92 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.96
Average Loss: -0.00012
Timesteps So Far: 368000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.3301e-05, 9.9894e-01, 9.7918e-04, 5.6853e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #93 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.95
Average Loss: -0.00021
Timesteps So Far: 372000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.9554e-05, 9.9911e-01, 8.2403e-04, 4.6844e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #94 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.96
Average Loss: -0.00024
Timesteps So Far: 376000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.8066e-05, 9.9930e-01, 6.3906e-04, 4.4428e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #95 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.96
Average Loss: -0.00025
Timesteps So Far: 380000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.6199e-05, 9.9934e-01, 6.0355e-04, 3.9063e-05],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

