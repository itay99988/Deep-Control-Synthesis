Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 4000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 4000 timesteps per batch for a total of 1500000 timesteps
tensor([0.1986, 0.2869, 0.2489, 0.2656], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.2
Average Loss: 0.2041
Timesteps So Far: 4000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2134, 0.2752, 0.2527, 0.2587], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.68
Average Loss: 0.14441
Timesteps So Far: 8000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1971, 0.2899, 0.2609, 0.2521], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.3
Average Loss: -0.00519
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1834, 0.3077, 0.2619, 0.2470], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.39
Average Loss: -0.02727
Timesteps So Far: 16000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1992, 0.2906, 0.2612, 0.2489], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.0
Average Loss: -0.04587
Timesteps So Far: 20000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2166, 0.2684, 0.2643, 0.2507], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.94
Average Loss: -0.05832
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2268, 0.2641, 0.2549, 0.2542], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.64
Average Loss: -0.05841
Timesteps So Far: 28000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2345, 0.2648, 0.2475, 0.2532], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.45
Average Loss: -0.06979
Timesteps So Far: 32000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2348, 0.2667, 0.2473, 0.2513], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.72
Average Loss: -0.06039
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2305, 0.2679, 0.2489, 0.2527], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.06
Average Loss: -0.07001
Timesteps So Far: 40000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2321, 0.2698, 0.2479, 0.2503], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.69
Average Loss: -0.06284
Timesteps So Far: 44000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2290, 0.2691, 0.2486, 0.2533], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.26
Average Loss: -0.06135
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2253, 0.2704, 0.2485, 0.2558], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.69
Average Loss: -0.05717
Timesteps So Far: 52000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2168, 0.2802, 0.2514, 0.2516], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.79
Average Loss: -0.0556
Timesteps So Far: 56000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2140, 0.2812, 0.2489, 0.2559], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.89
Average Loss: -0.06214
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1890, 0.2895, 0.2582, 0.2633], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.74
Average Loss: -0.05967
Timesteps So Far: 64000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1851, 0.3067, 0.2521, 0.2561], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.01
Average Loss: -0.06928
Timesteps So Far: 68000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1838, 0.3080, 0.2446, 0.2636], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.38
Average Loss: -0.06612
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1874, 0.3068, 0.2370, 0.2688], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.95
Average Loss: -0.06784
Timesteps So Far: 76000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1828, 0.3100, 0.2421, 0.2651], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.21
Average Loss: -0.06736
Timesteps So Far: 80000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1844, 0.2942, 0.2531, 0.2683], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.69
Average Loss: -0.06987
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1919, 0.2864, 0.2644, 0.2574], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.36
Average Loss: -0.07058
Timesteps So Far: 88000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1888, 0.2801, 0.2650, 0.2661], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.6
Average Loss: -0.06845
Timesteps So Far: 92000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1941, 0.2700, 0.2684, 0.2675], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.98
Average Loss: -0.06767
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1974, 0.2774, 0.2646, 0.2606], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.1
Average Loss: -0.05831
Timesteps So Far: 100000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1997, 0.2866, 0.2691, 0.2446], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.6
Average Loss: -0.05909
Timesteps So Far: 104000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2049, 0.2832, 0.2698, 0.2422], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.1
Average Loss: -0.05679
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2261, 0.2879, 0.2554, 0.2306], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.58
Average Loss: -0.05766
Timesteps So Far: 112000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2465, 0.2775, 0.2356, 0.2404], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.49
Average Loss: -0.06057
Timesteps So Far: 116000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2415, 0.2725, 0.2555, 0.2306], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.64
Average Loss: -0.05554
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2279, 0.2753, 0.2624, 0.2344], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.55
Average Loss: -0.0612
Timesteps So Far: 124000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2245, 0.2798, 0.2582, 0.2376], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.34
Average Loss: -0.05402
Timesteps So Far: 128000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2355, 0.2791, 0.2418, 0.2436], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.98
Average Loss: -0.05438
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2391, 0.2795, 0.2359, 0.2455], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.58
Average Loss: -0.05062
Timesteps So Far: 136000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2480, 0.2762, 0.2343, 0.2415], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.2
Average Loss: -0.05553
Timesteps So Far: 140000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2411, 0.2922, 0.2382, 0.2285], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.02
Average Loss: -0.04721
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2156, 0.3065, 0.2419, 0.2360], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.54
Average Loss: -0.04708
Timesteps So Far: 148000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2116, 0.2901, 0.2529, 0.2454], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.09
Average Loss: -0.05364
Timesteps So Far: 152000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2069, 0.3077, 0.2432, 0.2422], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.35
Average Loss: -0.04254
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2193, 0.3102, 0.2586, 0.2119], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.84
Average Loss: -0.05405
Timesteps So Far: 160000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2014, 0.3299, 0.2381, 0.2306], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.3
Average Loss: -0.04424
Timesteps So Far: 164000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2060, 0.3244, 0.2389, 0.2307], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.15
Average Loss: -0.05913
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1692, 0.3733, 0.2284, 0.2291], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.06
Average Loss: -0.04596
Timesteps So Far: 172000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1533, 0.4153, 0.2171, 0.2143], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.55
Average Loss: -0.05335
Timesteps So Far: 176000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1477, 0.4401, 0.2009, 0.2114], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.64
Average Loss: -0.04899
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1403, 0.4822, 0.1945, 0.1830], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.95
Average Loss: -0.05505
Timesteps So Far: 184000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1324, 0.5119, 0.1732, 0.1825], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.34
Average Loss: -0.05
Timesteps So Far: 188000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1042, 0.5622, 0.1628, 0.1708], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.76
Average Loss: -0.05309
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0932, 0.5694, 0.1670, 0.1705], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.92
Average Loss: -0.04868
Timesteps So Far: 196000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0823, 0.5723, 0.1761, 0.1693], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.86
Average Loss: -0.04323
Timesteps So Far: 200000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0840, 0.5518, 0.1853, 0.1788], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.05
Average Loss: -0.05316
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0666, 0.5851, 0.1683, 0.1799], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.1
Average Loss: -0.04751
Timesteps So Far: 208000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0510, 0.6249, 0.1538, 0.1704], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -14.79
Average Loss: -0.05229
Timesteps So Far: 212000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0350, 0.6797, 0.1294, 0.1559], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.36
Average Loss: -0.05189
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0283, 0.7067, 0.1119, 0.1531], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.51
Average Loss: -0.05375
Timesteps So Far: 220000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0228, 0.7427, 0.0999, 0.1346], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.46
Average Loss: -0.05242
Timesteps So Far: 224000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0123, 0.8263, 0.0638, 0.0976], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.81
Average Loss: -0.04729
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0092, 0.8874, 0.0378, 0.0656], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.28
Average Loss: -0.0486
Timesteps So Far: 232000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0037, 0.9427, 0.0177, 0.0358], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.12
Average Loss: -0.04386
Timesteps So Far: 236000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0046, 0.9425, 0.0223, 0.0306], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.11
Average Loss: -0.05037
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0031, 0.9596, 0.0175, 0.0198], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.1
Average Loss: -0.04867
Timesteps So Far: 244000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.4111e-04, 9.8702e-01, 4.7380e-03, 7.6038e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.95
Average Loss: -0.04108
Timesteps So Far: 248000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.9561e-04, 9.8512e-01, 5.6577e-03, 8.4299e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.72
Average Loss: -0.03827
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.2723e-04, 9.8417e-01, 6.9498e-03, 7.9569e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.74
Average Loss: -0.04187
Timesteps So Far: 256000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.0163e-04, 9.8602e-01, 6.5542e-03, 6.7223e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.46
Average Loss: -0.03099
Timesteps So Far: 260000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.7819e-04, 9.8907e-01, 5.3893e-03, 5.0646e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.52
Average Loss: -0.0313
Timesteps So Far: 264000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.5589e-04, 9.9094e-01, 4.4765e-03, 4.2307e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.7
Average Loss: -0.02128
Timesteps So Far: 268000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.8050e-04, 9.9183e-01, 3.6535e-03, 4.2396e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.79
Average Loss: -0.0227
Timesteps So Far: 272000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.4708e-04, 9.9254e-01, 3.2625e-03, 3.9530e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.05
Average Loss: -0.01863
Timesteps So Far: 276000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.3996e-04, 9.9489e-01, 2.0766e-03, 2.8948e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.0
Average Loss: -0.02099
Timesteps So Far: 280000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.2633e-05, 9.9624e-01, 1.4669e-03, 2.2211e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.6
Average Loss: -0.01741
Timesteps So Far: 284000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.3687e-05, 9.9517e-01, 2.1955e-03, 2.5454e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.54
Average Loss: -0.01977
Timesteps So Far: 288000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.7772e-04, 9.9212e-01, 4.2855e-03, 3.4170e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.11
Average Loss: -0.0243
Timesteps So Far: 292000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.5395e-04, 9.8369e-01, 1.0927e-02, 5.0247e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.35
Average Loss: -0.02255
Timesteps So Far: 296000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.3825e-04, 9.9132e-01, 5.3464e-03, 3.1964e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.12
Average Loss: -0.0164
Timesteps So Far: 300000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0195e-04, 9.9228e-01, 5.0192e-03, 2.6008e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.02
Average Loss: -0.01986
Timesteps So Far: 304000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.5193e-05, 9.9674e-01, 2.1551e-03, 1.0760e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.4
Average Loss: -0.02027
Timesteps So Far: 308000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.4593e-05, 9.9745e-01, 1.7307e-03, 7.9975e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.15
Average Loss: -0.01166
Timesteps So Far: 312000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.2262e-05, 9.9282e-01, 5.6559e-03, 1.4963e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.55
Average Loss: -0.01776
Timesteps So Far: 316000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.9596e-06, 9.9824e-01, 1.3696e-03, 3.9212e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.69
Average Loss: -0.01048
Timesteps So Far: 320000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.5290e-06, 9.9855e-01, 1.1913e-03, 2.5532e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.04
Average Loss: -0.01154
Timesteps So Far: 324000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.5305e-06, 9.9844e-01, 1.3150e-03, 2.4049e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.66
Average Loss: -0.02223
Timesteps So Far: 328000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.3019e-06, 9.9811e-01, 1.6652e-03, 2.2845e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.68
Average Loss: -0.00106
Timesteps So Far: 332000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.5234e-07, 9.9667e-01, 3.2051e-03, 1.2699e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.6
Average Loss: -0.00188
Timesteps So Far: 336000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.2628e-07, 9.9692e-01, 2.9846e-03, 9.1218e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.95
Average Loss: -0.00042
Timesteps So Far: 340000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.2757e-07, 9.9913e-01, 8.2747e-04, 4.4522e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.54
Average Loss: -0.00337
Timesteps So Far: 344000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.1499e-08, 9.9969e-01, 2.9140e-04, 2.1025e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.96
Average Loss: -0.00025
Timesteps So Far: 348000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.3016e-08, 9.9957e-01, 4.0241e-04, 2.9982e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #88 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.99
Average Loss: -0.00021
Timesteps So Far: 352000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.5657e-08, 9.9956e-01, 4.0393e-04, 3.5703e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #89 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: 0.0
Timesteps So Far: 356000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.2714e-08, 9.9964e-01, 3.2898e-04, 3.3721e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #90 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.99
Average Loss: -8e-05
Timesteps So Far: 360000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.9761e-08, 9.9973e-01, 2.4348e-04, 3.0501e-05],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

