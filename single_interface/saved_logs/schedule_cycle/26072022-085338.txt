Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 4000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 4000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2422, 0.2732, 0.2586, 0.2260], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.18
Average Loss: 0.21432
Timesteps So Far: 4000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2417, 0.2508, 0.2554, 0.2520], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.95
Average Loss: 0.11453
Timesteps So Far: 8000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2404, 0.2427, 0.2478, 0.2691], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.9
Average Loss: -0.02624
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2397, 0.2383, 0.2391, 0.2829], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.74
Average Loss: -0.04343
Timesteps So Far: 16000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2448, 0.2368, 0.2441, 0.2743], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.69
Average Loss: -0.02754
Timesteps So Far: 20000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2515, 0.2533, 0.2241, 0.2711], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.71
Average Loss: -0.05904
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2501, 0.2500, 0.2355, 0.2644], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.21
Average Loss: -0.07043
Timesteps So Far: 28000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2498, 0.2455, 0.2468, 0.2579], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.4
Average Loss: -0.07323
Timesteps So Far: 32000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2505, 0.2403, 0.2511, 0.2581], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.94
Average Loss: -0.07171
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2496, 0.2401, 0.2524, 0.2579], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.22
Average Loss: -0.07751
Timesteps So Far: 40000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2483, 0.2383, 0.2517, 0.2617], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.41
Average Loss: -0.07904
Timesteps So Far: 44000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2506, 0.2387, 0.2506, 0.2600], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.99
Average Loss: -0.07439
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2463, 0.2382, 0.2508, 0.2646], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.61
Average Loss: -0.07912
Timesteps So Far: 52000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2458, 0.2410, 0.2467, 0.2665], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.6
Average Loss: -0.07078
Timesteps So Far: 56000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2331, 0.2509, 0.2420, 0.2739], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.78
Average Loss: -0.07212
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2414, 0.2504, 0.2521, 0.2561], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.35
Average Loss: -0.07804
Timesteps So Far: 64000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2478, 0.2523, 0.2537, 0.2462], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.68
Average Loss: -0.07595
Timesteps So Far: 68000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2459, 0.2531, 0.2535, 0.2474], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.14
Average Loss: -0.07716
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2487, 0.2448, 0.2420, 0.2644], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.94
Average Loss: -0.0778
Timesteps So Far: 76000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2468, 0.2471, 0.2374, 0.2687], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.12
Average Loss: -0.07961
Timesteps So Far: 80000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2412, 0.2522, 0.2422, 0.2644], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.11
Average Loss: -0.07798
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2377, 0.2459, 0.2384, 0.2779], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.0
Average Loss: -0.07701
Timesteps So Far: 88000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2360, 0.2380, 0.2484, 0.2776], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.75
Average Loss: -0.07598
Timesteps So Far: 92000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2414, 0.2623, 0.2245, 0.2718], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.46
Average Loss: -0.07887
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2422, 0.2685, 0.2380, 0.2513], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.62
Average Loss: -0.07679
Timesteps So Far: 100000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2395, 0.2625, 0.2408, 0.2572], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.81
Average Loss: -0.07714
Timesteps So Far: 104000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2314, 0.2659, 0.2427, 0.2600], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.21
Average Loss: -0.08027
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2285, 0.2628, 0.2573, 0.2515], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.98
Average Loss: -0.07896
Timesteps So Far: 112000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2298, 0.2667, 0.2418, 0.2617], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.76
Average Loss: -0.07764
Timesteps So Far: 116000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2263, 0.2679, 0.2497, 0.2561], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.51
Average Loss: -0.07796
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2210, 0.2705, 0.2624, 0.2462], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.59
Average Loss: -0.07879
Timesteps So Far: 124000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2251, 0.2749, 0.2605, 0.2394], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.62
Average Loss: -0.07813
Timesteps So Far: 128000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2092, 0.2661, 0.2631, 0.2617], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.78
Average Loss: -0.07613
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2230, 0.2572, 0.2590, 0.2608], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.74
Average Loss: -0.07845
Timesteps So Far: 136000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2292, 0.2726, 0.2394, 0.2589], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.88
Average Loss: -0.07758
Timesteps So Far: 140000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2021, 0.2924, 0.2539, 0.2516], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.79
Average Loss: -0.07828
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2033, 0.2897, 0.2593, 0.2477], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.15
Average Loss: -0.07479
Timesteps So Far: 148000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1838, 0.3108, 0.2541, 0.2513], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.68
Average Loss: -0.0765
Timesteps So Far: 152000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1872, 0.3179, 0.2621, 0.2328], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.56
Average Loss: -0.07432
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1981, 0.3443, 0.2401, 0.2175], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.09
Average Loss: -0.0723
Timesteps So Far: 160000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1854, 0.3883, 0.2287, 0.1976], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.86
Average Loss: -0.07427
Timesteps So Far: 164000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1376, 0.4527, 0.2073, 0.2024], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.21
Average Loss: -0.06673
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1198, 0.4762, 0.2041, 0.1999], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.9
Average Loss: -0.06623
Timesteps So Far: 172000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1186, 0.4785, 0.2042, 0.1987], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.88
Average Loss: -0.06802
Timesteps So Far: 176000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1245, 0.5100, 0.1801, 0.1855], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.84
Average Loss: -0.05823
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1142, 0.5075, 0.1955, 0.1828], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.36
Average Loss: -0.05214
Timesteps So Far: 184000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1255, 0.4963, 0.1940, 0.1842], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.0
Average Loss: -0.05976
Timesteps So Far: 188000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0991, 0.5474, 0.1852, 0.1683], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.26
Average Loss: -0.05152
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0866, 0.5919, 0.1465, 0.1749], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.08
Average Loss: -0.05267
Timesteps So Far: 196000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0808, 0.6009, 0.1442, 0.1742], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.96
Average Loss: -0.03979
Timesteps So Far: 200000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0794, 0.6245, 0.1312, 0.1648], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.35
Average Loss: -0.03827
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0666, 0.6557, 0.1105, 0.1672], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.55
Average Loss: -0.04505
Timesteps So Far: 208000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0459, 0.7040, 0.0854, 0.1647], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.2
Average Loss: -0.02781
Timesteps So Far: 212000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0323, 0.7565, 0.0611, 0.1501], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -14.86
Average Loss: -0.03864
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0151, 0.8550, 0.0257, 0.1043], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.7
Average Loss: -0.03941
Timesteps So Far: 220000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0046, 0.9546, 0.0093, 0.0315], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.84
Average Loss: -0.03476
Timesteps So Far: 224000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0040, 0.9698, 0.0076, 0.0185], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.34
Average Loss: -0.04123
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0040, 0.9724, 0.0072, 0.0164], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.44
Average Loss: -0.03718
Timesteps So Far: 232000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0055, 0.9656, 0.0104, 0.0185], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.74
Average Loss: -0.03593
Timesteps So Far: 236000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0029, 0.9818, 0.0045, 0.0108], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.35
Average Loss: -0.03506
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0027, 0.9872, 0.0028, 0.0072], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.46
Average Loss: -0.03635
Timesteps So Far: 244000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0031, 0.9890, 0.0022, 0.0057], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.06
Average Loss: -0.03527
Timesteps So Far: 248000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0029, 0.9908, 0.0020, 0.0043], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.65
Average Loss: -0.02875
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0042, 0.9873, 0.0026, 0.0059], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.09
Average Loss: -0.02835
Timesteps So Far: 256000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0032, 0.9891, 0.0023, 0.0053], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.96
Average Loss: -0.02135
Timesteps So Far: 260000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0021, 0.9928, 0.0012, 0.0040], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.66
Average Loss: -0.02146
Timesteps So Far: 264000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.5096e-03, 9.9477e-01, 7.5846e-04, 2.9658e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.96
Average Loss: -0.03106
Timesteps So Far: 268000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.1468e-04, 9.9769e-01, 2.5444e-04, 1.5419e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.62
Average Loss: -0.0405
Timesteps So Far: 272000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.1297e-04, 9.9609e-01, 5.1676e-04, 2.7784e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.95
Average Loss: -0.03559
Timesteps So Far: 276000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.5779e-04, 9.9463e-01, 5.6546e-04, 4.3505e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.48
Average Loss: -0.03952
Timesteps So Far: 280000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.0687e-04, 9.9493e-01, 6.2089e-04, 3.9381e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.98
Average Loss: -0.05047
Timesteps So Far: 284000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.2090e-04, 9.9548e-01, 1.7675e-04, 4.0187e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.7
Average Loss: -0.03658
Timesteps So Far: 288000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.5065e-04, 9.9857e-01, 4.5605e-05, 1.2328e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.41
Average Loss: -0.03471
Timesteps So Far: 292000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.4652e-04, 9.9888e-01, 3.5190e-05, 9.3443e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.88
Average Loss: -0.04901
Timesteps So Far: 296000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.1346e-04, 9.9898e-01, 1.4146e-05, 8.9318e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.72
Average Loss: -0.0599
Timesteps So Far: 300000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.4667e-05, 9.9933e-01, 9.1131e-06, 5.8415e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.05
Average Loss: -0.06595
Timesteps So Far: 304000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.6228e-05, 9.9965e-01, 5.3118e-06, 2.9468e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.24
Average Loss: -0.07098
Timesteps So Far: 308000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.2487e-05, 9.9967e-01, 4.1532e-06, 2.7891e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.06
Average Loss: -0.06746
Timesteps So Far: 312000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.0111e-05, 9.9964e-01, 2.5805e-06, 3.1224e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.74
Average Loss: -0.06826
Timesteps So Far: 316000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.7218e-05, 9.9982e-01, 2.9029e-06, 1.5458e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.65
Average Loss: -0.05647
Timesteps So Far: 320000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.6229e-05, 9.9989e-01, 2.7102e-06, 8.6244e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.98
Average Loss: -0.04104
Timesteps So Far: 324000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.5848e-05, 9.9987e-01, 4.0603e-06, 1.0678e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.36
Average Loss: -0.0322
Timesteps So Far: 328000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.6060e-05, 9.9987e-01, 4.2542e-06, 1.1046e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.44
Average Loss: -0.0412
Timesteps So Far: 332000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.6077e-05, 9.9987e-01, 4.8841e-06, 1.1301e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.31
Average Loss: -0.04532
Timesteps So Far: 336000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.1988e-05, 9.9990e-01, 5.8175e-06, 8.5898e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.49
Average Loss: -0.04647
Timesteps So Far: 340000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.0221e-06, 9.9993e-01, 4.9385e-06, 6.0283e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.55
Average Loss: -0.02769
Timesteps So Far: 344000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.9560e-06, 9.9997e-01, 2.7758e-06, 2.3092e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.66
Average Loss: -0.0489
Timesteps So Far: 348000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.6371e-06, 9.9995e-01, 5.5053e-06, 3.9967e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #88 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.78
Average Loss: -0.0155
Timesteps So Far: 352000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.0789e-06, 9.9996e-01, 3.1323e-06, 2.9499e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #89 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.25
Average Loss: -0.03452
Timesteps So Far: 356000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.4725e-06, 9.9996e-01, 7.5917e-06, 2.9937e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #90 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.19
Average Loss: -0.0296
Timesteps So Far: 360000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.5478e-06, 9.9992e-01, 3.7414e-05, 3.5982e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #91 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.46
Average Loss: -0.04025
Timesteps So Far: 364000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.9545e-06, 9.9989e-01, 5.3734e-05, 4.4676e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #92 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.88
Average Loss: -0.02689
Timesteps So Far: 368000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.5366e-06, 9.9992e-01, 2.9631e-05, 4.5140e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #93 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -0.01694
Timesteps So Far: 372000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.8440e-06, 9.9988e-01, 3.9282e-05, 7.3498e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #94 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.76
Average Loss: -0.01545
Timesteps So Far: 376000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.8782e-05, 9.9968e-01, 6.4290e-05, 2.3651e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #95 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.99
Average Loss: -0.02547
Timesteps So Far: 380000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.7847e-05, 9.9945e-01, 7.9747e-05, 4.3498e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #96 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.66
Average Loss: -0.0106
Timesteps So Far: 384000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.0073e-05, 9.9975e-01, 3.4201e-05, 1.9580e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #97 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.84
Average Loss: -0.00921
Timesteps So Far: 388000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.8426e-09, 1.0000e+00, 5.2540e-12, 9.3173e-08],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #98 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.74
Average Loss: -0.01061
Timesteps So Far: 392000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.4203e-07, 1.0000e+00, 7.4522e-10, 4.2526e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #99 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.94
Average Loss: 0.00074
Timesteps So Far: 396000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.0436e-06, 9.9998e-01, 1.3369e-07, 1.4390e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #100 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: 6e-05
Timesteps So Far: 400000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.9178e-06, 9.9999e-01, 1.6165e-07, 3.4257e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #101 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.95
Average Loss: -0.0006
Timesteps So Far: 404000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0571e-06, 1.0000e+00, 1.4587e-07, 1.1382e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #102 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.99
Average Loss: -0.00045
Timesteps So Far: 408000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.2282e-07, 1.0000e+00, 1.4343e-07, 6.8068e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #103 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.99
Average Loss: -0.00021
Timesteps So Far: 412000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.1925e-07, 1.0000e+00, 1.8217e-07, 5.7574e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #104 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.98
Average Loss: -0.00066
Timesteps So Far: 416000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.2165e-07, 1.0000e+00, 1.9145e-07, 7.9213e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #105 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -0.00042
Timesteps So Far: 420000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.6491e-07, 1.0000e+00, 2.1799e-07, 9.6786e-07],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

