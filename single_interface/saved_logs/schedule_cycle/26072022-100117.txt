Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 4000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 4000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2598, 0.2704, 0.2510, 0.2188], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.18
Average Loss: 0.20572
Timesteps So Far: 4000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2404, 0.2956, 0.2313, 0.2328], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.42
Average Loss: 0.03625
Timesteps So Far: 8000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2113, 0.3280, 0.2134, 0.2472], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.16
Average Loss: -0.0194
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2151, 0.3231, 0.2160, 0.2459], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.14
Average Loss: -0.04031
Timesteps So Far: 16000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2385, 0.2953, 0.2292, 0.2370], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.05
Average Loss: -0.05804
Timesteps So Far: 20000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2537, 0.2758, 0.2386, 0.2319], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.99
Average Loss: -0.06375
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2577, 0.2703, 0.2413, 0.2307], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.36
Average Loss: -0.06535
Timesteps So Far: 28000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2565, 0.2741, 0.2384, 0.2310], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.16
Average Loss: -0.04892
Timesteps So Far: 32000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2533, 0.2726, 0.2409, 0.2332], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.04
Average Loss: -0.01885
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2468, 0.2755, 0.2407, 0.2370], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.35
Average Loss: 0.01445
Timesteps So Far: 40000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2365, 0.2803, 0.2417, 0.2415], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.76
Average Loss: -0.03389
Timesteps So Far: 44000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2271, 0.2849, 0.2353, 0.2526], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.99
Average Loss: -0.01298
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2211, 0.2866, 0.2292, 0.2631], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.26
Average Loss: -0.04283
Timesteps So Far: 52000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2167, 0.2905, 0.2250, 0.2679], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.98
Average Loss: -0.03067
Timesteps So Far: 56000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2165, 0.2884, 0.2293, 0.2658], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.41
Average Loss: -0.02088
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2159, 0.2888, 0.2329, 0.2624], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.36
Average Loss: -0.03227
Timesteps So Far: 64000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2230, 0.2818, 0.2378, 0.2574], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.08
Average Loss: -0.01403
Timesteps So Far: 68000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2246, 0.2777, 0.2404, 0.2573], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.23
Average Loss: -0.0283
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2176, 0.2765, 0.2464, 0.2595], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.68
Average Loss: -0.03985
Timesteps So Far: 76000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2133, 0.2785, 0.2583, 0.2499], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.02
Average Loss: -0.02554
Timesteps So Far: 80000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2062, 0.2904, 0.2555, 0.2479], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.45
Average Loss: -0.03356
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1882, 0.3037, 0.2286, 0.2795], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.01
Average Loss: -0.03779
Timesteps So Far: 88000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1843, 0.3332, 0.2005, 0.2821], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.96
Average Loss: -0.02092
Timesteps So Far: 92000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1574, 0.3402, 0.2210, 0.2814], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.1
Average Loss: -0.02893
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1558, 0.3774, 0.2332, 0.2336], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.04
Average Loss: -0.01207
Timesteps So Far: 100000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1622, 0.3957, 0.2165, 0.2256], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.74
Average Loss: -0.02638
Timesteps So Far: 104000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1617, 0.4119, 0.2187, 0.2078], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.05
Average Loss: -0.033
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1599, 0.4090, 0.2212, 0.2099], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.69
Average Loss: -0.03164
Timesteps So Far: 112000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1637, 0.4152, 0.2202, 0.2009], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.74
Average Loss: -0.02843
Timesteps So Far: 116000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1659, 0.4196, 0.2147, 0.1998], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.24
Average Loss: -0.02413
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1634, 0.4235, 0.2011, 0.2119], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.08
Average Loss: -0.03377
Timesteps So Far: 124000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1619, 0.4298, 0.2052, 0.2031], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.38
Average Loss: -0.03027
Timesteps So Far: 128000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1509, 0.4371, 0.2071, 0.2049], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.66
Average Loss: -0.02997
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1507, 0.4542, 0.2009, 0.1942], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.64
Average Loss: -0.02898
Timesteps So Far: 136000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1463, 0.4598, 0.1972, 0.1966], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.99
Average Loss: -0.03498
Timesteps So Far: 140000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1399, 0.4684, 0.1980, 0.1937], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.45
Average Loss: -0.03134
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1351, 0.4687, 0.2014, 0.1947], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.59
Average Loss: -0.04129
Timesteps So Far: 148000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1311, 0.4878, 0.1843, 0.1968], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.27
Average Loss: -0.02603
Timesteps So Far: 152000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1461, 0.4748, 0.1804, 0.1987], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.85
Average Loss: -0.03034
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1592, 0.4593, 0.1857, 0.1958], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.46
Average Loss: -0.03261
Timesteps So Far: 160000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1596, 0.4705, 0.1803, 0.1895], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.73
Average Loss: -0.03798
Timesteps So Far: 164000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1482, 0.4885, 0.1620, 0.2013], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.74
Average Loss: -0.04074
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1465, 0.5128, 0.1449, 0.1958], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.89
Average Loss: -0.03843
Timesteps So Far: 172000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1474, 0.5130, 0.1461, 0.1935], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.3
Average Loss: -0.04288
Timesteps So Far: 176000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1454, 0.5257, 0.1470, 0.1818], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.94
Average Loss: -0.03062
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1404, 0.5566, 0.1256, 0.1774], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.31
Average Loss: -0.03491
Timesteps So Far: 184000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1347, 0.5699, 0.1226, 0.1727], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.42
Average Loss: -0.04085
Timesteps So Far: 188000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1288, 0.5809, 0.1217, 0.1686], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.4
Average Loss: -0.02766
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1213, 0.5941, 0.1095, 0.1751], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.12
Average Loss: -0.03661
Timesteps So Far: 196000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1110, 0.6102, 0.1046, 0.1742], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.29
Average Loss: -0.03748
Timesteps So Far: 200000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1069, 0.6257, 0.1005, 0.1669], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -14.98
Average Loss: -0.04093
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0939, 0.6512, 0.0987, 0.1562], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -14.79
Average Loss: -0.03771
Timesteps So Far: 208000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0773, 0.6866, 0.0906, 0.1455], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.9
Average Loss: -0.03888
Timesteps So Far: 212000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0608, 0.7311, 0.0808, 0.1273], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.75
Average Loss: -0.03791
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0413, 0.7971, 0.0628, 0.0989], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.75
Average Loss: -0.04026
Timesteps So Far: 220000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0295, 0.8539, 0.0438, 0.0728], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.16
Average Loss: -0.04802
Timesteps So Far: 224000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0196, 0.9049, 0.0277, 0.0479], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.35
Average Loss: -0.0415
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0141, 0.9370, 0.0179, 0.0311], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.15
Average Loss: -0.04254
Timesteps So Far: 232000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0112, 0.9547, 0.0136, 0.0205], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.72
Average Loss: -0.04409
Timesteps So Far: 236000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0070, 0.9716, 0.0090, 0.0124], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.41
Average Loss: -0.0378
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0047, 0.9799, 0.0065, 0.0089], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.14
Average Loss: -0.03659
Timesteps So Far: 244000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0045, 0.9816, 0.0056, 0.0083], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.85
Average Loss: -0.03463
Timesteps So Far: 248000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0058, 0.9777, 0.0064, 0.0101], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.09
Average Loss: -0.02828
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0070, 0.9729, 0.0080, 0.0122], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.93
Average Loss: -0.0294
Timesteps So Far: 256000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0065, 0.9741, 0.0080, 0.0114], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.25
Average Loss: -0.00847
Timesteps So Far: 260000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0053, 0.9778, 0.0069, 0.0099], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.58
Average Loss: -0.01437
Timesteps So Far: 264000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0052, 0.9779, 0.0068, 0.0101], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.96
Average Loss: -0.02028
Timesteps So Far: 268000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0050, 0.9790, 0.0065, 0.0095], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.08
Average Loss: -0.01691
Timesteps So Far: 272000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0053, 0.9779, 0.0071, 0.0097], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.39
Average Loss: -0.01681
Timesteps So Far: 276000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0056, 0.9774, 0.0071, 0.0100], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.28
Average Loss: -0.01683
Timesteps So Far: 280000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0050, 0.9797, 0.0062, 0.0091], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.62
Average Loss: -0.0163
Timesteps So Far: 284000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0049, 0.9804, 0.0060, 0.0086], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.32
Average Loss: -0.01989
Timesteps So Far: 288000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0041, 0.9844, 0.0044, 0.0072], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.98
Average Loss: -0.02111
Timesteps So Far: 292000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0027, 0.9886, 0.0034, 0.0053], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.71
Average Loss: -0.01598
Timesteps So Far: 296000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0023, 0.9902, 0.0027, 0.0048], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.52
Average Loss: -0.01462
Timesteps So Far: 300000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0021, 0.9908, 0.0025, 0.0046], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.49
Average Loss: -0.01569
Timesteps So Far: 304000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0017, 0.9924, 0.0020, 0.0039], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.55
Average Loss: -0.00929
Timesteps So Far: 308000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0013, 0.9940, 0.0016, 0.0030], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.71
Average Loss: -0.01226
Timesteps So Far: 312000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0012, 0.9949, 0.0014, 0.0025], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.25
Average Loss: -0.00741
Timesteps So Far: 316000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0013, 0.9941, 0.0016, 0.0029], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.08
Average Loss: -0.00874
Timesteps So Far: 320000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0012, 0.9945, 0.0017, 0.0026], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.94
Average Loss: -0.00541
Timesteps So Far: 324000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.5626e-04, 9.9570e-01, 1.3027e-03, 2.0368e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.31
Average Loss: -0.00428
Timesteps So Far: 328000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0011, 0.9953, 0.0014, 0.0022], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.7
Average Loss: -0.00447
Timesteps So Far: 332000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.5815e-04, 9.9644e-01, 9.8275e-04, 1.7171e-03],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.3
Average Loss: -0.00847
Timesteps So Far: 336000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.0809e-04, 9.9892e-01, 3.7252e-04, 5.0277e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.56
Average Loss: -0.00221
Timesteps So Far: 340000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.8804e-05, 9.9952e-01, 1.5815e-04, 2.4318e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.86
Average Loss: -0.00153
Timesteps So Far: 344000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.6567e-05, 9.9963e-01, 1.2854e-04, 1.9549e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.74
Average Loss: -0.00123
Timesteps So Far: 348000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.7802e-05, 9.9975e-01, 7.4909e-05, 1.4896e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #88 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.95
Average Loss: -0.00062
Timesteps So Far: 352000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.0715e-05, 9.9979e-01, 5.2249e-05, 1.3881e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #89 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -2e-05
Timesteps So Far: 356000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.1553e-05, 9.9977e-01, 5.9603e-05, 1.5044e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #90 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.91
Average Loss: -0.00096
Timesteps So Far: 360000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.0372e-05, 9.9977e-01, 5.9581e-05, 1.4976e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #91 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -1e-05
Timesteps So Far: 364000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.5529e-05, 9.9970e-01, 8.8618e-05, 1.8594e-04],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

