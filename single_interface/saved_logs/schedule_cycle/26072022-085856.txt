Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 4000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 4000 timesteps per batch for a total of 1500000 timesteps
tensor([0.2480, 0.2256, 0.2290, 0.2974], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.46
Average Loss: 0.26403
Timesteps So Far: 4000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2521, 0.2401, 0.2369, 0.2708], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.66
Average Loss: 0.21389
Timesteps So Far: 8000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2620, 0.2436, 0.2362, 0.2582], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.59
Average Loss: 0.12327
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2746, 0.2451, 0.2303, 0.2500], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.3
Average Loss: -0.01946
Timesteps So Far: 16000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2851, 0.2473, 0.2263, 0.2413], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.11
Average Loss: -0.04654
Timesteps So Far: 20000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2831, 0.2478, 0.2280, 0.2412], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.02
Average Loss: -0.05549
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2731, 0.2525, 0.2298, 0.2447], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.55
Average Loss: -0.04674
Timesteps So Far: 28000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2376, 0.2804, 0.2241, 0.2579], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.23
Average Loss: -0.03862
Timesteps So Far: 32000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2354, 0.2778, 0.2259, 0.2609], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.39
Average Loss: -0.0433
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2432, 0.2750, 0.2309, 0.2509], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.55
Average Loss: -0.05126
Timesteps So Far: 40000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2539, 0.2786, 0.2386, 0.2289], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.2
Average Loss: -0.0542
Timesteps So Far: 44000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2666, 0.2664, 0.2432, 0.2238], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.61
Average Loss: -0.05723
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2693, 0.2794, 0.2334, 0.2179], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.74
Average Loss: -0.06166
Timesteps So Far: 52000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2799, 0.2686, 0.2333, 0.2183], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.38
Average Loss: -0.05843
Timesteps So Far: 56000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2722, 0.2614, 0.2437, 0.2227], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.34
Average Loss: -0.06503
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2696, 0.2627, 0.2441, 0.2236], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.69
Average Loss: -0.06992
Timesteps So Far: 64000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2656, 0.2722, 0.2405, 0.2217], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.74
Average Loss: -0.07306
Timesteps So Far: 68000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2589, 0.2738, 0.2391, 0.2282], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.84
Average Loss: -0.07095
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2557, 0.2745, 0.2315, 0.2383], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.48
Average Loss: -0.06389
Timesteps So Far: 76000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2564, 0.2621, 0.2455, 0.2361], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.01
Average Loss: -0.06227
Timesteps So Far: 80000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2712, 0.2607, 0.2429, 0.2252], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.15
Average Loss: -0.05225
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2489, 0.2685, 0.2397, 0.2429], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.1
Average Loss: -0.05563
Timesteps So Far: 88000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2456, 0.2601, 0.2475, 0.2468], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.55
Average Loss: -0.05392
Timesteps So Far: 92000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2524, 0.2578, 0.2501, 0.2397], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -21.01
Average Loss: -0.05373
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2550, 0.2590, 0.2428, 0.2432], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.5
Average Loss: -0.04419
Timesteps So Far: 100000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2460, 0.2644, 0.2577, 0.2319], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.56
Average Loss: -0.03729
Timesteps So Far: 104000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2402, 0.2718, 0.2539, 0.2341], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.94
Average Loss: -0.02683
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2353, 0.2752, 0.2452, 0.2443], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.01
Average Loss: -0.0372
Timesteps So Far: 112000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2381, 0.2751, 0.2436, 0.2433], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.55
Average Loss: -0.03124
Timesteps So Far: 116000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2298, 0.2831, 0.2500, 0.2371], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.21
Average Loss: -0.0308
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2269, 0.2806, 0.2460, 0.2464], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.49
Average Loss: -0.02807
Timesteps So Far: 124000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2290, 0.2769, 0.2481, 0.2460], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.3
Average Loss: -0.03802
Timesteps So Far: 128000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2237, 0.2785, 0.2554, 0.2424], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.34
Average Loss: -0.03469
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2274, 0.2687, 0.2587, 0.2452], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.06
Average Loss: -0.0305
Timesteps So Far: 136000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2388, 0.2700, 0.2549, 0.2364], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.8
Average Loss: -0.03186
Timesteps So Far: 140000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2368, 0.2909, 0.2483, 0.2240], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.4
Average Loss: -0.03254
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2226, 0.3050, 0.2431, 0.2293], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.85
Average Loss: -0.03368
Timesteps So Far: 148000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2170, 0.3214, 0.2367, 0.2248], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -20.34
Average Loss: -0.02894
Timesteps So Far: 152000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2209, 0.3260, 0.2374, 0.2158], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.79
Average Loss: -0.02226
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2188, 0.3284, 0.2354, 0.2173], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.32
Average Loss: -0.03113
Timesteps So Far: 160000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2063, 0.3710, 0.2288, 0.1939], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.91
Average Loss: -0.03263
Timesteps So Far: 164000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1969, 0.3947, 0.2196, 0.1888], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.73
Average Loss: -0.03133
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1879, 0.4113, 0.2075, 0.1933], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.81
Average Loss: -0.0326
Timesteps So Far: 172000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1857, 0.4321, 0.2012, 0.1810], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.4
Average Loss: -0.03875
Timesteps So Far: 176000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1716, 0.4506, 0.1975, 0.1803], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.82
Average Loss: -0.03608
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1616, 0.4794, 0.1937, 0.1653], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.61
Average Loss: -0.02914
Timesteps So Far: 184000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1581, 0.5152, 0.1793, 0.1474], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.21
Average Loss: -0.03413
Timesteps So Far: 188000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1409, 0.5195, 0.1989, 0.1407], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.86
Average Loss: -0.02976
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1425, 0.5211, 0.2014, 0.1350], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.89
Average Loss: -0.02727
Timesteps So Far: 196000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1453, 0.5374, 0.1938, 0.1235], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.29
Average Loss: -0.03266
Timesteps So Far: 200000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1355, 0.5630, 0.1994, 0.1020], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.9
Average Loss: -0.02868
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1220, 0.6035, 0.1825, 0.0920], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.01
Average Loss: -0.03624
Timesteps So Far: 208000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1084, 0.6277, 0.1872, 0.0767], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.56
Average Loss: -0.03883
Timesteps So Far: 212000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0907, 0.6734, 0.1746, 0.0613], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.44
Average Loss: -0.03296
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0842, 0.6811, 0.1855, 0.0492], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.65
Average Loss: -0.04249
Timesteps So Far: 220000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0622, 0.7282, 0.1727, 0.0369], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -10.7
Average Loss: -0.05281
Timesteps So Far: 224000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0414, 0.8159, 0.1222, 0.0205], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.15
Average Loss: -0.04191
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0261, 0.8666, 0.0948, 0.0125], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.59
Average Loss: -0.04328
Timesteps So Far: 232000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0127, 0.9295, 0.0522, 0.0056], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.25
Average Loss: -0.04545
Timesteps So Far: 236000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0075, 0.9595, 0.0303, 0.0027], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.75
Average Loss: -0.04004
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0067, 0.9647, 0.0268, 0.0018], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.4
Average Loss: -0.04021
Timesteps So Far: 244000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.2044e-03, 9.8055e-01, 1.4304e-02, 9.3663e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.04
Average Loss: -0.03061
Timesteps So Far: 248000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.5123e-03, 9.8278e-01, 1.3013e-02, 6.8993e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.48
Average Loss: -0.03597
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.6256e-03, 9.8205e-01, 1.3763e-02, 5.6285e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.75
Average Loss: -0.02364
Timesteps So Far: 256000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.3395e-03, 9.8302e-01, 1.3193e-02, 4.5183e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.14
Average Loss: -0.02398
Timesteps So Far: 260000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.4737e-03, 9.8612e-01, 1.1060e-02, 3.4851e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.31
Average Loss: -0.01931
Timesteps So Far: 264000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.8246e-03, 9.8342e-01, 1.3359e-02, 3.9166e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.82
Average Loss: -0.02141
Timesteps So Far: 268000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.5300e-03, 9.8367e-01, 1.3455e-02, 3.4949e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.42
Average Loss: -0.01946
Timesteps So Far: 272000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.5233e-03, 9.8168e-01, 1.5492e-02, 3.0598e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.71
Average Loss: -0.01586
Timesteps So Far: 276000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.6162e-03, 9.8158e-01, 1.5527e-02, 2.8169e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.21
Average Loss: -0.02015
Timesteps So Far: 280000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.3493e-03, 9.8444e-01, 1.2977e-02, 2.3572e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.91
Average Loss: -0.01751
Timesteps So Far: 284000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.1577e-03, 9.8671e-01, 1.0912e-02, 2.2245e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.9
Average Loss: -0.01698
Timesteps So Far: 288000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.8240e-03, 9.8925e-01, 8.7362e-03, 1.8866e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.52
Average Loss: -0.01695
Timesteps So Far: 292000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.7285e-03, 9.8967e-01, 8.4480e-03, 1.5802e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.59
Average Loss: -0.01373
Timesteps So Far: 296000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.8034e-03, 9.8874e-01, 9.2947e-03, 1.5980e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.15
Average Loss: -0.01912
Timesteps So Far: 300000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.2260e-03, 9.9247e-01, 6.2017e-03, 1.0620e-04],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.4
Average Loss: -0.01879
Timesteps So Far: 304000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.0600e-03, 9.9168e-01, 7.1971e-03, 6.4709e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.96
Average Loss: -0.01501
Timesteps So Far: 308000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.5000e-04, 9.9258e-01, 6.6333e-03, 3.4613e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.9
Average Loss: -0.01175
Timesteps So Far: 312000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.5176e-04, 9.9580e-01, 3.7334e-03, 1.8172e-05],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.06
Average Loss: -0.01299
Timesteps So Far: 316000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.9187e-04, 9.9702e-01, 2.7832e-03, 6.8560e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.48
Average Loss: -0.01046
Timesteps So Far: 320000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.1094e-04, 9.9341e-01, 6.3685e-03, 7.6389e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.41
Average Loss: -0.00991
Timesteps So Far: 324000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.9129e-05, 9.9830e-01, 1.6337e-03, 2.1697e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.19
Average Loss: -0.00637
Timesteps So Far: 328000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.0916e-05, 9.9856e-01, 1.3839e-03, 1.4688e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.59
Average Loss: -0.00605
Timesteps So Far: 332000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.9720e-05, 9.9842e-01, 1.5244e-03, 1.6176e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.5
Average Loss: -0.0029
Timesteps So Far: 336000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.2275e-05, 9.9831e-01, 1.6577e-03, 1.1171e-06],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.64
Average Loss: -0.00258
Timesteps So Far: 340000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.1504e-05, 9.9808e-01, 1.9021e-03, 7.8519e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.81
Average Loss: -0.00137
Timesteps So Far: 344000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.2101e-05, 9.9852e-01, 1.4627e-03, 4.7886e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.89
Average Loss: -0.00098
Timesteps So Far: 348000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.9505e-06, 9.9880e-01, 1.1977e-03, 2.9250e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #88 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.61
Average Loss: -0.00232
Timesteps So Far: 352000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.8889e-06, 9.9941e-01, 5.8231e-04, 2.6575e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #89 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.7
Average Loss: -0.00148
Timesteps So Far: 356000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.4327e-06, 9.9988e-01, 1.2201e-04, 1.7554e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #90 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -1e-05
Timesteps So Far: 360000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.9914e-06, 9.9993e-01, 6.9448e-05, 1.7885e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #91 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.96
Average Loss: -0.00043
Timesteps So Far: 364000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.6701e-06, 9.9993e-01, 7.1662e-05, 1.4916e-07],
       grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #92 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.61
Average Loss: -0.002
Timesteps So Far: 368000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.0132e-07, 9.9998e-01, 2.1852e-05, 1.8393e-08],
       grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

