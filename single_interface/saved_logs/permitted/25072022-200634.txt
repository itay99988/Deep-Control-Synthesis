Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.3062, 0.3035, 0.3903], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.97
Average Loss: -0.00096
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3005, 0.3430, 0.3565], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.45
Average Loss: -0.0026
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3001, 0.3252, 0.3748], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.42
Average Loss: -0.00596
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2949, 0.3132, 0.3918], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.43
Average Loss: -0.01295
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3235, 0.2859, 0.3906], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.72
Average Loss: -0.01801
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3403, 0.2792, 0.3805], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.77
Average Loss: -0.02409
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3634, 0.2777, 0.3589], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.3
Average Loss: -0.03222
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3744, 0.2804, 0.3452], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.38
Average Loss: -0.0439
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3943, 0.2790, 0.3267], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.4
Average Loss: -0.04496
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4118, 0.2865, 0.3017], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.83
Average Loss: -0.04806
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4274, 0.2787, 0.2939], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.58
Average Loss: -0.05031
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4465, 0.2747, 0.2789], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.38
Average Loss: -0.05291
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4534, 0.2707, 0.2759], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.95
Average Loss: -0.05375
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4546, 0.2703, 0.2751], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.43
Average Loss: -0.05124
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4550, 0.2688, 0.2762], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.12
Average Loss: -0.05016
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4525, 0.2678, 0.2796], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.63
Average Loss: -0.05512
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4608, 0.2657, 0.2735], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.17
Average Loss: -0.0553
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4606, 0.2647, 0.2747], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.88
Average Loss: -0.05472
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4653, 0.2641, 0.2706], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.45
Average Loss: -0.05539
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4651, 0.2650, 0.2699], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.43
Average Loss: -0.05619
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4649, 0.2638, 0.2713], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.55
Average Loss: -0.05314
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4727, 0.2619, 0.2655], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.1
Average Loss: -0.05462
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4718, 0.2606, 0.2676], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.07
Average Loss: -0.05478
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4737, 0.2594, 0.2669], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.23
Average Loss: -0.05667
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4754, 0.2569, 0.2677], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.92
Average Loss: -0.05752
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4800, 0.2543, 0.2657], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.07
Average Loss: -0.05413
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4820, 0.2547, 0.2633], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.08
Average Loss: -0.05733
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4808, 0.2541, 0.2651], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.28
Average Loss: -0.05466
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4835, 0.2521, 0.2644], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.03
Average Loss: -0.05576
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4898, 0.2502, 0.2600], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.17
Average Loss: -0.05507
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4897, 0.2502, 0.2601], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.33
Average Loss: -0.05777
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4959, 0.2486, 0.2556], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.18
Average Loss: -0.05676
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5086, 0.2474, 0.2440], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.28
Average Loss: -0.0573
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5167, 0.2449, 0.2384], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.75
Average Loss: -0.05995
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5206, 0.2433, 0.2361], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.18
Average Loss: -0.05449
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5199, 0.2434, 0.2367], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.25
Average Loss: -0.0562
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5283, 0.2379, 0.2337], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.43
Average Loss: -0.05911
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5348, 0.2324, 0.2327], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.28
Average Loss: -0.05744
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5371, 0.2324, 0.2305], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.72
Average Loss: -0.05522
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5468, 0.2281, 0.2251], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.48
Average Loss: -0.05473
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5543, 0.2237, 0.2220], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.12
Average Loss: -0.05541
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5676, 0.2175, 0.2150], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.2
Average Loss: -0.05268
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5800, 0.2174, 0.2026], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.47
Average Loss: -0.04823
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5961, 0.2131, 0.1908], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.2
Average Loss: -0.04928
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6164, 0.2063, 0.1773], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.85
Average Loss: -0.05248
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6274, 0.1997, 0.1728], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.02
Average Loss: -0.05086
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6215, 0.1997, 0.1788], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.97
Average Loss: -0.05359
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6562, 0.1895, 0.1543], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.27
Average Loss: -0.04535
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6950, 0.1778, 0.1272], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.77
Average Loss: -0.04744
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7369, 0.1619, 0.1012], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.42
Average Loss: -0.0426
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7398, 0.1614, 0.0988], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.3
Average Loss: -0.04484
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7859, 0.1413, 0.0729], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.15
Average Loss: -0.0399
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8241, 0.1218, 0.0541], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.88
Average Loss: -0.04159
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8610, 0.1008, 0.0382], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.38
Average Loss: -0.04399
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9157, 0.0672, 0.0172], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.02
Average Loss: -0.03648
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9433, 0.0475, 0.0092], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.88
Average Loss: -0.03885
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9594, 0.0358, 0.0048], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.02
Average Loss: -0.03507
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9728, 0.0251, 0.0022], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.4
Average Loss: -0.03381
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9813, 0.0175, 0.0012], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.28
Average Loss: -0.03301
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.8868e-01, 1.0556e-02, 7.6388e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.1
Average Loss: -0.03266
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9035e-01, 8.9699e-03, 6.8339e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.42
Average Loss: -0.02844
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.8996e-01, 9.3021e-03, 7.3776e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.23
Average Loss: -0.02934
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.8992e-01, 9.3561e-03, 7.2222e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.47
Average Loss: -0.0254
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9074e-01, 8.6339e-03, 6.2288e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.12
Average Loss: -0.02728
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9230e-01, 7.2105e-03, 4.8675e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.28
Average Loss: -0.02597
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9342e-01, 6.1706e-03, 4.0516e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.87
Average Loss: -0.02718
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9455e-01, 5.1348e-03, 3.1933e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.28
Average Loss: -0.02478
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9449e-01, 5.1875e-03, 3.2375e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.3
Average Loss: -0.0239
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9504e-01, 4.6669e-03, 2.9404e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.85
Average Loss: -0.01891
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9461e-01, 5.0732e-03, 3.1334e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.4
Average Loss: -0.01844
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9479e-01, 4.9247e-03, 2.8817e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.73
Average Loss: -0.02024
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9526e-01, 4.4797e-03, 2.5795e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.05
Average Loss: -0.02064
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9543e-01, 4.3276e-03, 2.4108e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.12
Average Loss: -0.01634
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9579e-01, 3.9845e-03, 2.2215e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.83
Average Loss: -0.01452
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9650e-01, 3.3130e-03, 1.8830e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.47
Average Loss: -0.01673
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9676e-01, 3.0595e-03, 1.7731e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.58
Average Loss: -0.01561
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9701e-01, 2.8160e-03, 1.7170e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.38
Average Loss: -0.013
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9728e-01, 2.5593e-03, 1.5934e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.72
Average Loss: -0.01206
Timesteps So Far: 234000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9756e-01, 2.3077e-03, 1.3689e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.22
Average Loss: -0.01063
Timesteps So Far: 237000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9771e-01, 2.1570e-03, 1.3216e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.27
Average Loss: -0.00988
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9789e-01, 1.9771e-03, 1.3080e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.47
Average Loss: -0.00934
Timesteps So Far: 243000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9801e-01, 1.8567e-03, 1.3610e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.67
Average Loss: -0.00824
Timesteps So Far: 246000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9794e-01, 1.9024e-03, 1.5318e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.98
Average Loss: -0.0071
Timesteps So Far: 249000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9822e-01, 1.6488e-03, 1.3474e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.15
Average Loss: -0.00521
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9863e-01, 1.2628e-03, 1.0970e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.2
Average Loss: -0.00483
Timesteps So Far: 255000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9896e-01, 9.5104e-04, 9.0185e-05], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.42
Average Loss: -0.00336
Timesteps So Far: 258000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9902e-01, 8.8226e-04, 9.5730e-05], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.58
Average Loss: -0.00211
Timesteps So Far: 261000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9902e-01, 8.8160e-04, 9.9983e-05], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #88 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.7
Average Loss: -0.0014
Timesteps So Far: 264000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9901e-01, 8.7957e-04, 1.1053e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #89 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.58
Average Loss: -0.00206
Timesteps So Far: 267000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9903e-01, 8.6033e-04, 1.1146e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #90 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.82
Average Loss: -0.00151
Timesteps So Far: 270000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9969e-01, 2.7324e-04, 3.4975e-05], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #91 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.75
Average Loss: -0.00126
Timesteps So Far: 273000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9989e-01, 9.5023e-05, 1.2523e-05], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #92 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.83
Average Loss: -0.00079
Timesteps So Far: 276000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9993e-01, 6.3388e-05, 9.0959e-06], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #93 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.9
Average Loss: -0.00054
Timesteps So Far: 279000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9994e-01, 5.4885e-05, 8.6071e-06], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #94 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.78
Average Loss: -0.00096
Timesteps So Far: 282000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9994e-01, 5.2127e-05, 9.1328e-06], grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

