Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.3402, 0.3584, 0.3014], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.8
Average Loss: -0.00418
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3288, 0.3752, 0.2960], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.22
Average Loss: -0.00372
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3233, 0.3791, 0.2975], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.43
Average Loss: -0.01295
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3074, 0.3777, 0.3148], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.85
Average Loss: -0.01782
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3320, 0.3550, 0.3130], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.28
Average Loss: -0.02299
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3519, 0.3331, 0.3150], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.25
Average Loss: -0.03776
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3602, 0.3297, 0.3101], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.37
Average Loss: -0.03839
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3721, 0.3332, 0.2947], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.67
Average Loss: -0.04399
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3915, 0.3208, 0.2877], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.27
Average Loss: -0.04653
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4235, 0.2892, 0.2873], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.35
Average Loss: -0.04844
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4311, 0.2845, 0.2844], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.03
Average Loss: -0.05011
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4456, 0.2806, 0.2737], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.72
Average Loss: -0.05136
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4487, 0.2773, 0.2740], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.12
Average Loss: -0.05056
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4520, 0.2775, 0.2705], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.95
Average Loss: -0.05382
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4560, 0.2744, 0.2696], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.23
Average Loss: -0.05045
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4552, 0.2768, 0.2680], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.37
Average Loss: -0.05481
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4536, 0.2776, 0.2688], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.57
Average Loss: -0.05573
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4528, 0.2776, 0.2696], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.8
Average Loss: -0.0501
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4583, 0.2759, 0.2658], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.13
Average Loss: -0.05543
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4582, 0.2773, 0.2644], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.43
Average Loss: -0.05551
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4632, 0.2752, 0.2616], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.33
Average Loss: -0.06067
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4711, 0.2691, 0.2598], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.77
Average Loss: -0.05789
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4718, 0.2660, 0.2622], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.57
Average Loss: -0.05739
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4751, 0.2656, 0.2593], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.43
Average Loss: -0.05639
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4770, 0.2644, 0.2587], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.85
Average Loss: -0.05718
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4795, 0.2643, 0.2563], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.23
Average Loss: -0.0553
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4816, 0.2630, 0.2554], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.17
Average Loss: -0.05806
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4868, 0.2584, 0.2548], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.48
Average Loss: -0.05677
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4908, 0.2583, 0.2509], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.3
Average Loss: -0.05636
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4948, 0.2566, 0.2486], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.07
Average Loss: -0.05471
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4946, 0.2544, 0.2510], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.43
Average Loss: -0.05871
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5015, 0.2536, 0.2449], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.43
Average Loss: -0.06064
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5062, 0.2511, 0.2427], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.57
Average Loss: -0.05663
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5129, 0.2483, 0.2388], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.9
Average Loss: -0.05876
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5187, 0.2446, 0.2367], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.95
Average Loss: -0.05474
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5238, 0.2418, 0.2344], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.7
Average Loss: -0.05605
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5248, 0.2397, 0.2355], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.72
Average Loss: -0.05237
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5330, 0.2358, 0.2312], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.02
Average Loss: -0.05443
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5398, 0.2360, 0.2242], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.73
Average Loss: -0.05459
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5420, 0.2339, 0.2240], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.63
Average Loss: -0.05383
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5536, 0.2300, 0.2164], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.95
Average Loss: -0.05341
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5649, 0.2230, 0.2121], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.78
Average Loss: -0.04853
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5650, 0.2224, 0.2126], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.6
Average Loss: -0.04972
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5576, 0.2253, 0.2171], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.33
Average Loss: -0.04913
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5769, 0.2145, 0.2086], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.33
Average Loss: -0.04648
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5974, 0.2071, 0.1955], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.33
Average Loss: -0.04773
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6226, 0.1987, 0.1788], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.2
Average Loss: -0.04724
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6284, 0.1965, 0.1751], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.27
Average Loss: -0.04441
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6505, 0.1873, 0.1621], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.88
Average Loss: -0.04601
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6871, 0.1730, 0.1399], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.58
Average Loss: -0.0466
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6905, 0.1723, 0.1372], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.07
Average Loss: -0.04384
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7136, 0.1608, 0.1256], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.72
Average Loss: -0.04437
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7563, 0.1339, 0.1098], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.32
Average Loss: -0.04324
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8144, 0.1107, 0.0749], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.05
Average Loss: -0.03311
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8276, 0.1188, 0.0537], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.6
Average Loss: -0.03611
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8783, 0.0839, 0.0378], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.87
Average Loss: -0.03392
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9129, 0.0617, 0.0254], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.13
Average Loss: -0.02727
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9223, 0.0549, 0.0228], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.17
Average Loss: -0.03375
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9269, 0.0506, 0.0225], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.77
Average Loss: -0.03225
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9424, 0.0393, 0.0184], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.68
Average Loss: -0.02968
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9452, 0.0338, 0.0209], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.63
Average Loss: -0.02632
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9447, 0.0245, 0.0309], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.75
Average Loss: -0.02492
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9027, 0.0277, 0.0696], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.58
Average Loss: -0.02544
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8994, 0.0231, 0.0776], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.52
Average Loss: -0.02519
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8824, 0.0345, 0.0831], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.08
Average Loss: -0.02249
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8935, 0.0291, 0.0774], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.93
Average Loss: -0.01797
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9178, 0.0186, 0.0636], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.33
Average Loss: -0.01817
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9355, 0.0138, 0.0507], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.4
Average Loss: -0.01804
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9592, 0.0096, 0.0312], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.77
Average Loss: -0.0164
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9786, 0.0057, 0.0158], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.57
Average Loss: -0.01213
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9858, 0.0042, 0.0100], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.88
Average Loss: -0.01216
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9913, 0.0029, 0.0058], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.13
Average Loss: -0.01075
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9949, 0.0016, 0.0035], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.08
Average Loss: -0.006
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9967, 0.0011, 0.0022], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.18
Average Loss: -0.00722
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9970, 0.0011, 0.0019], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.47
Average Loss: -0.00562
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9729e-01, 9.9184e-04, 1.7232e-03], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.53
Average Loss: -0.00519
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9972, 0.0010, 0.0017], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.48
Average Loss: -0.00596
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9971, 0.0011, 0.0018], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.75
Average Loss: -0.00416
Timesteps So Far: 234000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9970, 0.0012, 0.0018], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.63
Average Loss: -0.00503
Timesteps So Far: 237000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9974, 0.0010, 0.0015], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.82
Average Loss: -0.00334
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9748e-01, 9.9512e-04, 1.5220e-03], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.67
Average Loss: -0.00477
Timesteps So Far: 243000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9789e-01, 8.9040e-04, 1.2243e-03], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.83
Average Loss: -0.00311
Timesteps So Far: 246000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9978, 0.0012, 0.0010], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.8
Average Loss: -0.00354
Timesteps So Far: 249000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9789e-01, 1.4892e-03, 6.1814e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.9
Average Loss: -0.00236
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9735e-01, 2.2878e-03, 3.6706e-04], grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

