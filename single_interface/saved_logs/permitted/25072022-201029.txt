Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.3246, 0.3303, 0.3450], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.38
Average Loss: -0.00467
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3597, 0.2997, 0.3406], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.67
Average Loss: -0.00147
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3411, 0.3054, 0.3535], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.73
Average Loss: -0.00532
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3289, 0.3197, 0.3514], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.08
Average Loss: -0.01542
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3288, 0.3586, 0.3126], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.87
Average Loss: -0.02435
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3456, 0.3716, 0.2827], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.07
Average Loss: -0.04094
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3230, 0.3757, 0.3013], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.77
Average Loss: -0.0432
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3225, 0.3749, 0.3026], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.03
Average Loss: -0.04664
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3468, 0.3566, 0.2967], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.08
Average Loss: -0.04974
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4017, 0.3150, 0.2833], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.35
Average Loss: -0.04905
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4230, 0.3059, 0.2711], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.43
Average Loss: -0.05621
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4308, 0.2990, 0.2702], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.43
Average Loss: -0.05077
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4319, 0.3012, 0.2669], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.35
Average Loss: -0.05481
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4278, 0.3021, 0.2701], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.42
Average Loss: -0.05438
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4315, 0.3033, 0.2651], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.15
Average Loss: -0.05408
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4350, 0.3001, 0.2649], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.07
Average Loss: -0.05776
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4400, 0.2936, 0.2664], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.02
Average Loss: -0.05642
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4452, 0.2889, 0.2658], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.65
Average Loss: -0.05719
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4495, 0.2854, 0.2651], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.67
Average Loss: -0.05657
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4503, 0.2821, 0.2676], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.68
Average Loss: -0.05315
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4543, 0.2784, 0.2673], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.8
Average Loss: -0.05384
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4578, 0.2759, 0.2664], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.42
Average Loss: -0.05838
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4679, 0.2723, 0.2598], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.15
Average Loss: -0.0602
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4734, 0.2694, 0.2572], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.65
Average Loss: -0.05938
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4762, 0.2680, 0.2558], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.03
Average Loss: -0.05674
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4730, 0.2685, 0.2586], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.27
Average Loss: -0.05664
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4820, 0.2666, 0.2514], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.22
Average Loss: -0.05681
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4847, 0.2655, 0.2498], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.07
Average Loss: -0.05532
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4865, 0.2626, 0.2509], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.2
Average Loss: -0.05695
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4920, 0.2601, 0.2479], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.18
Average Loss: -0.05993
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4948, 0.2589, 0.2463], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.45
Average Loss: -0.05837
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4965, 0.2572, 0.2463], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.22
Average Loss: -0.05357
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4986, 0.2537, 0.2477], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.88
Average Loss: -0.06015
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5055, 0.2504, 0.2441], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.73
Average Loss: -0.05538
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5136, 0.2423, 0.2441], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.4
Average Loss: -0.05968
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5224, 0.2384, 0.2391], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.93
Average Loss: -0.05566
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5294, 0.2338, 0.2368], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.82
Average Loss: -0.05622
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5340, 0.2318, 0.2342], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.68
Average Loss: -0.05895
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5398, 0.2298, 0.2303], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.48
Average Loss: -0.05605
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5462, 0.2225, 0.2313], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.37
Average Loss: -0.05443
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5505, 0.2198, 0.2297], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.08
Average Loss: -0.05318
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5603, 0.2219, 0.2179], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.75
Average Loss: -0.05299
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5743, 0.2196, 0.2060], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.87
Average Loss: -0.05272
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5852, 0.2143, 0.2004], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.78
Average Loss: -0.05166
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5938, 0.2097, 0.1964], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.07
Average Loss: -0.04902
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6101, 0.2048, 0.1851], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.55
Average Loss: -0.05105
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6243, 0.2060, 0.1697], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.3
Average Loss: -0.05202
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6300, 0.1991, 0.1709], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.28
Average Loss: -0.0471
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6373, 0.1961, 0.1666], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.33
Average Loss: -0.04566
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6558, 0.1887, 0.1555], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.52
Average Loss: -0.04597
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6634, 0.1820, 0.1546], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.73
Average Loss: -0.04447
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6511, 0.1875, 0.1614], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.25
Average Loss: -0.04452
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6554, 0.1933, 0.1513], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.92
Average Loss: -0.04147
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6604, 0.1946, 0.1450], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.1
Average Loss: -0.0393
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6973, 0.1765, 0.1261], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.4
Average Loss: -0.03571
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7281, 0.1593, 0.1126], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.95
Average Loss: -0.03692
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7259, 0.1631, 0.1110], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.42
Average Loss: -0.03344
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6914, 0.1862, 0.1224], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.27
Average Loss: -0.03814
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6993, 0.1863, 0.1145], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.15
Average Loss: -0.03636
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7096, 0.1833, 0.1072], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.95
Average Loss: -0.03635
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7160, 0.1789, 0.1051], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.0
Average Loss: -0.03188
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7384, 0.1622, 0.0994], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.72
Average Loss: -0.03101
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7455, 0.1589, 0.0955], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.35
Average Loss: -0.03107
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7541, 0.1538, 0.0920], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.28
Average Loss: -0.03216
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7781, 0.1368, 0.0850], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.05
Average Loss: -0.03277
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8360, 0.1031, 0.0609], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.93
Average Loss: -0.02881
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8808, 0.0777, 0.0415], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.63
Average Loss: -0.02382
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8909, 0.0719, 0.0372], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.38
Average Loss: -0.02342
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8782, 0.0794, 0.0423], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.17
Average Loss: -0.02107
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8830, 0.0763, 0.0408], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.03
Average Loss: -0.01709
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8831, 0.0763, 0.0407], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.05
Average Loss: -0.02167
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8899, 0.0701, 0.0400], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.53
Average Loss: -0.02142
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9043, 0.0594, 0.0363], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.7
Average Loss: -0.01777
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9097, 0.0559, 0.0344], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.42
Average Loss: -0.01628
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9139, 0.0538, 0.0323], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.8
Average Loss: -0.01623
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9364, 0.0400, 0.0236], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.25
Average Loss: -0.01366
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9558, 0.0282, 0.0160], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.12
Average Loss: -0.01144
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9684, 0.0206, 0.0110], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.27
Average Loss: -0.0114
Timesteps So Far: 234000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9767, 0.0155, 0.0078], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.75
Average Loss: -0.0094
Timesteps So Far: 237000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9819, 0.0123, 0.0059], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.2
Average Loss: -0.00742
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9851, 0.0102, 0.0047], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.45
Average Loss: -0.00601
Timesteps So Far: 243000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9900, 0.0068, 0.0033], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.58
Average Loss: -0.00507
Timesteps So Far: 246000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9948, 0.0035, 0.0017], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.68
Average Loss: -0.00465
Timesteps So Far: 249000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9732e-01, 1.8594e-03, 8.2129e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.82
Average Loss: -0.00315
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9840e-01, 1.1610e-03, 4.4240e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.9
Average Loss: -0.00228
Timesteps So Far: 255000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9904e-01, 6.8942e-04, 2.6697e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.98
Average Loss: -0.00068
Timesteps So Far: 258000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9967e-01, 2.2091e-04, 1.0765e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.98
Average Loss: -0.00077
Timesteps So Far: 261000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9967e-01, 2.2073e-04, 1.1267e-04], grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

