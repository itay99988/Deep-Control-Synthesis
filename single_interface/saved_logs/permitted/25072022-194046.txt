Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.3391, 0.3405, 0.3204], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.93
Average Loss: -0.00123
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3143, 0.3647, 0.3209], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -8.78
Average Loss: -0.00526
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3456, 0.3643, 0.2900], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.73
Average Loss: -0.00696
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3667, 0.3409, 0.2923], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.78
Average Loss: -0.01683
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3911, 0.3289, 0.2800], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.78
Average Loss: -0.02583
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3968, 0.3396, 0.2636], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.18
Average Loss: -0.02748
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4040, 0.3331, 0.2629], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.62
Average Loss: -0.03293
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3968, 0.3291, 0.2741], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.83
Average Loss: -0.03451
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3815, 0.3504, 0.2681], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.7
Average Loss: -0.04022
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3641, 0.3696, 0.2663], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.58
Average Loss: -0.04464
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3525, 0.3819, 0.2656], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.45
Average Loss: -0.04929
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3527, 0.3784, 0.2689], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.02
Average Loss: -0.05037
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3835, 0.3473, 0.2692], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.57
Average Loss: -0.05416
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4084, 0.3211, 0.2705], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.1
Average Loss: -0.05377
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4224, 0.3151, 0.2625], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.53
Average Loss: -0.05057
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4361, 0.3047, 0.2592], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.7
Average Loss: -0.05351
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4400, 0.3005, 0.2595], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.18
Average Loss: -0.05563
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4451, 0.2950, 0.2598], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.78
Average Loss: -0.05347
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4495, 0.2917, 0.2588], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.62
Average Loss: -0.05769
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4544, 0.2856, 0.2600], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.4
Average Loss: -0.05492
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4589, 0.2807, 0.2604], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.3
Average Loss: -0.05723
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4663, 0.2758, 0.2579], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.47
Average Loss: -0.05735
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4679, 0.2730, 0.2592], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.58
Average Loss: -0.05402
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4698, 0.2728, 0.2574], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.72
Average Loss: -0.05682
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4795, 0.2659, 0.2546], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.95
Average Loss: -0.05783
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4871, 0.2580, 0.2549], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.88
Average Loss: -0.05595
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4875, 0.2578, 0.2547], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.3
Average Loss: -0.05637
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4883, 0.2571, 0.2546], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.2
Average Loss: -0.05708
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4914, 0.2558, 0.2528], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.85
Average Loss: -0.05481
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4943, 0.2542, 0.2515], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.3
Average Loss: -0.05755
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4992, 0.2529, 0.2479], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.62
Average Loss: -0.05849
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5060, 0.2489, 0.2451], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.05
Average Loss: -0.0582
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5064, 0.2473, 0.2463], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.75
Average Loss: -0.05846
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5132, 0.2446, 0.2421], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.28
Average Loss: -0.05636
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5123, 0.2425, 0.2452], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.55
Average Loss: -0.05644
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5174, 0.2423, 0.2403], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.08
Average Loss: -0.05881
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5301, 0.2327, 0.2371], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.45
Average Loss: -0.05223
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5270, 0.2366, 0.2364], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.42
Average Loss: -0.05282
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5287, 0.2355, 0.2358], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.87
Average Loss: -0.05446
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5383, 0.2287, 0.2330], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.83
Average Loss: -0.05431
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5414, 0.2279, 0.2306], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.82
Average Loss: -0.05291
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5504, 0.2229, 0.2266], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.78
Average Loss: -0.05564
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5614, 0.2161, 0.2225], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.0
Average Loss: -0.0526
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5634, 0.2144, 0.2222], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.32
Average Loss: -0.05043
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5691, 0.2170, 0.2139], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.27
Average Loss: -0.05199
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5856, 0.2097, 0.2048], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.35
Average Loss: -0.04787
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5950, 0.2039, 0.2011], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.9
Average Loss: -0.04547
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6062, 0.1968, 0.1971], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.6
Average Loss: -0.04496
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6221, 0.1877, 0.1902], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.12
Average Loss: -0.04681
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6480, 0.1729, 0.1791], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.7
Average Loss: -0.04823
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6719, 0.1558, 0.1723], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.67
Average Loss: -0.04382
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6884, 0.1482, 0.1634], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.82
Average Loss: -0.04739
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7250, 0.1322, 0.1429], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.08
Average Loss: -0.0443
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7675, 0.1125, 0.1200], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.92
Average Loss: -0.03975
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7698, 0.1147, 0.1155], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.45
Average Loss: -0.03801
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7750, 0.1149, 0.1101], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.8
Average Loss: -0.03747
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7804, 0.1145, 0.1051], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.92
Average Loss: -0.03494
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7541, 0.1307, 0.1153], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.32
Average Loss: -0.03943
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7568, 0.1269, 0.1163], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.23
Average Loss: -0.03535
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7492, 0.1267, 0.1240], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.28
Average Loss: -0.03331
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7463, 0.1242, 0.1295], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.53
Average Loss: -0.03361
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7571, 0.1192, 0.1237], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.33
Average Loss: -0.03285
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7589, 0.1204, 0.1207], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.98
Average Loss: -0.03141
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7731, 0.1156, 0.1112], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.18
Average Loss: -0.03304
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8143, 0.0959, 0.0898], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.1
Average Loss: -0.0283
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8371, 0.0840, 0.0789], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.18
Average Loss: -0.02976
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8593, 0.0728, 0.0679], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.18
Average Loss: -0.02673
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8940, 0.0533, 0.0527], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.53
Average Loss: -0.02821
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9146, 0.0418, 0.0435], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.05
Average Loss: -0.02727
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9170, 0.0406, 0.0424], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.83
Average Loss: -0.0254
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9180, 0.0397, 0.0423], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.47
Average Loss: -0.02325
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9142, 0.0409, 0.0449], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.65
Average Loss: -0.0199
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9239, 0.0358, 0.0403], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.75
Average Loss: -0.02174
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9312, 0.0320, 0.0368], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.57
Average Loss: -0.0208
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9575, 0.0186, 0.0239], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.63
Average Loss: -0.01912
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9693, 0.0131, 0.0176], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.02
Average Loss: -0.01395
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9685, 0.0137, 0.0178], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.8
Average Loss: -0.01541
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9714, 0.0124, 0.0162], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.32
Average Loss: -0.01464
Timesteps So Far: 234000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9744, 0.0111, 0.0145], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.72
Average Loss: -0.01292
Timesteps So Far: 237000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9807, 0.0086, 0.0107], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.1
Average Loss: -0.01183
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9880, 0.0054, 0.0066], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.77
Average Loss: -0.00886
Timesteps So Far: 243000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9931, 0.0030, 0.0038], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.2
Average Loss: -0.00746
Timesteps So Far: 246000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9951, 0.0022, 0.0026], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.37
Average Loss: -0.00654
Timesteps So Far: 249000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9968, 0.0017, 0.0015], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.72
Average Loss: -0.00376
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9803e-01, 9.4061e-04, 1.0280e-03], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.7
Average Loss: -0.00398
Timesteps So Far: 255000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9880e-01, 5.7687e-04, 6.2244e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.8
Average Loss: -0.00298
Timesteps So Far: 258000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9934e-01, 3.3671e-04, 3.2170e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.92
Average Loss: -0.0015
Timesteps So Far: 261000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9944e-01, 2.9729e-04, 2.6575e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #88 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.92
Average Loss: -0.00194
Timesteps So Far: 264000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9965e-01, 1.7594e-04, 1.7799e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #89 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -0.0
Timesteps So Far: 267000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9968e-01, 1.6999e-04, 1.5126e-04], grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

