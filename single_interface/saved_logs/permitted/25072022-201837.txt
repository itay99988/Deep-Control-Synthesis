Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.3495, 0.3310, 0.3195], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.75
Average Loss: -0.00141
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3335, 0.3094, 0.3571], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.18
Average Loss: -0.00336
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3329, 0.3191, 0.3481], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.72
Average Loss: -0.01609
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3696, 0.3025, 0.3279], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -6.55
Average Loss: -0.02614
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3645, 0.3145, 0.3210], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.88
Average Loss: -0.03457
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3906, 0.3177, 0.2917], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -5.28
Average Loss: -0.04038
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3910, 0.3178, 0.2912], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -4.13
Average Loss: -0.04829
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4067, 0.3069, 0.2864], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.03
Average Loss: -0.04815
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4003, 0.3121, 0.2876], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.15
Average Loss: -0.05143
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4162, 0.2975, 0.2863], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.97
Average Loss: -0.05081
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4323, 0.2844, 0.2833], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.3
Average Loss: -0.05182
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4370, 0.2763, 0.2867], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.08
Average Loss: -0.05109
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4451, 0.2740, 0.2809], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.07
Average Loss: -0.05319
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4478, 0.2753, 0.2769], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.62
Average Loss: -0.05024
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4531, 0.2729, 0.2740], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.4
Average Loss: -0.05262
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4538, 0.2699, 0.2763], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.4
Average Loss: -0.05648
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4570, 0.2661, 0.2769], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.63
Average Loss: -0.05277
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4569, 0.2711, 0.2720], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.22
Average Loss: -0.05532
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4607, 0.2675, 0.2718], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.32
Average Loss: -0.05841
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4600, 0.2699, 0.2700], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.5
Average Loss: -0.05468
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4605, 0.2714, 0.2681], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.07
Average Loss: -0.05651
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4628, 0.2686, 0.2686], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -2.15
Average Loss: -0.05656
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4716, 0.2624, 0.2661], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.33
Average Loss: -0.05673
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4754, 0.2624, 0.2622], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.87
Average Loss: -0.05601
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4835, 0.2589, 0.2576], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.68
Average Loss: -0.0558
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4811, 0.2614, 0.2574], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.53
Average Loss: -0.0531
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4861, 0.2585, 0.2554], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.38
Average Loss: -0.05632
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4895, 0.2574, 0.2530], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.57
Average Loss: -0.05698
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4906, 0.2573, 0.2521], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.28
Average Loss: -0.05679
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4968, 0.2527, 0.2505], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.0
Average Loss: -0.06174
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4973, 0.2525, 0.2502], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -0.42
Average Loss: -0.05631
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5009, 0.2522, 0.2469], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.53
Average Loss: -0.05749
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5025, 0.2514, 0.2461], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.5
Average Loss: -0.05583
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5084, 0.2481, 0.2435], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.08
Average Loss: -0.05523
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5144, 0.2436, 0.2420], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.17
Average Loss: -0.05655
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5198, 0.2405, 0.2397], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.9
Average Loss: -0.05472
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5227, 0.2389, 0.2384], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.98
Average Loss: -0.05617
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5290, 0.2364, 0.2346], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.33
Average Loss: -0.05544
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5345, 0.2325, 0.2331], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.13
Average Loss: -0.05745
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5421, 0.2256, 0.2323], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.37
Average Loss: -0.05231
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5461, 0.2244, 0.2295], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.35
Average Loss: -0.05376
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5455, 0.2261, 0.2284], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.3
Average Loss: -0.05026
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5570, 0.2210, 0.2220], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.88
Average Loss: -0.05152
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5695, 0.2166, 0.2139], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.52
Average Loss: -0.05014
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5785, 0.2142, 0.2073], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.92
Average Loss: -0.04946
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5867, 0.2127, 0.2006], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.4
Average Loss: -0.04553
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5818, 0.2151, 0.2031], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.43
Average Loss: -0.04387
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5881, 0.2088, 0.2031], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.6
Average Loss: -0.04337
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5928, 0.2050, 0.2022], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.07
Average Loss: -0.04482
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5960, 0.2024, 0.2015], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.87
Average Loss: -0.04241
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6029, 0.1978, 0.1993], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.02
Average Loss: -0.04693
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6145, 0.1914, 0.1941], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.28
Average Loss: -0.04351
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6150, 0.1909, 0.1941], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 5.97
Average Loss: -0.0418
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6268, 0.1871, 0.1861], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.7
Average Loss: -0.03585
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6417, 0.1764, 0.1819], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.53
Average Loss: -0.03912
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6496, 0.1735, 0.1769], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.43
Average Loss: -0.03932
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6549, 0.1707, 0.1745], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.62
Average Loss: -0.03738
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6552, 0.1741, 0.1707], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.55
Average Loss: -0.03656
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6762, 0.1590, 0.1647], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.62
Average Loss: -0.03521
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6799, 0.1581, 0.1620], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.1
Average Loss: -0.03357
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.6991, 0.1487, 0.1522], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.25
Average Loss: -0.03452
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7159, 0.1384, 0.1456], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.48
Average Loss: -0.03276
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7380, 0.1262, 0.1358], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.18
Average Loss: -0.03228
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7740, 0.1117, 0.1143], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.17
Average Loss: -0.02916
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.7876, 0.1029, 0.1095], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.75
Average Loss: -0.02814
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8014, 0.0980, 0.1006], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.42
Average Loss: -0.02544
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8236, 0.0856, 0.0908], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.65
Average Loss: -0.02268
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8465, 0.0724, 0.0812], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.83
Average Loss: -0.02205
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8462, 0.0708, 0.0829], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.35
Average Loss: -0.02338
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8542, 0.0678, 0.0780], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.18
Average Loss: -0.02154
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8664, 0.0596, 0.0740], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.1
Average Loss: -0.01847
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.8885, 0.0500, 0.0615], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.53
Average Loss: -0.01911
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9047, 0.0423, 0.0530], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.02
Average Loss: -0.01851
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9167, 0.0378, 0.0455], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.95
Average Loss: -0.01393
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9276, 0.0322, 0.0403], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 15.63
Average Loss: -0.01307
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9385, 0.0266, 0.0349], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.55
Average Loss: -0.01131
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9419, 0.0251, 0.0330], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.65
Average Loss: -0.01179
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9578, 0.0179, 0.0243], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.45
Average Loss: -0.0097
Timesteps So Far: 234000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9657, 0.0146, 0.0196], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.35
Average Loss: -0.00675
Timesteps So Far: 237000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9723, 0.0116, 0.0161], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.28
Average Loss: -0.00719
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9783, 0.0099, 0.0117], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.13
Average Loss: -0.00407
Timesteps So Far: 243000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9828, 0.0079, 0.0093], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.93
Average Loss: -0.0047
Timesteps So Far: 246000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9836, 0.0079, 0.0085], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.02
Average Loss: -0.00353
Timesteps So Far: 249000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9895, 0.0049, 0.0056], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.5
Average Loss: -0.00357
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9924, 0.0037, 0.0039], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.98
Average Loss: -0.00311
Timesteps So Far: 255000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9944, 0.0030, 0.0027], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.85
Average Loss: -0.0019
Timesteps So Far: 258000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9924, 0.0046, 0.0030], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.7
Average Loss: -0.0012
Timesteps So Far: 261000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.9961, 0.0024, 0.0015], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #88 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.97
Average Loss: -0.00084
Timesteps So Far: 264000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9851e-01, 8.1065e-04, 6.8365e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #89 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.23
Average Loss: -0.00052
Timesteps So Far: 267000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9894e-01, 5.8047e-04, 4.7972e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #90 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.27
Average Loss: -0.00053
Timesteps So Far: 270000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9934e-01, 3.6737e-04, 2.9531e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #91 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.67
Average Loss: -0.00013
Timesteps So Far: 273000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9927e-01, 4.0167e-04, 3.2394e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #92 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.53
Average Loss: -0.00054
Timesteps So Far: 276000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9921e-01, 4.5286e-04, 3.3889e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #93 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.72
Average Loss: -0.00019
Timesteps So Far: 279000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9955e-01, 2.5318e-04, 2.0163e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #94 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.78
Average Loss: -0.00035
Timesteps So Far: 282000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9973e-01, 1.4723e-04, 1.1878e-04], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #95 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.83
Average Loss: -0.0002
Timesteps So Far: 285000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9979e-01, 1.1994e-04, 9.0927e-05], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #96 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.75
Average Loss: -0.00042
Timesteps So Far: 288000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9983e-01, 9.7865e-05, 7.5906e-05], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #97 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.9
Average Loss: -9e-05
Timesteps So Far: 291000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9986e-01, 7.5507e-05, 6.1438e-05], grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

