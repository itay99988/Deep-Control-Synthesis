Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.5092, 0.4908], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.33
Average Loss: 0.22946
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4914, 0.5086], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.83
Average Loss: 0.15652
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4802, 0.5198], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.63
Average Loss: 0.02759
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4710, 0.5290], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.77
Average Loss: -0.03181
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4716, 0.5284], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.83
Average Loss: -0.04657
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4713, 0.5287], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.47
Average Loss: -0.05453
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4705, 0.5295], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.83
Average Loss: -0.05636
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4731, 0.5269], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.17
Average Loss: -0.0728
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4758, 0.5242], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.97
Average Loss: -0.06913
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4750, 0.5250], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.7
Average Loss: -0.05887
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4705, 0.5295], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.93
Average Loss: -0.06077
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4677, 0.5323], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.77
Average Loss: -0.05903
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4658, 0.5342], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.4
Average Loss: -0.07251
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4647, 0.5353], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.1
Average Loss: -0.04175
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4565, 0.5435], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.5
Average Loss: -0.03836
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4420, 0.5580], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.23
Average Loss: -0.03374
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4245, 0.5755], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.97
Average Loss: -0.03404
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4051, 0.5949], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.83
Average Loss: -0.04784
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3868, 0.6132], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.9
Average Loss: -0.01719
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3509, 0.6491], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -14.7
Average Loss: 0.00449
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1768, 0.8232], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.03
Average Loss: 0.10533
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0153, 0.9847], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.03
Average Loss: 0.14811
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0040, 0.9960], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.6
Average Loss: 0.13007
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0071, 0.9929], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.23
Average Loss: 0.11794
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0102, 0.9898], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.9
Average Loss: 0.1195
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0124, 0.9876], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.9
Average Loss: 0.11141
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0116, 0.9884], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: 0.11711
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0109, 0.9891], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.33
Average Loss: 0.10518
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0095, 0.9905], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.5
Average Loss: 0.0594
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0109, 0.9891], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.07
Average Loss: -0.00139
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0119, 0.9881], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.43
Average Loss: -0.02207
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0080, 0.9920], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.63
Average Loss: -0.02539
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0040, 0.9960], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.9
Average Loss: -0.03329
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0019, 0.9981], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.9
Average Loss: -0.00172
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0012, 0.9988], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.07
Average Loss: -0.01087
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.9114e-04, 9.9901e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.03
Average Loss: -0.01549
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0010, 0.9990], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.23
Average Loss: -0.03537
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.7500e-04, 9.9943e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.53
Average Loss: -0.04359
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.1612e-04, 9.9968e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.53
Average Loss: -0.05278
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.2934e-04, 9.9987e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.33
Average Loss: -0.06074
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.2730e-04, 9.9987e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.13
Average Loss: -0.0629
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([8.2341e-05, 9.9992e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.57
Average Loss: -0.06948
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.4178e-05, 9.9994e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.2
Average Loss: -0.06678
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.4938e-05, 9.9996e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.37
Average Loss: -0.07459
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.1093e-05, 9.9997e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.53
Average Loss: -0.07612
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.0159e-05, 9.9998e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.0
Average Loss: -0.07232
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.5395e-05, 9.9998e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.0
Average Loss: -0.07295
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.1478e-05, 9.9999e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.03
Average Loss: -0.07204
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.1743e-06, 9.9999e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.17
Average Loss: -0.07422
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.3888e-06, 9.9999e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.27
Average Loss: -0.07556
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.6763e-06, 9.9999e-01], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.23
Average Loss: -0.07995
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.4371e-06, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.6
Average Loss: -0.07589
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.4662e-06, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.97
Average Loss: -0.07751
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.9794e-06, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.63
Average Loss: -0.07619
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.3761e-06, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.13
Average Loss: -0.07809
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.7801e-06, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.57
Average Loss: -0.08224
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.4036e-06, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.27
Average Loss: -0.0792
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.1529e-06, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.6
Average Loss: -0.08072
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.2638e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.83
Average Loss: -0.08264
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([7.3406e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.37
Average Loss: -0.07772
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([5.9421e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.27
Average Loss: -0.07579
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([4.5336e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.07
Average Loss: -0.07478
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([3.7697e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.33
Average Loss: -0.0763
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.9739e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.43
Average Loss: -0.078
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.3787e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.63
Average Loss: -0.07941
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([2.1773e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.93
Average Loss: -0.08226
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.6232e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.57
Average Loss: -0.07268
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.4300e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.8
Average Loss: -0.06143
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.5957e-08, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.73
Average Loss: -0.06751
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([1.1249e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.77
Average Loss: -0.06124
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.3008e-08, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.93
Average Loss: -0.06601
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([6.8533e-08, 1.0000e+00], grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

