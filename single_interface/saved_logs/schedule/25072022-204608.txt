Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.4442, 0.5558], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.93
Average Loss: 0.19674
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4327, 0.5673], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.27
Average Loss: 0.14246
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4248, 0.5752], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.4
Average Loss: 0.03345
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4147, 0.5853], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.4
Average Loss: 0.00075
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4086, 0.5914], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.97
Average Loss: -0.00313
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4073, 0.5927], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.97
Average Loss: -0.01298
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4071, 0.5929], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.1
Average Loss: -0.04438
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4127, 0.5873], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.33
Average Loss: -0.05316
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4174, 0.5826], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.63
Average Loss: -0.02562
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4141, 0.5859], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.6
Average Loss: -0.03763
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4076, 0.5924], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.43
Average Loss: -0.01918
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3988, 0.6012], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.77
Average Loss: 0.01017
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3845, 0.6155], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.43
Average Loss: -0.00772
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3657, 0.6343], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.7
Average Loss: 0.00362
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3450, 0.6550], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -16.63
Average Loss: -0.02821
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3259, 0.6741], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.5
Average Loss: -0.02974
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3090, 0.6910], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -14.97
Average Loss: 0.00973
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2890, 0.7110], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -12.13
Average Loss: 0.03055
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2648, 0.7352], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.97
Average Loss: 0.05964
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2374, 0.7626], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.07
Average Loss: 0.02105
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2123, 0.7877], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -9.5
Average Loss: 0.00027
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1895, 0.8105], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.13
Average Loss: -0.01431
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1703, 0.8297], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -7.03
Average Loss: -0.03393
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1476, 0.8524], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -3.6
Average Loss: -0.03423
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1322, 0.8678], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -1.43
Average Loss: -0.0346
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1189, 0.8811], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 1.83
Average Loss: -0.03336
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1073, 0.8927], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 2.73
Average Loss: -0.03546
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0973, 0.9027], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 3.33
Average Loss: -0.03886
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0887, 0.9113], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 4.87
Average Loss: -0.04205
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0810, 0.9190], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.73
Average Loss: -0.02968
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0749, 0.9251], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.4
Average Loss: -0.03823
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0696, 0.9304], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.17
Average Loss: -0.04345
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0646, 0.9354], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 10.27
Average Loss: -0.03471
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0601, 0.9399], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 9.93
Average Loss: -0.04561
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0560, 0.9440], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 6.43
Average Loss: -0.03611
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0523, 0.9477], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.33
Average Loss: -0.03722
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0490, 0.9510], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.23
Average Loss: -0.03064
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0461, 0.9539], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.1
Average Loss: -0.03666
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0434, 0.9566], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.4
Average Loss: -0.0339
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0408, 0.9592], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.27
Average Loss: -0.03855
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0384, 0.9616], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.63
Average Loss: -0.02901
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0363, 0.9637], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.9
Average Loss: -0.03763
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0343, 0.9657], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 13.87
Average Loss: -0.0338
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0324, 0.9676], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.8
Average Loss: -0.03079
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0306, 0.9694], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.1
Average Loss: -0.02822
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0290, 0.9710], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 14.87
Average Loss: -0.03219
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0275, 0.9725], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.87
Average Loss: -0.03128
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0261, 0.9739], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.03
Average Loss: -0.02267
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0248, 0.9752], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.6
Average Loss: -0.02421
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0236, 0.9764], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.13
Average Loss: -0.02312
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0225, 0.9775], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.9
Average Loss: -0.02157
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0214, 0.9786], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.43
Average Loss: -0.02458
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0204, 0.9796], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.1
Average Loss: -0.02816
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0194, 0.9806], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.3
Average Loss: -0.02354
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0184, 0.9816], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.2
Average Loss: -0.0163
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0176, 0.9824], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.97
Average Loss: -0.01704
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0168, 0.9832], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.3
Average Loss: -0.01668
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0160, 0.9840], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.1
Average Loss: -0.01521
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0153, 0.9847], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.5
Average Loss: -0.02024
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0146, 0.9854], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.6
Average Loss: -0.02463
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0139, 0.9861], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.8
Average Loss: -0.01871
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0132, 0.9868], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.5
Average Loss: -0.01406
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0126, 0.9874], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.87
Average Loss: -0.01238
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0120, 0.9880], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.1
Average Loss: -0.01526
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0115, 0.9885], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.13
Average Loss: -0.01164
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0110, 0.9890], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.73
Average Loss: -0.01602
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0105, 0.9895], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.37
Average Loss: -0.01103
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0100, 0.9900], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.7
Average Loss: -0.0107
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0095, 0.9905], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.63
Average Loss: -0.00918
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0091, 0.9909], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.03
Average Loss: -0.00838
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0087, 0.9913], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.93
Average Loss: -0.01184
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0083, 0.9917], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.53
Average Loss: -0.01506
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0079, 0.9921], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #73 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.87
Average Loss: -0.0086
Timesteps So Far: 219000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0076, 0.9924], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #74 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.8
Average Loss: -0.01207
Timesteps So Far: 222000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0072, 0.9928], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #75 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.93
Average Loss: -0.00765
Timesteps So Far: 225000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0069, 0.9931], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #76 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.6
Average Loss: -0.00888
Timesteps So Far: 228000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0066, 0.9934], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #77 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.87
Average Loss: -0.00777
Timesteps So Far: 231000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0062, 0.9938], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #78 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.87
Average Loss: -0.01005
Timesteps So Far: 234000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0060, 0.9940], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #79 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.6
Average Loss: -0.00926
Timesteps So Far: 237000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0057, 0.9943], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #80 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.87
Average Loss: -0.00445
Timesteps So Far: 240000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0054, 0.9946], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #81 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.4
Average Loss: -0.00601
Timesteps So Far: 243000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0052, 0.9948], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #82 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.47
Average Loss: -0.00814
Timesteps So Far: 246000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0049, 0.9951], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #83 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.6
Average Loss: -0.00519
Timesteps So Far: 249000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0044, 0.9956], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #84 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.8
Average Loss: -0.00726
Timesteps So Far: 252000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0037, 0.9963], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #85 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.53
Average Loss: -0.00479
Timesteps So Far: 255000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0030, 0.9970], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #86 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.57
Average Loss: -0.0013
Timesteps So Far: 258000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0026, 0.9974], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #87 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.9
Average Loss: -0.00298
Timesteps So Far: 261000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0022, 0.9978], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #88 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.8
Average Loss: -0.00071
Timesteps So Far: 264000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0020, 0.9980], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #89 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.93
Average Loss: -0.00296
Timesteps So Far: 267000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0018, 0.9982], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #90 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.9
Average Loss: -0.0002
Timesteps So Far: 270000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0017, 0.9983], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #91 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.83
Average Loss: -0.00052
Timesteps So Far: 273000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0016, 0.9984], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #92 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -3e-05
Timesteps So Far: 276000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0015, 0.9985], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #93 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.27
Average Loss: -0.00113
Timesteps So Far: 279000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0014, 0.9986], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #94 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.53
Average Loss: -0.00142
Timesteps So Far: 282000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0013, 0.9987], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #95 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.63
Average Loss: -0.00121
Timesteps So Far: 285000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0012, 0.9988], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #96 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -2e-05
Timesteps So Far: 288000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0012, 0.9988], grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

