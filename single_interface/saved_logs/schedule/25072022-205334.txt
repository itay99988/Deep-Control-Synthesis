Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 3000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Training
Training from scratch.
Learning... Running 25 timesteps per episode, 3000 timesteps per batch for a total of 1500000 timesteps
tensor([0.5424, 0.4576], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #1 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.13
Average Loss: 0.19768
Timesteps So Far: 3000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.5211, 0.4789], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #2 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.2
Average Loss: 0.04454
Timesteps So Far: 6000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4947, 0.5053], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #3 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.37
Average Loss: 0.02105
Timesteps So Far: 9000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4679, 0.5321], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #4 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.37
Average Loss: -0.02402
Timesteps So Far: 12000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4628, 0.5372], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #5 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.97
Average Loss: -0.04085
Timesteps So Far: 15000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4774, 0.5226], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #6 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.47
Average Loss: -0.06846
Timesteps So Far: 18000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4809, 0.5191], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #7 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.8
Average Loss: -0.05989
Timesteps So Far: 21000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4843, 0.5157], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #8 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.0
Average Loss: -0.06474
Timesteps So Far: 24000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4828, 0.5172], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #9 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -19.13
Average Loss: -0.06713
Timesteps So Far: 27000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4797, 0.5203], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #10 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.9
Average Loss: -0.06007
Timesteps So Far: 30000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4780, 0.5220], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #11 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.47
Average Loss: -0.05679
Timesteps So Far: 33000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4729, 0.5271], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #12 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.57
Average Loss: -0.05046
Timesteps So Far: 36000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4630, 0.5370], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #13 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.83
Average Loss: -0.05593
Timesteps So Far: 39000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4505, 0.5495], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #14 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.33
Average Loss: -0.02046
Timesteps So Far: 42000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4324, 0.5676], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #15 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -18.1
Average Loss: -0.04534
Timesteps So Far: 45000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.4134, 0.5866], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #16 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.1
Average Loss: -0.01976
Timesteps So Far: 48000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3922, 0.6078], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #17 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -17.2
Average Loss: -0.03383
Timesteps So Far: 51000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3635, 0.6365], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #18 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.33
Average Loss: -0.00368
Timesteps So Far: 54000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3504, 0.6496], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #19 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -15.7
Average Loss: -0.0166
Timesteps So Far: 57000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.3202, 0.6798], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #20 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -13.5
Average Loss: 0.00989
Timesteps So Far: 60000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2879, 0.7121], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #21 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.53
Average Loss: 0.01136
Timesteps So Far: 63000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.2488, 0.7512], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #22 --------------------
Average Episodic Length: 25.0
Average Episodic Return: -11.33
Average Loss: 0.00949
Timesteps So Far: 66000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.1121, 0.8879], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #23 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.97
Average Loss: 0.10758
Timesteps So Far: 69000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0259, 0.9741], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #24 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.47
Average Loss: 0.08191
Timesteps So Far: 72000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0272, 0.9728], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #25 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.9
Average Loss: 0.03989
Timesteps So Far: 75000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0508, 0.9492], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #26 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 11.07
Average Loss: -0.02181
Timesteps So Far: 78000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0556, 0.9444], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #27 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 0.97
Average Loss: -0.042
Timesteps So Far: 81000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0635, 0.9365], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #28 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 7.47
Average Loss: -0.05658
Timesteps So Far: 84000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0711, 0.9289], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #29 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 8.93
Average Loss: -0.06275
Timesteps So Far: 87000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0586, 0.9414], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #30 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 12.47
Average Loss: -0.05788
Timesteps So Far: 90000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0376, 0.9624], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #31 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.2
Average Loss: -0.04924
Timesteps So Far: 93000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0267, 0.9733], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #32 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.13
Average Loss: -0.0482
Timesteps So Far: 96000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0251, 0.9749], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #33 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 16.33
Average Loss: -0.05172
Timesteps So Far: 99000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0261, 0.9739], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #34 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.73
Average Loss: -0.04737
Timesteps So Far: 102000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0246, 0.9754], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #35 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 18.0
Average Loss: -0.04783
Timesteps So Far: 105000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0221, 0.9779], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #36 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.63
Average Loss: -0.04953
Timesteps So Far: 108000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0198, 0.9802], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #37 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.3
Average Loss: -0.03687
Timesteps So Far: 111000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0171, 0.9829], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #38 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.47
Average Loss: -0.03634
Timesteps So Far: 114000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0178, 0.9822], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #39 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 17.9
Average Loss: -0.0484
Timesteps So Far: 117000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0194, 0.9806], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #40 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 19.73
Average Loss: -0.04592
Timesteps So Far: 120000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0131, 0.9869], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #41 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.57
Average Loss: -0.04174
Timesteps So Far: 123000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0146, 0.9854], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #42 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 20.67
Average Loss: -0.05277
Timesteps So Far: 126000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0075, 0.9925], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #43 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.97
Average Loss: -0.04377
Timesteps So Far: 129000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0115, 0.9885], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #44 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 22.17
Average Loss: -0.05049
Timesteps So Far: 132000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0099, 0.9901], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #45 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 21.53
Average Loss: -0.05139
Timesteps So Far: 135000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0094, 0.9906], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #46 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.13
Average Loss: -0.04893
Timesteps So Far: 138000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0105, 0.9895], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #47 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.3
Average Loss: -0.04842
Timesteps So Far: 141000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0077, 0.9923], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #48 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.6
Average Loss: -0.04515
Timesteps So Far: 144000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0075, 0.9925], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #49 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.0
Average Loss: -0.04594
Timesteps So Far: 147000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0064, 0.9936], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #50 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.67
Average Loss: -0.04678
Timesteps So Far: 150000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0055, 0.9945], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #51 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.7
Average Loss: -0.04669
Timesteps So Far: 153000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0063, 0.9937], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #52 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.13
Average Loss: -0.05022
Timesteps So Far: 156000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0046, 0.9954], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #53 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.23
Average Loss: -0.04896
Timesteps So Far: 159000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0045, 0.9955], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #54 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.47
Average Loss: -0.04457
Timesteps So Far: 162000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0046, 0.9954], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #55 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.5
Average Loss: -0.04683
Timesteps So Far: 165000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0039, 0.9961], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #56 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.67
Average Loss: -0.04518
Timesteps So Far: 168000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0037, 0.9963], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #57 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.33
Average Loss: -0.04608
Timesteps So Far: 171000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0035, 0.9965], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #58 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -0.04478
Timesteps So Far: 174000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0032, 0.9968], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #59 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -0.04488
Timesteps So Far: 177000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0028, 0.9972], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #60 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.67
Average Loss: -0.04761
Timesteps So Far: 180000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0027, 0.9973], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #61 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.33
Average Loss: -0.04616
Timesteps So Far: 183000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0023, 0.9977], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #62 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.6
Average Loss: -0.04651
Timesteps So Far: 186000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0023, 0.9977], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #63 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -0.04508
Timesteps So Far: 189000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0019, 0.9981], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #64 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.73
Average Loss: -0.04524
Timesteps So Far: 192000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0017, 0.9983], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #65 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 23.93
Average Loss: -0.04788
Timesteps So Far: 195000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0017, 0.9983], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #66 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.67
Average Loss: -0.04589
Timesteps So Far: 198000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0015, 0.9985], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #67 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.7
Average Loss: -0.04548
Timesteps So Far: 201000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0015, 0.9985], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #68 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -0.04515
Timesteps So Far: 204000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0014, 0.9986], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #69 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.7
Average Loss: -0.0457
Timesteps So Far: 207000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0012, 0.9988], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #70 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.7
Average Loss: -0.04561
Timesteps So Far: 210000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0011, 0.9989], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #71 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 24.63
Average Loss: -0.04648
Timesteps So Far: 213000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([0.0010, 0.9990], grad_fn=<SoftmaxBackward0>)

-------------------- Iteration #72 --------------------
Average Episodic Length: 25.0
Average Episodic Return: 25.0
Average Loss: -0.04546
Timesteps So Far: 216000
Iteration took: 0.0 secs
------------------------------------------------------

tensor([9.1067e-04, 9.9909e-01], grad_fn=<SoftmaxBackward0>)

Chosen hyperparameters for training:
{'history_len': 2, 'timesteps_per_batch': 2000, 'max_timesteps_per_episode': 25, 'gamma': 0.99, 'n_updates_per_iteration': 10, 'lr': 0.01, 'clip': 0.2, 'total_timesteps': 1500000}
Testing ppo_actor.pth

-------------------- Episode #0 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #1 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #2 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #3 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #4 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #5 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #6 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #7 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #8 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------


-------------------- Episode #9 --------------------
Episodic Length: 200
Episodic Return: 200
Failure Rate: 0.0%
------------------------------------------------------

